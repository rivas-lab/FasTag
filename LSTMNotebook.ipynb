{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# So code is automatically reloaded when saved in different modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  \n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import sys\n",
    "sys.path.append('src/taggerSystem/')\n",
    "from my_util import print_sentence, write_conll, read_conll\n",
    "from my_data_util import load_and_preprocess_data, load_embeddings, ModelHelper\n",
    "logger = logging.getLogger(\"hw3.q2\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = \"data/icd9NotesDataTable_train.csv\"\n",
    "data_valid = \"data/icd9NotesDataTable_valid.csv\"\n",
    "# data_train = \"data/smallIcd9NotesDataTable_test.csv\"\n",
    "# data_valid = \"data/smallIcd9NotesDataTable_valid.csv\"\n",
    "vocab = \"src/taggerSystem/data_hw3_delete/vocab.txt\"\n",
    "wordVecs = \"src/taggerSystem/data_hw3_delete/wordVectors.txt\"\n",
    "output_path = 'results/{}/{:%Y%m%d_%H%M%S}/\".format(self.cell, datetime.now())'\n",
    "log_output = output_path + \"log\"\n",
    "START_TOKEN = \"<s>\"\n",
    "END_TOKEN = \"</s>\"\n",
    "NUM = \"NNNUMMM\"\n",
    "UNK = \"UUUNKKK\"\n",
    "EMBED_SIZE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data and Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading training data...\n",
      "INFO:Done. Read 39544 notes\n",
      "INFO:Loading dev data...\n",
      "INFO:Done. Read 13182 notes\n",
      "INFO:Total read time 16.562712\n",
      "INFO:Built dictionary for 10007 features.\n",
      "INFO:There are a total of 20 ICD codes\n",
      "INFO:Initialized embeddings.\n"
     ]
    }
   ],
   "source": [
    "helper, train, dev, train_raw, dev_raw, xTrain, yTrain, xDev, yDev = load_and_preprocess_data(\n",
    "    data_train = data_train, data_valid = data_valid)\n",
    "# print('dev raw')\n",
    "# print(dev_raw)\n",
    "# print('dev')\n",
    "# print(dev)\n",
    "embeddings = load_embeddings(vocab, wordVecs, helper)\n",
    "helper.save(output_path)# token2id and max length saved to output_path\n",
    "handler = logging.FileHandler(log_output)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n",
    "logging.getLogger().addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 256\n",
    "total_batches = (xTrain.shape[0]//batch_size)\n",
    "\n",
    "n_input = 1\n",
    "n_steps = 10\n",
    "n_hidden = 30\n",
    "n_classes = helper.n_labels\n",
    "n_features = 1\n",
    "\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39544, 500)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39544, 20)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x = tf.placeholder(tf.int32, shape= (None, helper.max_length, n_features))\n",
    "x = tf.placeholder(tf.int32, shape= (None, helper.max_length))\n",
    "yTruth = tf.placeholder(tf.int32, shape = (None, helper.n_labels))\n",
    "y_steps = tf.placeholder(tf.int32, shape = (None, helper.n_labels))# not sure what this is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def LSTM(x, weight, bias):\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(n_hidden,state_is_tuple = True)\n",
    "    print(type(cell))\n",
    "    print(cell)\n",
    "    print(type(x))\n",
    "    print(x.get_shape())\n",
    "    print('cell output size')\n",
    "    print(cell.output_size)\n",
    "    print('cell state size')\n",
    "    print(cell.state_size)\n",
    "#     1/0\n",
    "#     print('cell size')\n",
    "#     print(cell.get_shape())\n",
    "#     1/0\n",
    "#     multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell([cell] * 2)\n",
    "\n",
    "    output, state = tf.nn.dynamic_rnn(cell = cell, inputs = x, dtype = tf.float32)\n",
    "    print('output shape')\n",
    "    print(output.get_shape())\n",
    "#     print(tf.transpose(output,[1,0,2]).get_shape())\n",
    "#     temp = tf.gather(tf.transpose(output,[1,0,2]), helper.max_length-1) \n",
    "#     print('temp shape')\n",
    "#     print(temp.get_shape())\n",
    "#     1/0\n",
    "#     output_flattened = tf.reshape(output, [-1, n_hidden])\n",
    "    output_flattened = tf.gather(tf.transpose(output,[1,0,2]), helper.max_length - 1)\n",
    "    print('output flattened shape')\n",
    "    print(output_flattened.get_shape())\n",
    "    output_logits = tf.add(tf.matmul(output_flattened,weight),bias)\n",
    "    # TODO here is where you're gonna have to change some stuff. You're\n",
    "    # running out of memory with this run. It'd be best to not multiply\n",
    "    # and get all predictions since we really only need last one\n",
    "\n",
    "#     output_all = tf.nn.sigmoid(output_logits)\n",
    "    print('output wx + b')\n",
    "    print(output_logits.get_shape())\n",
    "#     1/0\n",
    "#     output_reshaped = tf.reshape(output_logits,[-1,n_steps,n_classes])\n",
    "#     output_reshaped = tf.reshape(output_logits,[-1,helper.max_length,n_classes])\n",
    "#     print('reshaped shape')\n",
    "#     print(output_reshaped.get_shape())\n",
    "#     output_last = tf.gather(tf.transpose(output_reshaped,[1,0,2]), helper.max_length - 1)\n",
    "    output_last = output_logits\n",
    "    print('output last shape')\n",
    "    print(output_last.get_shape())\n",
    "    #Here is where you wanna get the last one. \n",
    "    #output = tf.transpose(output, [1, 0, 2])\n",
    "    #last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "    #output_last = tf.nn.sigmoid(tf.matmul(last, weight) + bias)\n",
    "    return output_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 500, 50)\n",
      "shape of embeddings\n",
      "(?, 500, 50)\n",
      "U shape\n",
      "(30, 20)\n",
      "bias shape\n",
      "(20,)\n",
      "<class 'tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell'>\n",
      "<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fa7dcbb1278>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 500, 50)\n",
      "cell output size\n",
      "30\n",
      "cell state size\n",
      "LSTMStateTuple(c=30, h=30)\n",
      "output shape\n",
      "(?, 500, 30)\n",
      "output flattened shape\n",
      "(?, 30)\n",
      "output wx + b\n",
      "(?, 20)\n",
      "output last shape\n",
      "(?, 20)\n"
     ]
    }
   ],
   "source": [
    "# weight = weight_variable([n_hidden,n_classes])\n",
    "with tf.variable_scope('RNN_OutsideCell', reuse = False) as scope:\n",
    "    U = tf.get_variable(name = 'U', shape = (n_hidden, n_classes), \n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "    bias = tf.get_variable(name = 'bias', shape = [n_classes], \n",
    "                           initializer = tf.constant_initializer(0))\n",
    "    # bias = bias_variable([n_classes])\n",
    "    pretrainedEmbeddings = tf.Variable(embeddings)\n",
    "    wordEmbeddings = tf.nn.embedding_lookup(params = pretrainedEmbeddings, ids = x)\n",
    "    print(wordEmbeddings.get_shape())\n",
    "#     wordEmbeddings = tf.reshape(wordEmbeddings, \n",
    "#                                 shape = tf.stack([-1, wordEmbeddings.get_shape()[1], wordEmbeddings.get_shape()[2]*wordEmbeddings.get_shape()[3]])) \n",
    "    print('shape of embeddings')\n",
    "    print(wordEmbeddings.get_shape())\n",
    "    print('U shape')\n",
    "    print(U.get_shape())\n",
    "    print('bias shape')\n",
    "    print(bias.get_shape())\n",
    "    y_last = LSTM(wordEmbeddings,U,bias)# TODO is y_last the correct thing to return?\n",
    "# adding loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandeepayyar1/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "batchError = tf.nn.sigmoid_cross_entropy_with_logits(logits = y_last, \n",
    "                                                 labels = tf.cast(yTruth, tf.float32))\n",
    "# print('yolo2')\n",
    "loss_function = tf.reduce_mean(batchError)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The paper does something weird. I'd suggest doing something closer to what we do in homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xDev[xDev == -1] = 0\n",
    "xTrain[xTrain == -1] = 0\n",
    "# hacky work around for issue where -1 is padding but now maps to UUNNNKKK vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "***************************\n",
      "Running on epoch 0\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.708766\n",
      "running iteration 25 with error 0.592134\n",
      "running iteration 50 with error 0.498013\n",
      "running iteration 75 with error 0.496222\n",
      "running iteration 100 with error 0.477900\n",
      "running iteration 125 with error 0.467245\n",
      "running iteration 150 with error 0.462870\n",
      "average Error 0.519059\n",
      "Total run time was 43.486848\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 1\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.480418\n",
      "running iteration 25 with error 0.470096\n",
      "running iteration 50 with error 0.462857\n",
      "running iteration 75 with error 0.476209\n",
      "running iteration 100 with error 0.452238\n",
      "running iteration 125 with error 0.445673\n",
      "running iteration 150 with error 0.441331\n",
      "average Error 0.462731\n",
      "Total run time was 42.929129\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 2\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.462339\n",
      "running iteration 25 with error 0.451672\n",
      "running iteration 50 with error 0.442723\n",
      "running iteration 75 with error 0.462313\n",
      "running iteration 100 with error 0.431483\n",
      "running iteration 125 with error 0.430391\n",
      "running iteration 150 with error 0.417639\n",
      "average Error 0.444206\n",
      "Total run time was 43.087904\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 3\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.449482\n",
      "running iteration 25 with error 0.425820\n",
      "running iteration 50 with error 0.420086\n",
      "running iteration 75 with error 0.440682\n",
      "running iteration 100 with error 0.416567\n",
      "running iteration 125 with error 0.425376\n",
      "running iteration 150 with error 0.399175\n",
      "average Error 0.425276\n",
      "Total run time was 43.234908\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 4\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.430282\n",
      "running iteration 25 with error 0.411252\n",
      "running iteration 50 with error 0.407858\n",
      "running iteration 75 with error 0.435015\n",
      "running iteration 100 with error 0.405938\n",
      "running iteration 125 with error 0.411355\n",
      "running iteration 150 with error 0.399110\n",
      "average Error 0.415272\n",
      "Total run time was 43.480313\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 5\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.424935\n",
      "running iteration 25 with error 0.404499\n",
      "running iteration 50 with error 0.402250\n",
      "running iteration 75 with error 0.439061\n",
      "running iteration 100 with error 0.400917\n",
      "running iteration 125 with error 0.407694\n",
      "running iteration 150 with error 0.387232\n",
      "average Error 0.410682\n",
      "Total run time was 43.026532\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 6\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.417202\n",
      "running iteration 25 with error 0.400562\n",
      "running iteration 50 with error 0.399630\n",
      "running iteration 75 with error 0.425884\n",
      "running iteration 100 with error 0.396433\n",
      "running iteration 125 with error 0.405508\n",
      "running iteration 150 with error 0.384078\n",
      "average Error 0.406227\n",
      "Total run time was 43.366888\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 7\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.413847\n",
      "running iteration 25 with error 0.397844\n",
      "running iteration 50 with error 0.397622\n",
      "running iteration 75 with error 0.424565\n",
      "running iteration 100 with error 0.394480\n",
      "running iteration 125 with error 0.403784\n",
      "running iteration 150 with error 0.381851\n",
      "average Error 0.403986\n",
      "Total run time was 44.268574\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 8\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.411507\n",
      "running iteration 25 with error 0.395813\n",
      "running iteration 50 with error 0.395759\n",
      "running iteration 75 with error 0.422742\n",
      "running iteration 100 with error 0.392803\n",
      "running iteration 125 with error 0.401862\n",
      "running iteration 150 with error 0.379886\n",
      "average Error 0.402101\n",
      "Total run time was 43.164910\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 9\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.409525\n",
      "running iteration 25 with error 0.394254\n",
      "running iteration 50 with error 0.393826\n",
      "running iteration 75 with error 0.421158\n",
      "running iteration 100 with error 0.391577\n",
      "running iteration 125 with error 0.399652\n",
      "running iteration 150 with error 0.378262\n",
      "average Error 0.400361\n",
      "Total run time was 44.418470\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 10\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.407884\n",
      "running iteration 25 with error 0.392783\n",
      "running iteration 50 with error 0.391945\n",
      "running iteration 75 with error 0.419578\n",
      "running iteration 100 with error 0.390150\n",
      "running iteration 125 with error 0.397734\n",
      "running iteration 150 with error 0.376103\n",
      "average Error 0.398634\n",
      "Total run time was 43.713028\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 11\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.406134\n",
      "running iteration 25 with error 0.391014\n",
      "running iteration 50 with error 0.390217\n",
      "running iteration 75 with error 0.417914\n",
      "running iteration 100 with error 0.388685\n",
      "running iteration 125 with error 0.395544\n",
      "running iteration 150 with error 0.373885\n",
      "average Error 0.396730\n",
      "Total run time was 43.684372\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 12\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.403594\n",
      "running iteration 25 with error 0.389226\n",
      "running iteration 50 with error 0.387033\n",
      "running iteration 75 with error 0.415470\n",
      "running iteration 100 with error 0.385927\n",
      "running iteration 125 with error 0.392609\n",
      "running iteration 150 with error 0.370899\n",
      "average Error 0.394395\n",
      "Total run time was 43.525064\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 13\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.400027\n",
      "running iteration 25 with error 0.386031\n",
      "running iteration 50 with error 0.383992\n",
      "running iteration 75 with error 0.412335\n",
      "running iteration 100 with error 0.383076\n",
      "running iteration 125 with error 0.389079\n",
      "running iteration 150 with error 0.366189\n",
      "average Error 0.391189\n",
      "Total run time was 43.556524\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 14\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.395061\n",
      "running iteration 25 with error 0.381650\n",
      "running iteration 50 with error 0.381442\n",
      "running iteration 75 with error 0.408921\n",
      "running iteration 100 with error 0.380218\n",
      "running iteration 125 with error 0.385376\n",
      "running iteration 150 with error 0.362419\n",
      "average Error 0.387554\n",
      "Total run time was 43.546804\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 15\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.390925\n",
      "running iteration 25 with error 0.378227\n",
      "running iteration 50 with error 0.378879\n",
      "running iteration 75 with error 0.404227\n",
      "running iteration 100 with error 0.377589\n",
      "running iteration 125 with error 0.382058\n",
      "running iteration 150 with error 0.359579\n",
      "average Error 0.384080\n",
      "Total run time was 43.076331\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 16\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.388365\n",
      "running iteration 25 with error 0.375022\n",
      "running iteration 50 with error 0.376324\n",
      "running iteration 75 with error 0.401318\n",
      "running iteration 100 with error 0.376888\n",
      "running iteration 125 with error 0.380023\n",
      "running iteration 150 with error 0.356526\n",
      "average Error 0.381421\n",
      "Total run time was 43.500169\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 17\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with error 0.385731\n",
      "running iteration 25 with error 0.371895\n",
      "running iteration 50 with error 0.373909\n",
      "running iteration 75 with error 0.398957\n",
      "running iteration 100 with error 0.373632\n",
      "running iteration 125 with error 0.377015\n"
     ]
    }
   ],
   "source": [
    "with open('runOutput.txt', 'w') as f:\n",
    "    with tf.Session() as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for epoch in range(training_epochs):\n",
    "            totalError = 0.0\n",
    "            f.write(\"\"\"***************************\n",
    "***************************\n",
    "Running on epoch %d\n",
    "***************************\n",
    "***************************\n",
    "***************************\\n\"\"\" %(epoch))\n",
    "            print('***************************')\n",
    "            print('***************************')\n",
    "            print('Running on epoch %d'% (epoch))\n",
    "            print('***************************')\n",
    "            print('***************************')\n",
    "            start = time.time()\n",
    "            for b in range(total_batches):\n",
    "        #             print(b)\n",
    "        #             if(b%25 == 0):\n",
    "        #                 print('running iteration %d'% (b))\n",
    "                offset = (b * batch_size) % (yTrain.shape[0] - batch_size)\n",
    "                batch_x = xTrain[offset:(offset + batch_size), :]\n",
    "        #             print('batch x size')\n",
    "        #             print(batch_x.shape)\n",
    "                batch_y = yTrain[offset:(offset + batch_size), :]\n",
    "        #             print('y shape')\n",
    "        #             print(batch_y.shape)\n",
    "        #             print(psutil.virtual_memory())\n",
    "        #             1/0\n",
    "        #             batch_y_steps = np.tile(batch_y,((xTrain.shape[1]),1))\n",
    "        #             1/0\n",
    "                _, c = session.run([train_op, loss_function],feed_dict={x: batch_x, yTruth : batch_y})\n",
    "                if(b%25 == 0):\n",
    "                    f.write('running iteration %d with error %3f \\n'% (b, c))\n",
    "                    print('running iteration %d with error %3f'% (b, c))\n",
    "        #             1/0\n",
    "                totalError = totalError + c\n",
    "            pred_y = session.run(y_last,feed_dict={x:xDev})\n",
    "        #         pred_y = tf.nn.sigmoid_cross_entropy_with_logits(logits = pred_y)\n",
    "        #         print(\"ROC AUC Score: \",roc_auc_score(yDev,pred_y))\n",
    "            print('average Error %f'% (totalError/total_batches))\n",
    "            print('Total run time was %3f'% (time.time() - start))\n",
    "            f.write('average Error %f \\n'%(totalError/total_batches)) \n",
    "            f.write('Total run time was %3f \\n'% (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13182, 20)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13182"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "np.sum(tf.argmax(pred_y, 1).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of multilabel-indicator and continuous-multioutput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-c29538b4167c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1_score %f\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myDev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sandeepayyar1/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    690\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m    691\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandeepayyar1/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    807\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandeepayyar1/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandeepayyar1/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[0;32m---> 82\u001b[0;31m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't handle mix of multilabel-indicator and continuous-multioutput"
     ]
    }
   ],
   "source": [
    "print(\"f1_score %f\"% sklearn.metrics.f1_score(yDev, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = tf.argmax(pred_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([735, 735, 735, ..., 735, 735, 735])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "temp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13182, 1851)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51492.1875"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13182000/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1000)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7fa8bdfdfb70>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22618506132782279"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalError/154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13182.0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6591000/(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '624': 1,\n",
       " 'V552': 2,\n",
       " 'V1062': 6,\n",
       " '323': 7,\n",
       " '962': 8,\n",
       " '437': 9,\n",
       " '288': 10,\n",
       " 'E8193': 11,\n",
       " 'V2501': 12,\n",
       " '471': 13,\n",
       " '333': 14,\n",
       " 'V1741': 15,\n",
       " 'E8543': 16,\n",
       " '176': 17,\n",
       " '651': 18,\n",
       " 'V0991': 19,\n",
       " 'E8405': 20,\n",
       " '273': 21,\n",
       " '226': 22,\n",
       " 'E9504': 1552,\n",
       " '183': 24,\n",
       " '823': 937,\n",
       " '611': 26,\n",
       " 'V4976': 624,\n",
       " 'E8210': 28,\n",
       " 'E9220': 29,\n",
       " '718': 30,\n",
       " 'V449': 31,\n",
       " 'V561': 1616,\n",
       " '299': 32,\n",
       " 'E9888': 33,\n",
       " 'E8702': 34,\n",
       " '343': 627,\n",
       " 'V0950': 939,\n",
       " '133': 37,\n",
       " 'V145': 38,\n",
       " 'V180': 39,\n",
       " 'E8840': 1811,\n",
       " 'V023': 40,\n",
       " '449': 41,\n",
       " 'V5481': 42,\n",
       " '218': 43,\n",
       " 'E8853': 267,\n",
       " '97': 45,\n",
       " '707': 46,\n",
       " '345': 47,\n",
       " '879': 48,\n",
       " 'V4281': 49,\n",
       " 'E8314': 50,\n",
       " '756': 51,\n",
       " 'E8609': 52,\n",
       " 'E9293': 53,\n",
       " 'V671': 54,\n",
       " 'E8584': 55,\n",
       " '161': 56,\n",
       " '999': 57,\n",
       " '180': 58,\n",
       " '972': 1384,\n",
       " 'V643': 59,\n",
       " 'E9294': 60,\n",
       " '7': 943,\n",
       " 'V4986': 62,\n",
       " '698': 63,\n",
       " 'E8497': 64,\n",
       " '875': 1764,\n",
       " 'E0039': 65,\n",
       " 'E9346': 66,\n",
       " 'V1261': 67,\n",
       " 'E9325': 68,\n",
       " 'V440': 69,\n",
       " '438': 70,\n",
       " 'E8624': 71,\n",
       " '377': 72,\n",
       " 'V1505': 73,\n",
       " 'E9331': 74,\n",
       " '659': 75,\n",
       " '738': 76,\n",
       " '354': 78,\n",
       " 'E9455': 79,\n",
       " '478': 81,\n",
       " 'E8162': 82,\n",
       " 'E9671': 83,\n",
       " '540': 84,\n",
       " 'V1085': 85,\n",
       " '436': 86,\n",
       " 'E9063': 87,\n",
       " '421': 88,\n",
       " '225': 946,\n",
       " 'E0026': 90,\n",
       " '919': 92,\n",
       " 'E9412': 93,\n",
       " 'E8769': 94,\n",
       " 'V0389': 95,\n",
       " '175': 96,\n",
       " 'E8353': 547,\n",
       " 'V1659': 98,\n",
       " 'E9452': 100,\n",
       " 'V174': 101,\n",
       " 'V4282': 102,\n",
       " 'V1083': 103,\n",
       " '822': 104,\n",
       " 'E9433': 105,\n",
       " 'V1381': 107,\n",
       " 'V1029': 108,\n",
       " '734': 109,\n",
       " 'V812': 110,\n",
       " '204': 111,\n",
       " 'V4589': 112,\n",
       " 'V017': 114,\n",
       " 'E9192': 115,\n",
       " 'E8002': 116,\n",
       " 'E9299': 117,\n",
       " 'V8741': 118,\n",
       " '111': 119,\n",
       " 'V8524': 120,\n",
       " 'V1859': 121,\n",
       " '317': 122,\n",
       " 'V4989': 123,\n",
       " 'E8800': 125,\n",
       " '326': 126,\n",
       " 'V1209': 127,\n",
       " 'V580': 128,\n",
       " '912': 130,\n",
       " 'E9288': 131,\n",
       " '492': 132,\n",
       " 'E8780': 133,\n",
       " 'V5881': 134,\n",
       " '173': 135,\n",
       " '414': 136,\n",
       " '953': 137,\n",
       " 'E0161': 138,\n",
       " 'E0089': 139,\n",
       " '321': 140,\n",
       " '866': 141,\n",
       " '351': 142,\n",
       " 'E8502': 143,\n",
       " '144': 144,\n",
       " '558': 146,\n",
       " 'V5416': 148,\n",
       " 'E9478': 336,\n",
       " 'V1006': 150,\n",
       " 'V291': 151,\n",
       " 'V4574': 152,\n",
       " '814': 153,\n",
       " '217': 154,\n",
       " 'E8187': 155,\n",
       " '824': 156,\n",
       " '432': 157,\n",
       " '402': 158,\n",
       " 'E8552': 159,\n",
       " '258': 160,\n",
       " 'E8503': 161,\n",
       " '876': 162,\n",
       " 'V1060': 1690,\n",
       " '208': 1578,\n",
       " 'E9242': 164,\n",
       " '385': 165,\n",
       " '405': 962,\n",
       " '454': 167,\n",
       " 'V1504': 168,\n",
       " 'E9301': 169,\n",
       " '682': 170,\n",
       " 'V138': 171,\n",
       " 'V6103': 172,\n",
       " '202': 173,\n",
       " '282': 174,\n",
       " 'E8138': 175,\n",
       " '629': 339,\n",
       " 'V560': 177,\n",
       " '694': 178,\n",
       " 'V272': 1268,\n",
       " '53': 180,\n",
       " 'E8842': 181,\n",
       " 'V167': 182,\n",
       " '342': 183,\n",
       " '610': 1052,\n",
       " 'E8216': 185,\n",
       " 'E9300': 186,\n",
       " 'E9572': 187,\n",
       " 'V111': 188,\n",
       " '428': 189,\n",
       " 'V6107': 190,\n",
       " 'V7651': 191,\n",
       " 'V0253': 192,\n",
       " '555': 193,\n",
       " '120': 194,\n",
       " 'E9506': 195,\n",
       " '433': 196,\n",
       " '205': 197,\n",
       " '341': 1118,\n",
       " 'V1641': 199,\n",
       " 'V444': 200,\n",
       " 'E9674': 201,\n",
       " 'V301': 202,\n",
       " 'E8384': 203,\n",
       " 'V4973': 1413,\n",
       " '623': 204,\n",
       " 'V4571': 205,\n",
       " '834': 206,\n",
       " 'V6141': 965,\n",
       " 'V113': 208,\n",
       " '729': 209,\n",
       " '496': 210,\n",
       " '132': 211,\n",
       " 'V163': 212,\n",
       " 'V8801': 213,\n",
       " '372': 214,\n",
       " 'V5417': 1470,\n",
       " '276': 216,\n",
       " 'V4511': 217,\n",
       " '339': 218,\n",
       " '685': 219,\n",
       " '139': 1700,\n",
       " '514': 220,\n",
       " '627': 288,\n",
       " 'V8389': 221,\n",
       " 'V4459': 222,\n",
       " 'V5843': 223,\n",
       " '255': 224,\n",
       " '943': 768,\n",
       " '188': 226,\n",
       " 'V5301': 1292,\n",
       " '881': 228,\n",
       " 'E9330': 229,\n",
       " 'V4578': 230,\n",
       " '712': 231,\n",
       " '298': 232,\n",
       " 'V016': 233,\n",
       " 'E8052': 1786,\n",
       " 'V1001': 813,\n",
       " '238': 234,\n",
       " 'E8792': 235,\n",
       " '122': 1429,\n",
       " 'E856': 509,\n",
       " '830': 237,\n",
       " 'V1309': 238,\n",
       " '770': 239,\n",
       " '38': 240,\n",
       " '595': 241,\n",
       " '847': 242,\n",
       " 'V5410': 243,\n",
       " '522': 1727,\n",
       " 'V4363': 244,\n",
       " 'V1004': 245,\n",
       " 'E8703': 246,\n",
       " '49': 247,\n",
       " 'E848': 248,\n",
       " '868': 667,\n",
       " 'V601': 250,\n",
       " '705': 1798,\n",
       " 'V052': 251,\n",
       " 'E8240': 252,\n",
       " 'V537': 253,\n",
       " '365': 254,\n",
       " 'E9238': 255,\n",
       " 'V292': 256,\n",
       " '260': 257,\n",
       " '494': 258,\n",
       " '989': 259,\n",
       " 'V0179': 353,\n",
       " '356': 262,\n",
       " 'V290': 263,\n",
       " '696': 264,\n",
       " '582': 265,\n",
       " 'V4614': 266,\n",
       " 'E9356': 44,\n",
       " 'V4364': 268,\n",
       " '731': 269,\n",
       " '980': 270,\n",
       " 'E8881': 271,\n",
       " 'V625': 977,\n",
       " 'V708': 274,\n",
       " '925': 275,\n",
       " 'V608': 276,\n",
       " 'cat:14': 277,\n",
       " '33': 278,\n",
       " '553': 356,\n",
       " 'E8415': 280,\n",
       " '440': 281,\n",
       " 'V3401': 282,\n",
       " '742': 980,\n",
       " 'V1043': 284,\n",
       " '313': 285,\n",
       " 'E9398': 286,\n",
       " '422': 287,\n",
       " 'E9687': 676,\n",
       " '794': 289,\n",
       " 'E9310': 290,\n",
       " '304': 291,\n",
       " 'E8150': 292,\n",
       " 'E9530': 293,\n",
       " 'V1819': 294,\n",
       " 'E8735': 474,\n",
       " '571': 296,\n",
       " '708': 297,\n",
       " 'E8191': 298,\n",
       " 'V5411': 299,\n",
       " '541': 300,\n",
       " 'V1242': 301,\n",
       " '792': 302,\n",
       " 'E8551': 1475,\n",
       " 'V5863': 678,\n",
       " 'V596': 304,\n",
       " 'E8343': 305,\n",
       " '588': 591,\n",
       " '145': 1598,\n",
       " '958': 308,\n",
       " '905': 309,\n",
       " '578': 310,\n",
       " '23': 311,\n",
       " 'V6406': 312,\n",
       " 'V1652': 1406,\n",
       " 'V8543': 313,\n",
       " '928': 314,\n",
       " 'E9386': 315,\n",
       " 'V1506': 316,\n",
       " 'V5841': 317,\n",
       " 'V1059': 318,\n",
       " '404': 319,\n",
       " 'E9250': 320,\n",
       " 'E8192': 1601,\n",
       " 'V252': 322,\n",
       " '869': 323,\n",
       " '591': 324,\n",
       " '802': 326,\n",
       " 'E8613': 327,\n",
       " 'E8846': 328,\n",
       " 'E9358': 329,\n",
       " '604': 330,\n",
       " 'V703': 331,\n",
       " 'V1586': 1420,\n",
       " '991': 332,\n",
       " '812': 333,\n",
       " 'E9421': 334,\n",
       " '908': 335,\n",
       " 'E9334': 149,\n",
       " '358': 337,\n",
       " 'E9209': 1703,\n",
       " '435': 338,\n",
       " 'E8130': 176,\n",
       " 'V602': 340,\n",
       " 'E9308': 342,\n",
       " 'E9315': 343,\n",
       " 'E8508': 344,\n",
       " 'E9344': 345,\n",
       " 'E8161': 346,\n",
       " '825': 1067,\n",
       " '921': 348,\n",
       " 'V4361': 349,\n",
       " 'E8783': 350,\n",
       " 'V5401': 351,\n",
       " 'E8830': 352,\n",
       " 'V1254': 261,\n",
       " 'E8587': 354,\n",
       " 'V1811': 355,\n",
       " 'E8554': 279,\n",
       " '507': 357,\n",
       " 'V5844': 1584,\n",
       " 'E9240': 358,\n",
       " '185': 359,\n",
       " 'V331': 360,\n",
       " '872': 361,\n",
       " '781': 362,\n",
       " 'E8548': 1608,\n",
       " '594': 364,\n",
       " 'E9689': 365,\n",
       " '733': 366,\n",
       " '466': 367,\n",
       " '525': 368,\n",
       " '884': 1250,\n",
       " '93': 830,\n",
       " '880': 369,\n",
       " '804': 370,\n",
       " '348': 371,\n",
       " 'E9317': 372,\n",
       " 'V672': 373,\n",
       " '954': 374,\n",
       " '639': 1724,\n",
       " '841': 375,\n",
       " 'V9010': 376,\n",
       " 'V08': 377,\n",
       " 'V140': 379,\n",
       " '431': 380,\n",
       " 'E9451': 381,\n",
       " 'V8530': 382,\n",
       " 'E915': 1615,\n",
       " 'E8490': 384,\n",
       " '885': 385,\n",
       " '665': 386,\n",
       " '195': 388,\n",
       " 'E8230': 389,\n",
       " '584': 390,\n",
       " 'V433': 391,\n",
       " '158': 392,\n",
       " 'V4577': 393,\n",
       " '842': 532,\n",
       " 'E8789': 1304,\n",
       " 'V640': 396,\n",
       " '586': 397,\n",
       " '134': 398,\n",
       " '622': 399,\n",
       " '461': 400,\n",
       " 'E9309': 570,\n",
       " 'E8710': 404,\n",
       " '955': 582,\n",
       " 'V1585': 406,\n",
       " 'V624': 407,\n",
       " 'E9208': 408,\n",
       " 'V171': 697,\n",
       " '331': 411,\n",
       " '206': 412,\n",
       " 'E8132': 413,\n",
       " 'E9800': 1307,\n",
       " 'V462': 416,\n",
       " 'V461': 417,\n",
       " '910': 418,\n",
       " 'V3001': 419,\n",
       " 'E8140': 420,\n",
       " 'E0080': 421,\n",
       " '30': 422,\n",
       " 'V298': 423,\n",
       " '254': 425,\n",
       " 'E9651': 1756,\n",
       " 'E8298': 426,\n",
       " '961': 427,\n",
       " '536': 428,\n",
       " 'V270': 429,\n",
       " 'V8812': 430,\n",
       " 'E9447': 431,\n",
       " '846': 432,\n",
       " '587': 433,\n",
       " 'V053': 434,\n",
       " '765': 435,\n",
       " 'V5422': 436,\n",
       " '752': 437,\n",
       " 'V1061': 438,\n",
       " 'V6111': 439,\n",
       " '34': 440,\n",
       " '40': 441,\n",
       " 'E976': 442,\n",
       " '607': 1004,\n",
       " '398': 445,\n",
       " '520': 446,\n",
       " '992': 447,\n",
       " 'V452': 448,\n",
       " '934': 449,\n",
       " '337': 450,\n",
       " 'E9109': 451,\n",
       " '542': 452,\n",
       " 'V5842': 453,\n",
       " '566': 454,\n",
       " 'V151': 455,\n",
       " '632': 456,\n",
       " 'E8248': 457,\n",
       " 'E8706': 458,\n",
       " '284': 1312,\n",
       " 'E9570': 460,\n",
       " '914': 461,\n",
       " '891': 106,\n",
       " '275': 463,\n",
       " 'V4611': 464,\n",
       " 'E9379': 1627,\n",
       " 'V1071': 466,\n",
       " '863': 467,\n",
       " 'V1241': 468,\n",
       " 'V8521': 469,\n",
       " '355': 470,\n",
       " 'V721': 471,\n",
       " 'V4972': 472,\n",
       " 'V5412': 473,\n",
       " '213': 1526,\n",
       " '790': 475,\n",
       " '773': 476,\n",
       " 'V4588': 477,\n",
       " '798': 478,\n",
       " 'V5811': 479,\n",
       " '537': 480,\n",
       " 'V510': 481,\n",
       " '371': 482,\n",
       " 'E8261': 483,\n",
       " 'V6104': 225,\n",
       " '164': 1318,\n",
       " '228': 1046,\n",
       " '590': 487,\n",
       " '539': 1240,\n",
       " 'E9019': 489,\n",
       " 'E9393': 490,\n",
       " 'E8189': 1573,\n",
       " '821': 492,\n",
       " '278': 1632,\n",
       " 'E9579': 495,\n",
       " '761': 496,\n",
       " 'E9351': 1108,\n",
       " 'E8582': 498,\n",
       " '227': 499,\n",
       " 'V1251': 500,\n",
       " '916': 501,\n",
       " '483': 502,\n",
       " '820': 503,\n",
       " '870': 504,\n",
       " 'E899': 1160,\n",
       " '453': 507,\n",
       " 'E8200': 508,\n",
       " 'cat:16': 510,\n",
       " 'E9340': 511,\n",
       " '815': 512,\n",
       " '660': 1220,\n",
       " 'V1541': 514,\n",
       " '8': 515,\n",
       " 'cat:10': 516,\n",
       " '446': 517,\n",
       " 'V1079': 518,\n",
       " 'V1502': 520,\n",
       " 'V040': 522,\n",
       " 'E9453': 523,\n",
       " 'V4963': 524,\n",
       " 'V029': 525,\n",
       " '723': 526,\n",
       " '136': 528,\n",
       " 'E8212': 529,\n",
       " 'V1584': 1019,\n",
       " '976': 531,\n",
       " '839': 394,\n",
       " '12': 533,\n",
       " '79': 534,\n",
       " 'E9320': 535,\n",
       " 'E8012': 536,\n",
       " 'V5302': 537,\n",
       " '265': 538,\n",
       " 'V5339': 539,\n",
       " '616': 540,\n",
       " 'V0261': 541,\n",
       " '229': 542,\n",
       " 'E0010': 944,\n",
       " 'V850': 544,\n",
       " 'V5861': 545,\n",
       " 'E9270': 546,\n",
       " '376': 97,\n",
       " 'E8801': 548,\n",
       " 'E8318': 1646,\n",
       " 'E8257': 551,\n",
       " 'E9248': 1332,\n",
       " 'E0139': 553,\n",
       " '806': 554,\n",
       " 'V6285': 555,\n",
       " 'E0138': 556,\n",
       " 'E9673': 558,\n",
       " '36': 559,\n",
       " 'V641': 560,\n",
       " 'E9385': 561,\n",
       " '923': 562,\n",
       " 'V4983': 563,\n",
       " 'E9470': 1024,\n",
       " '831': 565,\n",
       " 'E9198': 566,\n",
       " '380': 567,\n",
       " '957': 568,\n",
       " '873': 569,\n",
       " '429': 727,\n",
       " 'E9292': 571,\n",
       " '922': 572,\n",
       " '411': 573,\n",
       " 'E8902': 1640,\n",
       " 'E9821': 574,\n",
       " 'E9211': 575,\n",
       " '918': 576,\n",
       " 'V6129': 577,\n",
       " 'V403': 578,\n",
       " 'V554': 580,\n",
       " 'V536': 1013,\n",
       " 'V8489': 405,\n",
       " '572': 583,\n",
       " '801': 585,\n",
       " 'E8841': 586,\n",
       " 'E9060': 587,\n",
       " 'V8401': 588,\n",
       " '362': 589,\n",
       " 'E8233': 590,\n",
       " 'E9201': 1728,\n",
       " 'E8555': 1357,\n",
       " '840': 592,\n",
       " 'V453': 594,\n",
       " 'V289': 751,\n",
       " '279': 595,\n",
       " 'E9502': 596,\n",
       " 'V168': 597,\n",
       " '671': 1654,\n",
       " '860': 598,\n",
       " '187': 599,\n",
       " '340': 600,\n",
       " 'E9382': 601,\n",
       " '833': 602,\n",
       " 'V1649': 603,\n",
       " 'E8228': 604,\n",
       " '592': 666,\n",
       " 'E9600': 606,\n",
       " 'V741': 607,\n",
       " 'E8740': 608,\n",
       " 'V425': 609,\n",
       " '458': 610,\n",
       " '788': 611,\n",
       " 'V0971': 612,\n",
       " 'E9507': 613,\n",
       " '170': 614,\n",
       " 'V4582': 615,\n",
       " '215': 1657,\n",
       " '155': 617,\n",
       " 'V51': 1343,\n",
       " 'V8533': 619,\n",
       " 'V071': 620,\n",
       " '533': 621,\n",
       " '666': 622,\n",
       " '35': 623,\n",
       " 'V1047': 27,\n",
       " '602': 626,\n",
       " '988': 35,\n",
       " 'V110': 628,\n",
       " 'cat:4': 629,\n",
       " 'E8768': 630,\n",
       " 'E9390': 1283,\n",
       " '137': 631,\n",
       " '803': 632,\n",
       " '306': 634,\n",
       " '861': 635,\n",
       " '94': 1035,\n",
       " 'E8260': 637,\n",
       " 'E8133': 638,\n",
       " '778': 1363,\n",
       " '159': 639,\n",
       " '3': 145,\n",
       " 'V1302': 641,\n",
       " '970': 642,\n",
       " '190': 643,\n",
       " 'E9395': 645,\n",
       " '945': 646,\n",
       " 'E9380': 647,\n",
       " 'E8241': 648,\n",
       " '783': 649,\n",
       " 'V1052': 650,\n",
       " 'V202': 651,\n",
       " 'E9571': 652,\n",
       " '297': 653,\n",
       " 'V1255': 654,\n",
       " '116': 655,\n",
       " '308': 198,\n",
       " 'V5489': 414,\n",
       " 'V020': 658,\n",
       " 'E8180': 659,\n",
       " '325': 660,\n",
       " 'E8500': 661,\n",
       " '216': 662,\n",
       " 'V6289': 663,\n",
       " 'V1364': 664,\n",
       " 'V1072': 665,\n",
       " 'cat:1': 249,\n",
       " '777': 1191,\n",
       " 'V583': 669,\n",
       " 'cat:2': 670,\n",
       " 'E9322': 671,\n",
       " '335': 672,\n",
       " 'V1581': 673,\n",
       " '664': 674,\n",
       " 'E8251': 675,\n",
       " 'cat:11': 579,\n",
       " 'E8171': 677,\n",
       " '799': 303,\n",
       " 'V5399': 679,\n",
       " 'V1007': 680,\n",
       " '171': 681,\n",
       " 'E9479': 682,\n",
       " '182': 683,\n",
       " '686': 684,\n",
       " 'E9589': 685,\n",
       " '77': 686,\n",
       " 'cat:6': 687,\n",
       " '386': 688,\n",
       " 'E8908': 689,\n",
       " '154': 690,\n",
       " 'E8583': 691,\n",
       " '150': 692,\n",
       " '456': 1329,\n",
       " 'V667': 693,\n",
       " 'E8793': 694,\n",
       " '633': 696,\n",
       " '388': 410,\n",
       " '902': 698,\n",
       " '484': 699,\n",
       " 'E9360': 700,\n",
       " 'E8121': 701,\n",
       " '465': 702,\n",
       " '142': 703,\n",
       " '268': 704,\n",
       " 'E8797': 705,\n",
       " 'E9463': 706,\n",
       " 'V160': 707,\n",
       " 'E8668': 708,\n",
       " 'V556': 709,\n",
       " 'E8589': 710,\n",
       " '352': 711,\n",
       " 'E8541': 712,\n",
       " 'E8845': 713,\n",
       " 'V4573': 714,\n",
       " 'V431': 715,\n",
       " 'E0032': 716,\n",
       " '52': 1670,\n",
       " 'E8217': 718,\n",
       " 'E989': 719,\n",
       " '877': 721,\n",
       " 'E8550': 722,\n",
       " '357': 723,\n",
       " '412': 724,\n",
       " '262': 1311,\n",
       " 'E8556': 726,\n",
       " '397': 1243,\n",
       " 'E9204': 1358,\n",
       " '816': 729,\n",
       " '511': 730,\n",
       " '426': 731,\n",
       " '315': 732,\n",
       " '617': 733,\n",
       " '149': 734,\n",
       " '538': 1049,\n",
       " '579': 736,\n",
       " '500': 737,\n",
       " '743': 738,\n",
       " '663': 1673,\n",
       " '130': 955,\n",
       " 'E9804': 739,\n",
       " 'E9173': 740,\n",
       " '5': 741,\n",
       " '367': 742,\n",
       " '235': 743,\n",
       " 'E8242': 744,\n",
       " 'E9001': 745,\n",
       " 'E8809': 1050,\n",
       " 'E9850': 747,\n",
       " '597': 748,\n",
       " 'V6284': 749,\n",
       " '237': 750,\n",
       " '746': 754,\n",
       " 'E8637': 752,\n",
       " 'V4975': 753,\n",
       " 'E8641': 804,\n",
       " 'V469': 755,\n",
       " 'V061': 756,\n",
       " '791': 757,\n",
       " 'V626': 758,\n",
       " '387': 759,\n",
       " '13': 760,\n",
       " '947': 762,\n",
       " 'V1044': 763,\n",
       " '18': 817,\n",
       " 'E8197': 764,\n",
       " '753': 765,\n",
       " 'E977': 766,\n",
       " 'E9290': 767,\n",
       " '599': 867,\n",
       " '249': 770,\n",
       " 'V660': 771,\n",
       " '232': 772,\n",
       " '420': 773,\n",
       " '66': 774,\n",
       " '808': 775,\n",
       " '375': 776,\n",
       " '309': 912,\n",
       " 'E9100': 778,\n",
       " 'V420': 779,\n",
       " '779': 780,\n",
       " 'E8588': 782,\n",
       " 'E9241': 783,\n",
       " 'E8532': 784,\n",
       " '430': 785,\n",
       " 'E0190': 786,\n",
       " '464': 787,\n",
       " 'E8163': 788,\n",
       " '534': 985,\n",
       " 'V4985': 790,\n",
       " 'V0382': 791,\n",
       " 'E9222': 792,\n",
       " '459': 793,\n",
       " 'V789': 794,\n",
       " '994': 795,\n",
       " 'E8580': 796,\n",
       " 'V172': 797,\n",
       " '620': 1056,\n",
       " 'E0076': 800,\n",
       " 'V6149': 1683,\n",
       " 'V1087': 803,\n",
       " 'E8748': 1069,\n",
       " 'E9370': 805,\n",
       " 'V4971': 806,\n",
       " '172': 807,\n",
       " '647': 808,\n",
       " 'V1009': 809,\n",
       " '382': 810,\n",
       " 'E9419': 811,\n",
       " 'E986': 812,\n",
       " '724': 1115,\n",
       " 'cat:5': 1684,\n",
       " 'V5423': 814,\n",
       " 'V610': 815,\n",
       " 'V4961': 816,\n",
       " '441': 1152,\n",
       " 'E9426': 818,\n",
       " '848': 819,\n",
       " 'E8348': 820,\n",
       " 'V5831': 821,\n",
       " '674': 822,\n",
       " '295': 888,\n",
       " '853': 823,\n",
       " 'E8619': 1197,\n",
       " '148': 825,\n",
       " '413': 826,\n",
       " '642': 827,\n",
       " '574': 1804,\n",
       " 'E8495': 828,\n",
       " '110': 829,\n",
       " '495': 1225,\n",
       " '628': 1686,\n",
       " '670': 832,\n",
       " 'V6549': 1594,\n",
       " 'E9410': 1252,\n",
       " 'E8761': 836,\n",
       " '27': 837,\n",
       " 'V618': 838,\n",
       " 'V434': 839,\n",
       " 'E9420': 840,\n",
       " 'E9225': 841,\n",
       " 'E8142': 842,\n",
       " '714': 843,\n",
       " 'E8889': 844,\n",
       " '301': 845,\n",
       " 'V9039': 846,\n",
       " '305': 847,\n",
       " 'E8795': 848,\n",
       " 'V3201': 1784,\n",
       " '942': 849,\n",
       " 'E9314': 850,\n",
       " '21': 851,\n",
       " 'V1507': 852,\n",
       " '370': 853,\n",
       " '618': 1356,\n",
       " '219': 855,\n",
       " 'V4512': 856,\n",
       " '987': 857,\n",
       " '557': 1362,\n",
       " 'V1542': 859,\n",
       " '15': 1593,\n",
       " 'E9068': 860,\n",
       " '383': 861,\n",
       " '906': 862,\n",
       " 'V155': 484,\n",
       " 'E9190': 864,\n",
       " 'E9499': 927,\n",
       " '730': 1758,\n",
       " 'V6282': 866,\n",
       " 'E8041': 868,\n",
       " 'E912': 869,\n",
       " 'V8542': 870,\n",
       " '423': 871,\n",
       " 'V065': 872,\n",
       " '728': 873,\n",
       " '909': 874,\n",
       " 'E9394': 875,\n",
       " 'E0060': 876,\n",
       " 'V707': 877,\n",
       " 'V0981': 1450,\n",
       " '759': 1071,\n",
       " '289': 835,\n",
       " '125': 880,\n",
       " 'E9304': 882,\n",
       " 'V146': 883,\n",
       " '291': 959,\n",
       " 'E8839': 885,\n",
       " 'E9352': 1376,\n",
       " 'E9295': 896,\n",
       " '272': 889,\n",
       " '521': 890,\n",
       " '556': 891,\n",
       " 'V1022': 892,\n",
       " 'V1084': 893,\n",
       " '381': 894,\n",
       " '239': 895,\n",
       " 'E970': 897,\n",
       " 'V2652': 898,\n",
       " '903': 1012,\n",
       " '127': 900,\n",
       " 'V8538': 901,\n",
       " '964': 1586,\n",
       " '451': 902,\n",
       " 'E0299': 903,\n",
       " 'E8585': 904,\n",
       " '287': 1380,\n",
       " '394': 906,\n",
       " 'E9354': 907,\n",
       " '259': 908,\n",
       " '596': 909,\n",
       " '184': 910,\n",
       " '477': 911,\n",
       " 'cat:8': 777,\n",
       " '744': 913,\n",
       " '852': 914,\n",
       " 'E8654': 915,\n",
       " '997': 1077,\n",
       " '174': 1385,\n",
       " 'V1559': 918,\n",
       " '774': 919,\n",
       " 'E8705': 920,\n",
       " 'E8718': 921,\n",
       " '151': 922,\n",
       " 'V181': 923,\n",
       " '874': 924,\n",
       " 'E9193': 925,\n",
       " 'V4579': 926,\n",
       " 'V192': 928,\n",
       " '681': 929,\n",
       " '598': 930,\n",
       " '615': 147,\n",
       " 'E9809': 932,\n",
       " '684': 933,\n",
       " 'V4501': 1782,\n",
       " 'E8844': 934,\n",
       " '789': 935,\n",
       " '661': 936,\n",
       " 'V1000': 25,\n",
       " '319': 938,\n",
       " '701': 36,\n",
       " 'E9363': 940,\n",
       " 'E0011': 941,\n",
       " '960': 942,\n",
       " '209': 61,\n",
       " 'E9670': 761,\n",
       " 'cat:18': 657,\n",
       " 'E888': 945,\n",
       " 'V4962': 89,\n",
       " '882': 947,\n",
       " 'V5867': 948,\n",
       " 'V655': 949,\n",
       " '410': 950,\n",
       " '45': 951,\n",
       " 'V1051': 952,\n",
       " 'E8062': 953,\n",
       " 'V5413': 129,\n",
       " 'V1082': 834,\n",
       " '648': 956,\n",
       " '890': 957,\n",
       " 'V1389': 958,\n",
       " '867': 960,\n",
       " 'V011': 961,\n",
       " '691': 1754,\n",
       " '296': 166,\n",
       " '762': 963,\n",
       " 'E9303': 964,\n",
       " '389': 207,\n",
       " '141': 966,\n",
       " 'V188': 967,\n",
       " '569': 968,\n",
       " '516': 969,\n",
       " '749': 970,\n",
       " '220': 971,\n",
       " 'E0071': 972,\n",
       " 'V5849': 973,\n",
       " '85': 974,\n",
       " 'V443': 975,\n",
       " 'E8709': 976,\n",
       " '726': 272,\n",
       " 'E8227': 978,\n",
       " 'cat:17': 283,\n",
       " 'E8655': 981,\n",
       " '211': 983,\n",
       " '290': 789,\n",
       " 'E9397': 987,\n",
       " 'V9089': 988,\n",
       " 'E9174': 989,\n",
       " 'V0482': 990,\n",
       " '751': 991,\n",
       " 'V8523': 1463,\n",
       " '193': 992,\n",
       " 'V143': 994,\n",
       " 'E9205': 995,\n",
       " 'E8494': 996,\n",
       " 'E918': 997,\n",
       " 'E8190': 1602,\n",
       " 'E9438': 999,\n",
       " '763': 1000,\n",
       " '490': 1001,\n",
       " 'E8219': 1002,\n",
       " '32': 1003,\n",
       " 'V468': 444,\n",
       " 'E0061': 1005,\n",
       " 'V4966': 1006,\n",
       " 'V1069': 1007,\n",
       " 'E8600': 1741,\n",
       " '703': 1008,\n",
       " 'E963': 1009,\n",
       " '143': 1010,\n",
       " 'V632': 1011,\n",
       " '292': 1827,\n",
       " '415': 695,\n",
       " ...}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.icdDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
