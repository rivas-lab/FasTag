{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training DT, RF on your Data\n",
    "This notebook will take you through the steps necessary to train Decision Tree (DT) and Random Forest (RF) classifiers to recognize ICD-9 codes, or items from similar dictionaries, from free text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Definitions\n",
    "Make sure that the below packages are installed on the server on which this program will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBestModelStatistics(gridCV, scoring, modelName):\n",
    "    \"\"\"\n",
    "    Description: Prints information about the model specified in modelName.\n",
    "    Input:\n",
    "        gridCV (dict): A dictionary returned by sklearn's GridSearchCV function.\n",
    "        scoring (list): A list of metrics in gridCV which are to be printed\n",
    "        modelName (str): Name of model to be printed.\n",
    "    Output:\n",
    "        None: Results are printed.\n",
    "    TODO:\n",
    "    \"\"\"\n",
    "    scoringDict = {}\n",
    "    bestModelIndex = gridCV.best_index_\n",
    "    for score in scoring:\n",
    "        scoringDict[score] = gridCV.cv_results_[\"mean_test_\" + score][bestModelIndex]\n",
    "        outStr = \"For Model {}:\".format(modelName)\n",
    "    for scoreName, scoreVal in scoringDict.items():\n",
    "        outStr += \"\\n\\t{}: {}\".format(scoreName, np.round(scoreVal, decimals = 3))\n",
    "    print(outStr)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Change the dataPrefix variable below to run this on different datasets. It does expect that there is a separate train and validation file with similarly formatted column names (input = `\"TEXT\"`, labels = `\"V9\"`), so make sure of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n train: 39541\n",
      "n Val: 13181\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# dataPrefix = 'data/mimic_0815'\n",
    "dataPrefix = 'data/mimic_mm_reps_0815'\n",
    "# dataPrefix = 'data/csu_mm_reps_nodiag_no17_0815'\n",
    "# dataPrefix = 'data/csu_nodiag_no17_0815'\n",
    "nRows = None\n",
    "df = pd.read_csv(dataPrefix + \"_train.csv\", usecols = [\"TEXT\", \"V9\"], nrows = nRows)\n",
    "nTrain = df.shape[0]\n",
    "df = pd.concat([df, pd.read_csv(dataPrefix + \"_valid.csv\", usecols = [\"TEXT\", \"V9\"], nrows = nRows)])\n",
    "nVal = df.shape[0] - nTrain\n",
    "Y_temp = [x.split(\"-\") for x in df.V9]\n",
    "Y = []\n",
    "for sublist in Y_temp:\n",
    "    categories = [cat.split(\":\")[-1] for cat in sublist]\n",
    "    Y.append(categories)\n",
    "Y = MultiLabelBinarizer().fit_transform(Y)\n",
    "print(\"n train: {}\\nn Val: {}\".format(nTrain, nVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Model\n",
    "\n",
    "The below code declares the necessary parameters needed to train the models above over a grid of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDict = {}\n",
    "cv = lambda: zip([np.arange(nTrain)], [np.arange(nTrain, nTrain + nVal)])\n",
    "n_jobs = 2\n",
    "verbose = 1\n",
    "\n",
    "scoring = [\"f1_micro\", \"f1_macro\", \"f1_weighted\", \"precision_samples\", \"recall_samples\"]\n",
    "importantMetric = \"f1_weighted\"\n",
    "# scoring = None#[\"f1\",\"precision\", \"recall\"]\n",
    "# importantMetric = None#\"f1\"\n",
    "\n",
    "max_df = (0.5, 0.75, 0.95)\n",
    "tf_idf_norm = ('l1', 'l2')\n",
    "myCountVectorizer = ('vect', CountVectorizer(stop_words = 'english', min_df = 0.05))\n",
    "myTfidfTransformer = ('tfidf', TfidfTransformer(norm = 'l2',  use_idf = True))\n",
    "\n",
    "# Decision Tree Classifier\n",
    "\n",
    "estimators_DT = []\n",
    "estimators_DT.append(myCountVectorizer)\n",
    "estimators_DT.append(myTfidfTransformer)\n",
    "estimators_DT.append(('DT', DecisionTreeClassifier()))\n",
    "paramGrid_DT = [\n",
    "    {\n",
    "        'vect__max_df': max_df,\n",
    "#         'vect__max_features': (5000, 10000),\n",
    "#         'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "        # 'tfidf__use_idf': (True, False),\n",
    "        'tfidf__norm': tf_idf_norm,\n",
    "        \"DT__max_features\": [\"sqrt\", \"log2\", 0.5],# we have lots of possibly extraneous\n",
    "        # features so it might be good to use lower numbers here\n",
    "        \"DT__max_depth\": [None],# still need to understand if deeper trees are better.\n",
    "        \"DT__criterion\":[\"gini\"],\n",
    "    }\n",
    "]\n",
    "modelDict[\"DT\"] = {\"pipe\": Pipeline(estimators_DT),\n",
    "                             \"params\": paramGrid_DT}\n",
    "modelDict[\"DT\"][\"gridcv\"] = GridSearchCV(estimator = modelDict[\"DT\"][\"pipe\"],\n",
    "                       param_grid = modelDict[\"DT\"][\"params\"],\n",
    "                       cv = cv(), \n",
    "                       n_jobs = n_jobs, return_train_score = False,\n",
    "                       scoring = scoring, refit = importantMetric, verbose = verbose)\n",
    "\n",
    "# Random Forest Classifier\n",
    "estimators_RF = []\n",
    "estimators_RF.append(myCountVectorizer)\n",
    "estimators_RF.append(myTfidfTransformer)\n",
    "estimators_RF.append(('RFC', RandomForestClassifier()))\n",
    "paramGrid_RF = [\n",
    "    {\n",
    "        'vect__max_df': max_df,\n",
    "        'tfidf__norm': tf_idf_norm,\n",
    "        \"RFC__n_estimators\": [5, 10],# second most important feature to tune. First\n",
    "        # is max number of feats.\n",
    "        \"RFC__max_features\": [\"sqrt\", \"log2\", 0.5],# we have lots of possibly extraneous\n",
    "        # features so it might be good to use lower numbers here\n",
    "        \"RFC__max_depth\": [None],# still need to understand if deeper trees are better.\n",
    "        \"RFC__criterion\":[\"gini\"],\n",
    "    }\n",
    "]\n",
    "modelDict[\"RFC\"] = {\"pipe\": Pipeline(estimators_RF),\n",
    "                             \"params\": paramGrid_RF}\n",
    "modelDict[\"RFC\"][\"gridcv\"] = GridSearchCV(estimator = modelDict[\"RFC\"][\"pipe\"],\n",
    "                       param_grid = modelDict[\"RFC\"][\"params\"],\n",
    "                       cv = cv(), \n",
    "                       n_jobs = n_jobs, return_train_score = False,\n",
    "                       scoring = scoring, refit = importantMetric, verbose = verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "The below trains the models and prints the best classification performances and parameters over the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DT\n",
      "Fitting 1 folds for each of 18 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed: 32.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Model DT:\n",
      "\tf1_micro: 0.617\n",
      "\tf1_macro: 0.488\n",
      "\tf1_weighted: 0.615\n",
      "\tprecision_samples: 0.638\n",
      "\trecall_samples: 0.607\n",
      "Best Model Parameters {'DT__criterion': 'gini', 'DT__max_depth': None, 'DT__max_features': 0.5, 'tfidf__norm': 'l1', 'vect__max_df': 0.5}\n",
      "****************************************************************************************************\n",
      "Training RFC\n",
      "Fitting 1 folds for each of 36 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  36 out of  36 | elapsed: 146.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Model RFC:\n",
      "\tf1_micro: 0.671\n",
      "\tf1_macro: 0.509\n",
      "\tf1_weighted: 0.644\n",
      "\tprecision_samples: 0.731\n",
      "\trecall_samples: 0.627\n",
      "Best Model Parameters {'RFC__criterion': 'gini', 'RFC__max_depth': None, 'RFC__max_features': 0.5, 'RFC__n_estimators': 5, 'tfidf__norm': 'l2', 'vect__max_df': 0.5}\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for modelName, currModelDict in modelDict.items():\n",
    "    print(\"Training {}\".format(modelName))\n",
    "    currModelDict[\"gridcv\"].fit(df.TEXT.values, Y)\n",
    "    printBestModelStatistics(gridCV = currModelDict[\"gridcv\"],\n",
    "                         scoring = scoring, modelName = modelName)\n",
    "    currModelDict[\"refitMetric\"] = importantMetric\n",
    "    print(\"Best Model Parameters {}\".format(currModelDict[\"gridcv\"].best_params_))\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output\n",
    "\n",
    "The below saves the model performance data to a pickled Python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataPrefix + \"modelPerformance.pkl\", \"wb\") as pickleFile:\n",
    "    pickle.dump(modelDict, pickleFile, protocol= 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
