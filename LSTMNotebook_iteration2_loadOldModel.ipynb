{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# So code is automatically reloaded when saved in different modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from scipy import stats\n",
    "import tensorflow as tf\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import sklearn.metrics\n",
    "from sklearn import metrics\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import sys\n",
    "import pprint\n",
    "sys.path.append('src/taggerSystem/')\n",
    "from data_util import load_and_preprocess_data, load_embeddings, ModelHelper, lastTrueWordIdxs\n",
    "logger = logging.getLogger(\"hw3.q2\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_train = \"data/icd9NotesDataTable_train.csv\"\n",
    "# data_valid = \"data/icd9NotesDataTable_valid.csv\"\n",
    "# data_train = \"data/smallIcd9NotesDataTable_train.csv\"\n",
    "# data_valid = \"data/smallIcd9NotesDataTable_valid.csv\"\n",
    "data_train = \"data/smallIcd9NotesDataTable_train_2.csv\"\n",
    "data_valid = \"data/smallIcd9NotesDataTable_train_2.csv\"\n",
    "vocab = \"src/taggerSystem/data_hw3_delete/vocab.txt\"\n",
    "wordVecs = \"src/taggerSystem/data_hw3_delete/wordVectors.txt\"\n",
    "output_path = 'results/model_description'\n",
    "# log_output = output_path + \"log\"\n",
    "# vocab = 'data/icd9Vocab.txt'# vocab for our data\n",
    "# wordVecs = 'data/newgloveicd9.txt'# len 300 word vectors\n",
    "output_path = 'results/{}/{:%Y%m%d_%H%M%S}/\".format(self.cell, datetime.now())'\n",
    "log_output = output_path + \"log\"\n",
    "START_TOKEN = \"<s>\"\n",
    "END_TOKEN = \"</s>\"\n",
    "NUM = \"NNNUMMM\"\n",
    "UNK = \"UUUNKKK\"\n",
    "EMBED_SIZE = 50 # this should not be manually set and should instead come from the word\n",
    "# vectors. Or maybe it's good that we have to set it so we know for sure the size\n",
    "# of word vecs we're using\n",
    "maxAllowedNoteLength = 500\n",
    "max_grad_norm = 5\n",
    "codeIdx = 9\n",
    "textIdx = 6\n",
    "num_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where should models and performances be saved to?\n"
     ]
    }
   ],
   "source": [
    "modelRunOutputPath = input(prompt = 'Where should models and performances be saved to?')\n",
    "if modelRunOutputPath == '':\n",
    "    modelRunOutputPath = 'results/temp'\n",
    "if not os.path.exists(modelRunOutputPath):\n",
    "    os.makedirs(modelRunOutputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data and Word Embeddings\n",
    "You'll probably only need to work with xDev, yDev and xTrain, yTrain. The X matrices hold all word IDs in the order they appear in the note. yDev is a matrix of indicator vectors for icd9 presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "helper, train, dev, train_raw, dev_raw, xTrain, yTrain, xDev, yDev = load_and_preprocess_data(\n",
    "    data_train = data_train, data_valid = data_valid, \n",
    "    maxAllowedNoteLength = maxAllowedNoteLength, \n",
    "    codeIdx = codeIdx, textIdx = textIdx,\n",
    "    helperLoadPath = 'results/temp/')\n",
    "# embeddings = load_embeddings(vocab, wordVecs, helper, embeddingSize = EMBED_SIZE)\n",
    "lastTrueWordIdx_train = lastTrueWordIdxs(train)\n",
    "lastTrueWordIdx_dev = lastTrueWordIdxs(dev)\n",
    "# helper.save(output_path)# token2id and max length saved to output_path\n",
    "# handler = logging.FileHandler(log_output)\n",
    "# handler.setLevel(logging.DEBUG)\n",
    "# handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n",
    "# logging.getLogger().addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'18': 0, '456': 5, '123': 2, '4240': 1, '45': 4, '486': 3}\n",
      "{'<s>': 11, '</s>': 10, 'horse': 3, 'CASE:Aa': 8, 'UUUNKKK': 9, 'CASE:AA': 5, 'deadpool': 4, 'dog': 1, 'CASE:aA': 7, 'CASE:aa': 6, 'cat': 2, 'welcometonightvale': 9}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(helper.icdDict)\n",
    "print(helper.tok2id)\n",
    "print(helper.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'18': 0, '456': 5, '123': 2, '4240': 1, '45': 4, '486': 3}\n",
      "{'<s>': 11, '</s>': 10, 'horse': 3, 'CASE:Aa': 8, 'UUUNKKK': 9, 'CASE:AA': 5, 'deadpool': 4, 'dog': 1, 'CASE:aA': 7, 'CASE:aa': 6, 'cat': 2, 'welcometonightvale': 9}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(helper.icdDict)\n",
    "print(helper.tok2id)\n",
    "print(helper.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xDev[xDev == -1] = 0\n",
    "xTrain[xTrain == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is the loss\n",
      "0.955575\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(modelRunOutputPath, 'runOutput.txt'), 'w') as f:\n",
    "    with tf.Session() as session:\n",
    "        new_saver = tf.train.import_meta_graph('results/temp/bestModel.meta')\n",
    "        new_saver.restore(session, tf.train.latest_checkpoint('results/temp/'))\n",
    "        x = tf.get_collection('x')[0]\n",
    "        trueWordIdxs = tf.get_collection('trueWordIdxs')[0]\n",
    "        outputKeepProb = tf.get_collection('outputKeepProb')[0]\n",
    "        inputKeepProb = tf.get_collection('inputKeepProb')[0]\n",
    "        pretrainedEmbeddings = tf.get_collection('pretrainedEmbeddings')[0]\n",
    "        y_last = tf.get_collection('y_last')[0]\n",
    "        batchSizeDev = 3295\n",
    "        totalBatchesDev = (xDev.shape[0]//batchSizeDev)\n",
    "        pred_y = np.full(shape = yDev.shape, fill_value = -1.0, dtype = np.float32)\n",
    "        for b in range(totalBatchesDev + 1):\n",
    "#                 print(b)\n",
    "            offset = min((b * batchSizeDev), yDev.shape[0])\n",
    "            devBatch_x = xDev[offset:(offset + batchSizeDev), :]\n",
    "            devBatchTrueWordIdxs = lastTrueWordIdx_dev[offset:(offset + batchSizeDev)]\n",
    "            pred_yBatch = session.run(y_last,feed_dict={x: devBatch_x,\n",
    "                                                  trueWordIdxs:devBatchTrueWordIdxs,\n",
    "                                                  outputKeepProb: 1,\n",
    "                                                    inputKeepProb: 1}, ) # must be set to one for predictions.\n",
    "            pred_y[offset:(offset + batchSizeDev), :] = pred_yBatch\n",
    "        if (pred_y == -1).all():\n",
    "            print('negative values exist. This means indexing is off in pred_yBatch')\n",
    "            1/0\n",
    "        validLoss = tf.nn.sigmoid_cross_entropy_with_logits(logits = pred_y, \n",
    "                                             labels = tf.cast(yDev, tf.float32))\n",
    "        validLoss = tf.reduce_mean(validLoss)\n",
    "        validLoss = validLoss.eval()\n",
    "        print('here is the loss')\n",
    "        print(validLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'18': 0, '456': 5, '123': 2, '4240': 1, '45': 4, '486': 3}\n",
      "{'<s>': 11, '</s>': 10, 'horse': 3, 'CASE:Aa': 8, 'UUUNKKK': 9, 'CASE:AA': 5, 'deadpool': 4, 'dog': 1, 'CASE:aA': 7, 'CASE:aa': 6, 'cat': 2, 'welcometonightvale': 9}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(helper.icdDict)\n",
    "print(helper.tok2id)\n",
    "print(helper.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yDev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
