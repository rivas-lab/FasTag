{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# So code is automatically reloaded when saved in different modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from scipy import stats\n",
    "import tensorflow as tf\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import sklearn.metrics\n",
    "from sklearn import metrics\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import sys\n",
    "import pprint\n",
    "sys.path.append('src/taggerSystem/')\n",
    "from my_data_util_2 import load_and_preprocess_data, load_embeddings, ModelHelper, lastTrueWordIdxs\n",
    "logger = logging.getLogger(\"hw3.q2\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_train = \"data/icd9NotesDataTable_train.csv\"\n",
    "# data_valid = \"data/icd9NotesDataTable_valid.csv\"\n",
    "data_train = \"data/smallIcd9NotesDataTable_train.csv\"\n",
    "# data_train = \"data/smallIcd9NotesDataTable_train_2.csv\"\n",
    "data_valid = \"data/smallIcd9NotesDataTable_valid.csv\"\n",
    "# vocab = 'data/icd9Vocab.txt'# vocab for our data\n",
    "# wordVecs = 'data/newgloveicd9.txt'# len 300 word vectors\n",
    "vocab = \"src/taggerSystem/data_hw3_delete/vocab.txt\"\n",
    "wordVecs = \"src/taggerSystem/data_hw3_delete/wordVectors.txt\"\n",
    "START_TOKEN = \"<s>\"\n",
    "END_TOKEN = \"</s>\"\n",
    "NUM = \"NNNUMMM\"\n",
    "UNK = \"UUUNKKK\"\n",
    "EMBED_SIZE = 50\n",
    "maxAllowedNoteLength = 3\n",
    "codeIdx = 9\n",
    "textIdx = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ICDCODELIST = []\n",
    "ICDCODEDICT = {}# this allows us to map codes to integer values.\n",
    "helper, train, dev, train_raw, dev_raw, xTrain, yTrain, xDev, yDev = load_and_preprocess_data(\n",
    "    data_train = data_train, data_valid = data_valid, \n",
    "    maxAllowedNoteLength = maxAllowedNoteLength, \n",
    "    codeIdx = codeIdx, textIdx = textIdx,\n",
    "    helperLoadPath = None)#'results/temp/features.pkl')\n",
    "outputPath = 'results/temp/'\n",
    "embeddings = load_embeddings(vocab, wordVecs, helper, embeddingSize = EMBED_SIZE)\n",
    "lastTrueWordIdx_train = lastTrueWordIdxs(train)\n",
    "lastTrueWordIdx_dev = lastTrueWordIdxs(dev)\n",
    "# helper.save(outputPath)# token2id and max length saved to output_path\n",
    "# with open(os.path.join(outputPath, \"icdMapping.pkl\"), \"wb\") as f:\n",
    "#     pickle.dump(helper.icdDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4240': 5, '456': 0, '45': 1, '123': 3, '486': 4, '18': 2}\n",
      "{'cat': 2, 'horse': 3, 'CASE:aa': 5, 'CASE:aA': 8, 'deadpool': 4, '</s>': 9, 'CASE:Aa': 6, 'dog': 1, 'CASE:AA': 7, 'the': 5, 'UUUNKKK': 10, '<s>': 11}\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(helper.icdDict)\n",
    "print(helper.tok2id)\n",
    "print(helper.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.49164701,  0.614438  , -0.149609  , -0.285045  ],\n",
       "       [-0.780038  ,  0.430511  , -0.208709  , -0.55492598],\n",
       "       [ 0.032049  , -0.34206101, -0.74521202, -0.88928097],\n",
       "       [ 0.004422  ,  0.006439  , -0.004394  ,  0.009065  ],\n",
       "       [ 1.00277305, -1.406829  , -0.016482  ,  0.459856  ],\n",
       "       [ 0.82947177, -0.34992629,  0.72440302,  1.19216001],\n",
       "       [ 0.48994979,  1.22273219,  1.38936615, -0.2411315 ],\n",
       "       [-2.26171994, -0.04729586, -0.02004942,  0.39720514],\n",
       "       [ 2.02874303, -2.45117092,  0.355793  , -0.85604501],\n",
       "       [ 0.81293803,  0.66100264,  1.65423679,  1.18584061],\n",
       "       [-0.236247  , -0.65228099,  0.40685201,  0.84960198],\n",
       "       [ 0.5996834 , -0.28633684, -1.08432508, -1.70849454]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[:,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "helper, train, dev, train_raw, dev_raw, xTrain, yTrain, xDev, yDev = load_and_preprocess_data(\n",
    "    data_train = \"data/smallIcd9NotesDataTable_train_2.csv\", data_valid = data_valid, \n",
    "    maxAllowedNoteLength = maxAllowedNoteLength, \n",
    "    codeIdx = codeIdx, textIdx = textIdx,\n",
    "    helperLoadPath = 'results/temp/')\n",
    "outputPath = 'results/temp/'\n",
    "embeddings = load_embeddings(vocab, wordVecs, helper, embeddingSize = EMBED_SIZE)\n",
    "lastTrueWordIdx_train = lastTrueWordIdxs(train)\n",
    "lastTrueWordIdx_dev = lastTrueWordIdxs(dev)\n",
    "# helper.save(outputPath)# token2id and max length saved to output_path\n",
    "# with open(os.path.join(outputPath, \"icdMapping.pkl\"), \"wb\") as f:\n",
    "#     pickle.dump(helper.icdDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'456': 2, '45': 0, '18': 1, '123': 5, '486': 4, '4240': 3}\n",
      "{'cat': 2, 'horse': 3, 'CASE:aa': 5, 'welcometonightvale': 10, 'deadpool': 4, '</s>': 11, 'CASE:Aa': 8, 'dog': 1, 'CASE:AA': 6, 'UUUNKKK': 10, '<s>': 9, 'CASE:aA': 7}\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(helper.icdDict)\n",
    "print(helper.tok2id)\n",
    "print(helper.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['dog', 'dog'], ['']),\n",
       " (['deadpool', 'welcomeToNightVale'], ['']),\n",
       " (['deadpool', 'deadpool'], ['']),\n",
       " (['cat', 'dog', 'horse'], ['']),\n",
       " (['horse'], ['']),\n",
       " (['dog', 'dog', 'dog', 'dog'], ['']),\n",
       " (['dog', 'dog', 'dog', 'cat'], [''])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[1, 5], [1, 5]], array([ 0.,  0.,  0.,  0.,  0.,  0.])),\n",
       " ([[4, 5], [10, 7]], array([ 0.,  0.,  0.,  0.,  0.,  0.])),\n",
       " ([[4, 5], [4, 5]], array([ 0.,  0.,  0.,  0.,  0.,  0.])),\n",
       " ([[2, 5], [1, 5], [3, 5]], array([ 0.,  0.,  0.,  0.,  0.,  0.])),\n",
       " ([[3, 5]], array([ 0.,  0.,  0.,  0.,  0.,  0.])),\n",
       " ([[1, 5], [1, 5], [1, 5]], array([ 0.,  0.,  0.,  0.,  0.,  0.])),\n",
       " ([[1, 5], [1, 5], [1, 5]], array([ 0.,  0.,  0.,  0.,  0.,  0.]))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.18571389  0.13177936 -0.98973244  0.38124523]\n",
      "[ 0.004422  0.006439 -0.004394  0.009065]\n",
      "[-1.18571389  0.13177936 -0.98973244  0.38124523]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings[helper.tok2id['welcometonightvale'], 1:5])\n",
    "print(embeddings[helper.tok2id['deadpool'], 1:5])\n",
    "print(embeddings[helper.tok2id['UUUNKKK'], 1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['the', 'dog', 'dog', 'horse'], ['4240', '486']),\n",
       " (['cat', 'cat', 'cat', 'horse'], ['4240', '486', '123', '45', '18']),\n",
       " (['deadpool', 'deadpool'], ['4240']),\n",
       " (['cat', 'dog', 'horse'], ['486']),\n",
       " (['horse'], ['123', '456']),\n",
       " (['dog', 'dog', 'dog', 'dog'], ['4240', '486']),\n",
       " (['dog', 'dog', 'dog', 'cat'], ['4240', '486'])]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'</s>': 11,\n",
       " '<s>': 9,\n",
       " 'CASE:AA': 6,\n",
       " 'CASE:Aa': 8,\n",
       " 'CASE:aA': 7,\n",
       " 'CASE:aa': 5,\n",
       " 'UUUNKKK': 10,\n",
       " 'cat': 3,\n",
       " 'deadpool': 2,\n",
       " 'dog': 1,\n",
       " 'horse': 4,\n",
       " 'welcometonightvale': 5}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.tok2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'</s>': 11,\n",
       " '<s>': 9,\n",
       " 'CASE:AA': 6,\n",
       " 'CASE:Aa': 8,\n",
       " 'CASE:aA': 7,\n",
       " 'CASE:aa': 5,\n",
       " 'UUUNKKK': 10,\n",
       " 'cat': 2,\n",
       " 'deadpool': 4,\n",
       " 'dog': 1,\n",
       " 'horse': 3,\n",
       " 'the': 5}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.tok2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'123': 5, '18': 1, '4240': 3, '45': 0, '456': 2, '486': 4}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.icdDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'123': 5, '18': 1, '4240': 3, '45': 0, '456': 2, '486': 4}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.icdDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from scipy import stats\n",
    "import tensorflow as tf\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import sklearn.metrics\n",
    "from sklearn import metrics\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph('tempDelete/bestModel.meta')\n",
    "\n",
    "# We can now access the default graph where all our metadata has been loaded\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# Finally we can retrieve tensors, operations, collections, etc.\n",
    "# returns tensors with these given namres\n",
    "# global_step_tensor = graph.get_tensor_by_name('loss/global_step:0')\n",
    "# train_op = graph.get_operation_by_name('loss/train_op')\n",
    "# hyperparameters = tf.get_collection('hyperparameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7f79c00dc080>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'loss_function' refers to an Operation not in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f079756f9efe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# global_step_tensor = graph.get_tensor_by_name('loss/global_step:0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_operation_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hyperparameters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_operation_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2599\u001b[0m       raise TypeError(\"Operation names are strings (or similar), not %s.\"\n\u001b[1;32m   2600\u001b[0m                       % type(name).__name__)\n\u001b[0;32m-> 2601\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m           raise KeyError(\"The name %s refers to an Operation not in the \"\n\u001b[0;32m-> 2533\u001b[0;31m                          \"graph.\" % repr(name))\n\u001b[0m\u001b[1;32m   2534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'loss_function' refers to an Operation not in the graph.\""
     ]
    }
   ],
   "source": [
    "# global_step_tensor = graph.get_tensor_by_name('loss/global_step:0')\n",
    "# train_op = graph.get_operation_by_name('loss_function')\n",
    "# hyperparameters = tf.get_collection('hyperparameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DataLossError",
     "evalue": "Unable to open table file tempDelete/bestModel.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_3/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_3/Const_0, save_3/RestoreV2/tensor_names, save_3/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_3/RestoreV2', defined at:\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-1e1b03d2d2ec>\", line 1, in <module>\n    saver = tf.train.import_meta_graph('tempDelete/bestModel.meta')\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1577, in import_meta_graph\n    **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 498, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 287, in import_graph_def\n    op_def=op_def)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nDataLossError (see above for traceback): Unable to open table file tempDelete/bestModel.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_3/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_3/Const_0, save_3/RestoreV2/tensor_names, save_3/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: Unable to open table file tempDelete/bestModel.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_3/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_3/Const_0, save_3/RestoreV2/tensor_names, save_3/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4ec09b7287f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# To initialize values with saved data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tempDelete/bestModel.data-00000-of-00001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# returns 1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1437\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1439\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: Unable to open table file tempDelete/bestModel.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_3/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_3/Const_0, save_3/RestoreV2/tensor_names, save_3/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_3/RestoreV2', defined at:\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-1e1b03d2d2ec>\", line 1, in <module>\n    saver = tf.train.import_meta_graph('tempDelete/bestModel.meta')\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1577, in import_meta_graph\n    **kwargs)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py\", line 498, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/importer.py\", line 287, in import_graph_def\n    op_def=op_def)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/oliver/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nDataLossError (see above for traceback): Unable to open table file tempDelete/bestModel.data-00000-of-00001: Data loss: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?\n\t [[Node: save_3/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_3/Const_0, save_3/RestoreV2/tensor_names, save_3/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # To initialize values with saved data\n",
    "    saver.restore(sess, 'tempDelete/bestModel.data-00000-of-00001')\n",
    "    print(sess.run(global_step_tensor)) # returns 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'RNN_OutsideCell/Add:0' shape=(?, 6) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     new_saver = tf.train.import_meta_graph('my-save-dir/my-model-10000.meta')\n",
    "#     new_saver.restore(sess, 'my-save-dir/my-model-10000')\n",
    "    new_saver = tf.train.import_meta_graph('tempDelete/bestModel-2.meta')\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('tempDelete/'))\n",
    "    y_last = tf.get_collection('y_last')\n",
    "    print(y_last)\n",
    "#     for v in y_last:\n",
    "#         print('hello')\n",
    "#         v_ = sess.run(v)\n",
    "#         print(v_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
