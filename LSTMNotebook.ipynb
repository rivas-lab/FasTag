{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# So code is automatically reloaded when saved in different modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import sys\n",
    "import pprint\n",
    "sys.path.append('src/taggerSystem/')\n",
    "from my_util import print_sentence, write_conll, read_conll\n",
    "from my_data_util import load_and_preprocess_data, load_embeddings, ModelHelper\n",
    "logger = logging.getLogger(\"hw3.q2\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_train = \"data/icd9NotesDataTable_train.csv\"\n",
    "# data_valid = \"data/icd9NotesDataTable_valid.csv\"\n",
    "data_train = \"data/smallIcd9NotesDataTable_train.csv\"\n",
    "data_valid = \"data/smallIcd9NotesDataTable_valid.csv\"\n",
    "vocab = \"src/taggerSystem/data_hw3_delete/vocab.txt\"\n",
    "wordVecs = \"src/taggerSystem/data_hw3_delete/wordVectors.txt\"\n",
    "output_path = 'results/{}/{:%Y%m%d_%H%M%S}/\".format(self.cell, datetime.now())'\n",
    "log_output = output_path + \"log\"\n",
    "START_TOKEN = \"<s>\"\n",
    "END_TOKEN = \"</s>\"\n",
    "NUM = \"NNNUMMM\"\n",
    "UNK = \"UUUNKKK\"\n",
    "EMBED_SIZE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data and Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading training data...\n",
      "INFO:Done. Read 7 notes\n",
      "INFO:Loading dev data...\n",
      "INFO:Done. Read 7 notes\n",
      "INFO:Total read time 0.007526\n",
      "INFO:Built dictionary for 11 features.\n",
      "INFO:There are a total of 6 ICD codes\n",
      "INFO:Initialized embeddings.\n"
     ]
    }
   ],
   "source": [
    "helper, train, dev, train_raw, dev_raw, xTrain, yTrain, xDev, yDev = load_and_preprocess_data(\n",
    "    data_train = data_train, data_valid = data_valid)\n",
    "# print('dev raw')\n",
    "# print(dev_raw)\n",
    "# print('dev')\n",
    "# print(dev)\n",
    "embeddings = load_embeddings(vocab, wordVecs, helper)\n",
    "helper.save(output_path)# token2id and max length saved to output_path\n",
    "handler = logging.FileHandler(log_output)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n",
    "logging.getLogger().addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('results/yDev.npy',yDev)\n",
    "np.save('results/xDev.npy', xDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max note length 4\n",
      "Number of Icd9 codes 6\n",
      "icd9 present\n",
      "{'123': 5, '18': 4, '4240': 0, '45': 2, '456': 1, '486': 3}\n"
     ]
    }
   ],
   "source": [
    "print('Max note length %d'%(helper.max_length))\n",
    "print('Number of Icd9 codes %d'%(helper.n_labels))\n",
    "print('icd9 present')\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(helper.icdDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 256\n",
    "total_batches = (xTrain.shape[0]//batch_size)\n",
    "\n",
    "n_input = 1\n",
    "n_steps = 10\n",
    "n_hidden = 30\n",
    "n_classes = helper.n_labels\n",
    "n_features = 1\n",
    "\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39544, 1500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39544, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x = tf.placeholder(tf.int32, shape= (None, helper.max_length, n_features))\n",
    "x = tf.placeholder(tf.int32, shape= (None, helper.max_length))\n",
    "yTruth = tf.placeholder(tf.int32, shape = (None, helper.n_labels))\n",
    "y_steps = tf.placeholder(tf.int32, shape = (None, helper.n_labels))# not sure what this is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def LSTM(x, weight, bias):\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(n_hidden,state_is_tuple = True)\n",
    "    print(type(cell))\n",
    "    print(cell)\n",
    "    print(type(x))\n",
    "    print(x.get_shape())\n",
    "    print('cell output size')\n",
    "    print(cell.output_size)\n",
    "    print('cell state size')\n",
    "    print(cell.state_size)\n",
    "#     1/0\n",
    "#     print('cell size')\n",
    "#     print(cell.get_shape())\n",
    "#     1/0\n",
    "#     multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell([cell] * 2)\n",
    "\n",
    "    output, state = tf.nn.dynamic_rnn(cell = cell, inputs = x, dtype = tf.float32)\n",
    "    print('output shape')\n",
    "    print(output.get_shape())\n",
    "#     print(tf.transpose(output,[1,0,2]).get_shape())\n",
    "#     temp = tf.gather(tf.transpose(output,[1,0,2]), helper.max_length-1) \n",
    "#     print('temp shape')\n",
    "#     print(temp.get_shape())\n",
    "#     1/0\n",
    "#     output_flattened = tf.reshape(output, [-1, n_hidden])\n",
    "    output_flattened = tf.gather(tf.transpose(output,[1,0,2]), helper.max_length - 1)\n",
    "    print('output flattened shape')\n",
    "    print(output_flattened.get_shape())\n",
    "    output_logits = tf.add(tf.matmul(output_flattened,weight),bias)\n",
    "    # TODO here is where you're gonna have to change some stuff. You're\n",
    "    # running out of memory with this run. It'd be best to not multiply\n",
    "    # and get all predictions since we really only need last one\n",
    "\n",
    "#     output_all = tf.nn.sigmoid(output_logits)\n",
    "    print('output wx + b')\n",
    "    print(output_logits.get_shape())\n",
    "#     1/0\n",
    "#     output_reshaped = tf.reshape(output_logits,[-1,n_steps,n_classes])\n",
    "#     output_reshaped = tf.reshape(output_logits,[-1,helper.max_length,n_classes])\n",
    "#     print('reshaped shape')\n",
    "#     print(output_reshaped.get_shape())\n",
    "#     output_last = tf.gather(tf.transpose(output_reshaped,[1,0,2]), helper.max_length - 1)\n",
    "    output_last = output_logits\n",
    "    print('output last shape')\n",
    "    print(output_last.get_shape())\n",
    "    #Here is where you wanna get the last one. \n",
    "    #output = tf.transpose(output, [1, 0, 2])\n",
    "    #last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "    #output_last = tf.nn.sigmoid(tf.matmul(last, weight) + bias)\n",
    "    return output_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1500, 50)\n",
      "shape of embeddings\n",
      "(?, 1500, 50)\n",
      "U shape\n",
      "(30, 20)\n",
      "bias shape\n",
      "(20,)\n",
      "<class 'tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell'>\n",
      "<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fccea6cee80>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 1500, 50)\n",
      "cell output size\n",
      "30\n",
      "cell state size\n",
      "LSTMStateTuple(c=30, h=30)\n",
      "output shape\n",
      "(?, 1500, 30)\n",
      "output flattened shape\n",
      "(?, 30)\n",
      "output wx + b\n",
      "(?, 20)\n",
      "output last shape\n",
      "(?, 20)\n"
     ]
    }
   ],
   "source": [
    "# weight = weight_variable([n_hidden,n_classes])\n",
    "with tf.variable_scope('RNN_OutsideCell', reuse = False) as scope:\n",
    "    U = tf.get_variable(name = 'U', shape = (n_hidden, n_classes), \n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "    bias = tf.get_variable(name = 'bias', shape = [n_classes], \n",
    "                           initializer = tf.constant_initializer(0))\n",
    "    # bias = bias_variable([n_classes])\n",
    "    pretrainedEmbeddings = tf.Variable(embeddings)\n",
    "    wordEmbeddings = tf.nn.embedding_lookup(params = pretrainedEmbeddings, ids = x)\n",
    "    print(wordEmbeddings.get_shape())\n",
    "#     wordEmbeddings = tf.reshape(wordEmbeddings, \n",
    "#                                 shape = tf.stack([-1, wordEmbeddings.get_shape()[1], wordEmbeddings.get_shape()[2]*wordEmbeddings.get_shape()[3]])) \n",
    "    print('shape of embeddings')\n",
    "    print(wordEmbeddings.get_shape())\n",
    "    print('U shape')\n",
    "    print(U.get_shape())\n",
    "    print('bias shape')\n",
    "    print(bias.get_shape())\n",
    "    y_last = LSTM(wordEmbeddings,U,bias)# TODO is y_last the correct thing to return?\n",
    "# adding loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandeepayyar1/anaconda3/envs/clinicalNoteTagger/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "batchError = tf.nn.sigmoid_cross_entropy_with_logits(logits = y_last, \n",
    "                                                 labels = tf.cast(yTruth, tf.float32))\n",
    "# print('yolo2')\n",
    "loss_function = tf.reduce_mean(batchError)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The paper does something weird. I'd suggest doing something closer to what we do in homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xDev[xDev == -1] = 0\n",
    "xTrain[xTrain == -1] = 0\n",
    "# hacky work around for issue where -1 is padding but now maps to UUNNNKKK vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochAvgLoss = np.zeros(training_epochs)\n",
    "epochAvgLossValid = np.zeros(training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochPredictions = np.zeros(shape = [training_epochs, yDev.shape[0], yDev.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "***************************\n",
      "Running on epoch 0\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.696267\n",
      "running iteration 25 with loss 0.607959\n",
      "running iteration 50 with loss 0.501610\n",
      "running iteration 75 with loss 0.493468\n",
      "running iteration 100 with loss 0.471040\n",
      "running iteration 125 with loss 0.460985\n",
      "running iteration 150 with loss 0.477573\n",
      "average loss 0.518536\n",
      "test loss 0.478814\n",
      "Total run time was 137.751194\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 1\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.483146\n",
      "running iteration 25 with loss 0.466070\n",
      "running iteration 50 with loss 0.456713\n",
      "running iteration 75 with loss 0.478262\n",
      "running iteration 100 with loss 0.451200\n",
      "running iteration 125 with loss 0.449805\n",
      "running iteration 150 with loss 0.448074\n",
      "average loss 0.462765\n",
      "test loss 0.473275\n",
      "Total run time was 136.885442\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 2\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.468540\n",
      "running iteration 25 with loss 0.460156\n",
      "running iteration 50 with loss 0.454077\n",
      "running iteration 75 with loss 0.476487\n",
      "running iteration 100 with loss 0.448798\n",
      "running iteration 125 with loss 0.448183\n",
      "running iteration 150 with loss 0.444263\n",
      "average loss 0.458005\n",
      "test loss 0.471232\n",
      "Total run time was 137.178198\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 3\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.467583\n",
      "running iteration 25 with loss 0.460011\n",
      "running iteration 50 with loss 0.453136\n",
      "running iteration 75 with loss 0.475222\n",
      "running iteration 100 with loss 0.447681\n",
      "running iteration 125 with loss 0.447607\n",
      "running iteration 150 with loss 0.442350\n",
      "average loss 0.456438\n",
      "test loss 0.470191\n",
      "Total run time was 137.586532\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 4\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.465908\n",
      "running iteration 25 with loss 0.458119\n",
      "running iteration 50 with loss 0.451448\n",
      "running iteration 75 with loss 0.476385\n",
      "running iteration 100 with loss 0.446802\n",
      "running iteration 125 with loss 0.444570\n",
      "running iteration 150 with loss 0.444275\n",
      "average loss 0.455886\n",
      "test loss 0.470086\n",
      "Total run time was 138.684941\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 5\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.464551\n",
      "running iteration 25 with loss 0.455082\n",
      "running iteration 50 with loss 0.448375\n",
      "running iteration 75 with loss 0.474026\n",
      "running iteration 100 with loss 0.446831\n",
      "running iteration 125 with loss 0.444362\n",
      "running iteration 150 with loss 0.439868\n",
      "average loss 0.454410\n",
      "test loss 0.468610\n",
      "Total run time was 136.459054\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 6\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.464024\n",
      "running iteration 25 with loss 0.456214\n",
      "running iteration 50 with loss 0.449907\n",
      "running iteration 75 with loss 0.472838\n",
      "running iteration 100 with loss 0.443710\n",
      "running iteration 125 with loss 0.440986\n",
      "running iteration 150 with loss 0.437570\n",
      "average loss 0.452746\n",
      "test loss 0.467012\n",
      "Total run time was 138.239537\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 7\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.462463\n",
      "running iteration 25 with loss 0.450181\n",
      "running iteration 50 with loss 0.462499\n",
      "running iteration 75 with loss 0.473449\n",
      "running iteration 100 with loss 0.451863\n",
      "running iteration 125 with loss 0.450160\n",
      "running iteration 150 with loss 0.432797\n",
      "average loss 0.457467\n",
      "test loss 0.473507\n",
      "Total run time was 136.263613\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 8\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.452313\n",
      "running iteration 25 with loss 0.442555\n",
      "running iteration 50 with loss 0.436078\n",
      "running iteration 75 with loss 0.468040\n",
      "running iteration 100 with loss 0.428334\n",
      "running iteration 125 with loss 0.424903\n",
      "running iteration 150 with loss 0.418536\n",
      "average loss 0.440874\n",
      "test loss 0.466084\n",
      "Total run time was 138.490049\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 9\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.445209\n",
      "running iteration 25 with loss 0.439690\n",
      "running iteration 50 with loss 0.426822\n",
      "running iteration 75 with loss 0.455764\n",
      "running iteration 100 with loss 0.424235\n",
      "running iteration 125 with loss 0.424446\n",
      "running iteration 150 with loss 0.430132\n",
      "average loss 0.434179\n",
      "test loss 0.465002\n",
      "Total run time was 138.252107\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 10\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.440079\n",
      "running iteration 25 with loss 0.436345\n",
      "running iteration 50 with loss 0.423515\n",
      "running iteration 75 with loss 0.456210\n",
      "running iteration 100 with loss 0.421721\n",
      "running iteration 125 with loss 0.421308\n",
      "running iteration 150 with loss 0.408498\n",
      "average loss 0.429250\n",
      "test loss 0.456477\n",
      "Total run time was 135.018827\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 11\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.437249\n",
      "running iteration 25 with loss 0.429824\n",
      "running iteration 50 with loss 0.422561\n",
      "running iteration 75 with loss 0.454838\n",
      "running iteration 100 with loss 0.425260\n",
      "running iteration 125 with loss 0.422155\n",
      "running iteration 150 with loss 0.404683\n",
      "average loss 0.431673\n",
      "test loss 0.459699\n",
      "Total run time was 132.287179\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 12\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.430925\n",
      "running iteration 25 with loss 0.424697\n",
      "running iteration 50 with loss 0.424163\n",
      "running iteration 75 with loss 0.455082\n",
      "running iteration 100 with loss 0.432922\n",
      "running iteration 125 with loss 0.429763\n",
      "running iteration 150 with loss 0.420810\n",
      "average loss 0.435218\n",
      "test loss 0.467762\n",
      "Total run time was 130.327415\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 13\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.445023\n",
      "running iteration 25 with loss 0.433507\n",
      "running iteration 50 with loss 0.430799\n",
      "running iteration 75 with loss 0.454058\n",
      "running iteration 100 with loss 0.426378\n",
      "running iteration 125 with loss 0.420657\n",
      "running iteration 150 with loss 0.408979\n",
      "average loss 0.432824\n",
      "test loss 0.454806\n",
      "Total run time was 130.405966\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 14\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.432748\n",
      "running iteration 25 with loss 0.424200\n",
      "running iteration 50 with loss 0.428165\n",
      "running iteration 75 with loss 0.455501\n",
      "running iteration 100 with loss 0.421903\n",
      "running iteration 125 with loss 0.420208\n",
      "running iteration 150 with loss 0.411586\n",
      "average loss 0.428644\n",
      "test loss 0.455220\n",
      "Total run time was 129.371448\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 15\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.429857\n",
      "running iteration 25 with loss 0.422318\n",
      "running iteration 50 with loss 0.416982\n",
      "running iteration 75 with loss 0.444929\n",
      "running iteration 100 with loss 0.413053\n",
      "running iteration 125 with loss 0.412665\n",
      "running iteration 150 with loss 0.395062\n",
      "average loss 0.420487\n",
      "test loss 0.454481\n",
      "Total run time was 129.968966\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 16\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.421288\n",
      "running iteration 25 with loss 0.415324\n",
      "running iteration 50 with loss 0.415280\n",
      "running iteration 75 with loss 0.440514\n",
      "running iteration 100 with loss 0.415083\n",
      "running iteration 125 with loss 0.409711\n",
      "running iteration 150 with loss 0.405550\n",
      "average loss 0.418182\n",
      "test loss 0.461637\n",
      "Total run time was 129.071300\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 17\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.433207\n",
      "running iteration 25 with loss 0.426210\n",
      "running iteration 50 with loss 0.415369\n",
      "running iteration 75 with loss 0.451177\n",
      "running iteration 100 with loss 0.410280\n",
      "running iteration 125 with loss 0.412138\n",
      "running iteration 150 with loss 0.393749\n",
      "average loss 0.420372\n",
      "test loss 0.456398\n",
      "Total run time was 129.264943\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 18\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.424345\n",
      "running iteration 25 with loss 0.413393\n",
      "running iteration 50 with loss 0.408120\n",
      "running iteration 75 with loss 0.439942\n",
      "running iteration 100 with loss 0.401151\n",
      "running iteration 125 with loss 0.401722\n",
      "running iteration 150 with loss 0.386354\n",
      "average loss 0.410873\n",
      "test loss 0.449545\n",
      "Total run time was 129.400321\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 19\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.414091\n",
      "running iteration 25 with loss 0.404874\n",
      "running iteration 50 with loss 0.402353\n",
      "running iteration 75 with loss 0.433856\n",
      "running iteration 100 with loss 0.393674\n",
      "running iteration 125 with loss 0.397740\n",
      "running iteration 150 with loss 0.383181\n",
      "average loss 0.405217\n",
      "test loss 0.447443\n",
      "Total run time was 129.816234\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 20\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.409075\n",
      "running iteration 25 with loss 0.402133\n",
      "running iteration 50 with loss 0.399371\n",
      "running iteration 75 with loss 0.431450\n",
      "running iteration 100 with loss 0.393874\n",
      "running iteration 125 with loss 0.396352\n",
      "running iteration 150 with loss 0.381869\n",
      "average loss 0.402714\n",
      "test loss 0.446026\n",
      "Total run time was 129.125477\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 21\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.406262\n",
      "running iteration 25 with loss 0.398010\n",
      "running iteration 50 with loss 0.396323\n",
      "running iteration 75 with loss 0.428056\n",
      "running iteration 100 with loss 0.389498\n",
      "running iteration 125 with loss 0.394637\n",
      "running iteration 150 with loss 0.377767\n",
      "average loss 0.399990\n",
      "test loss 0.444602\n",
      "Total run time was 128.509359\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 22\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.403891\n",
      "running iteration 25 with loss 0.394862\n",
      "running iteration 50 with loss 0.393578\n",
      "running iteration 75 with loss 0.424239\n",
      "running iteration 100 with loss 0.387260\n",
      "running iteration 125 with loss 0.392063\n",
      "running iteration 150 with loss 0.375545\n",
      "average loss 0.397911\n",
      "test loss 0.444365\n",
      "Total run time was 128.967836\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 23\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.401193\n",
      "running iteration 25 with loss 0.391016\n",
      "running iteration 50 with loss 0.393325\n",
      "running iteration 75 with loss 0.424523\n",
      "running iteration 100 with loss 0.387969\n",
      "running iteration 125 with loss 0.391828\n",
      "running iteration 150 with loss 0.374862\n",
      "average loss 0.397265\n",
      "test loss 0.444226\n",
      "Total run time was 129.227330\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 24\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.400220\n",
      "running iteration 25 with loss 0.391227\n",
      "running iteration 50 with loss 0.387471\n",
      "running iteration 75 with loss 0.419491\n",
      "running iteration 100 with loss 0.386047\n",
      "running iteration 125 with loss 0.391845\n",
      "running iteration 150 with loss 0.373692\n",
      "average loss 0.395334\n",
      "test loss 0.444606\n",
      "Total run time was 129.705214\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 25\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.400418\n",
      "running iteration 25 with loss 0.389926\n",
      "running iteration 50 with loss 0.386206\n",
      "running iteration 75 with loss 0.417687\n",
      "running iteration 100 with loss 0.384641\n",
      "running iteration 125 with loss 0.389576\n",
      "running iteration 150 with loss 0.372922\n",
      "average loss 0.393430\n",
      "test loss 0.444401\n",
      "Total run time was 129.940043\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 26\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.396604\n",
      "running iteration 25 with loss 0.388406\n",
      "running iteration 50 with loss 0.385198\n",
      "running iteration 75 with loss 0.417242\n",
      "running iteration 100 with loss 0.394109\n",
      "running iteration 125 with loss 0.397629\n",
      "running iteration 150 with loss 0.372002\n",
      "average loss 0.395034\n",
      "test loss 0.444379\n",
      "Total run time was 128.866292\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 27\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.397842\n",
      "running iteration 25 with loss 0.387099\n",
      "running iteration 50 with loss 0.383680\n",
      "running iteration 75 with loss 0.412700\n",
      "running iteration 100 with loss 0.383630\n",
      "running iteration 125 with loss 0.389890\n",
      "running iteration 150 with loss 0.369809\n",
      "average loss 0.391272\n",
      "test loss 0.444432\n",
      "Total run time was 128.850454\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 28\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.394556\n",
      "running iteration 25 with loss 0.388607\n",
      "running iteration 50 with loss 0.381472\n",
      "running iteration 75 with loss 0.409557\n",
      "running iteration 100 with loss 0.382271\n",
      "running iteration 125 with loss 0.384502\n",
      "running iteration 150 with loss 0.367808\n",
      "average loss 0.389643\n",
      "test loss 0.445667\n",
      "Total run time was 131.101433\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 29\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.393920\n",
      "running iteration 25 with loss 0.383842\n",
      "running iteration 50 with loss 0.379416\n",
      "running iteration 75 with loss 0.407684\n",
      "running iteration 100 with loss 0.379007\n",
      "running iteration 125 with loss 0.383058\n",
      "running iteration 150 with loss 0.366988\n",
      "average loss 0.387740\n",
      "test loss 0.444807\n",
      "Total run time was 129.946132\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 30\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.392131\n",
      "running iteration 25 with loss 0.382994\n",
      "running iteration 50 with loss 0.378603\n",
      "running iteration 75 with loss 0.408893\n",
      "running iteration 100 with loss 0.380139\n",
      "running iteration 125 with loss 0.383845\n",
      "running iteration 150 with loss 0.368168\n",
      "average loss 0.386908\n",
      "test loss 0.444928\n",
      "Total run time was 131.045155\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 31\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.391843\n",
      "running iteration 25 with loss 0.382873\n",
      "running iteration 50 with loss 0.376705\n",
      "running iteration 75 with loss 0.408278\n",
      "running iteration 100 with loss 0.376825\n",
      "running iteration 125 with loss 0.380896\n",
      "running iteration 150 with loss 0.364058\n",
      "average loss 0.385241\n",
      "test loss 0.445837\n",
      "Total run time was 129.485627\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 32\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.389638\n",
      "running iteration 25 with loss 0.381185\n",
      "running iteration 50 with loss 0.374904\n",
      "running iteration 75 with loss 0.404698\n",
      "running iteration 100 with loss 0.375116\n",
      "running iteration 125 with loss 0.379754\n",
      "running iteration 150 with loss 0.377306\n",
      "average loss 0.384631\n",
      "test loss 0.448545\n",
      "Total run time was 130.635458\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 33\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.393683\n",
      "running iteration 25 with loss 0.379867\n",
      "running iteration 50 with loss 0.377454\n",
      "running iteration 75 with loss 0.402333\n",
      "running iteration 100 with loss 0.373919\n",
      "running iteration 125 with loss 0.378613\n",
      "running iteration 150 with loss 0.364586\n",
      "average loss 0.382881\n",
      "test loss 0.448339\n",
      "Total run time was 132.299841\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 34\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.387718\n",
      "running iteration 25 with loss 0.380236\n",
      "running iteration 50 with loss 0.377156\n",
      "running iteration 75 with loss 0.406448\n",
      "running iteration 100 with loss 0.372711\n",
      "running iteration 125 with loss 0.377630\n",
      "running iteration 150 with loss 0.362066\n",
      "average loss 0.382661\n",
      "test loss 0.448615\n",
      "Total run time was 130.026296\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 35\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.385556\n",
      "running iteration 25 with loss 0.377978\n",
      "running iteration 50 with loss 0.370340\n",
      "running iteration 75 with loss 0.399864\n",
      "running iteration 100 with loss 0.372635\n",
      "running iteration 125 with loss 0.376754\n",
      "running iteration 150 with loss 0.360349\n",
      "average loss 0.379726\n",
      "test loss 0.449585\n",
      "Total run time was 130.238198\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 36\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.384207\n",
      "running iteration 25 with loss 0.377544\n",
      "running iteration 50 with loss 0.368570\n",
      "running iteration 75 with loss 0.400067\n",
      "running iteration 100 with loss 0.371232\n",
      "running iteration 125 with loss 0.375918\n",
      "running iteration 150 with loss 0.360112\n",
      "average loss 0.378614\n",
      "test loss 0.451733\n",
      "Total run time was 130.551474\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 37\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.382804\n",
      "running iteration 25 with loss 0.376332\n",
      "running iteration 50 with loss 0.370300\n",
      "running iteration 75 with loss 0.395756\n",
      "running iteration 100 with loss 0.373706\n",
      "running iteration 125 with loss 0.378057\n",
      "running iteration 150 with loss 0.359899\n",
      "average loss 0.379873\n",
      "test loss 0.453867\n",
      "Total run time was 129.513389\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 38\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.385235\n",
      "running iteration 25 with loss 0.376130\n",
      "running iteration 50 with loss 0.370963\n",
      "running iteration 75 with loss 0.394014\n",
      "running iteration 100 with loss 0.370312\n",
      "running iteration 125 with loss 0.374254\n",
      "running iteration 150 with loss 0.357221\n",
      "average loss 0.376617\n",
      "test loss 0.453614\n",
      "Total run time was 129.475393\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 39\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.380242\n",
      "running iteration 25 with loss 0.373173\n",
      "running iteration 50 with loss 0.363948\n",
      "running iteration 75 with loss 0.390035\n",
      "running iteration 100 with loss 0.382787\n",
      "running iteration 125 with loss 0.380171\n",
      "running iteration 150 with loss 0.357787\n",
      "average loss 0.377728\n",
      "test loss 0.451721\n",
      "Total run time was 131.449296\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 40\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.382580\n",
      "running iteration 25 with loss 0.374182\n",
      "running iteration 50 with loss 0.367402\n",
      "running iteration 75 with loss 0.397108\n",
      "running iteration 100 with loss 0.369771\n",
      "running iteration 125 with loss 0.373463\n",
      "running iteration 150 with loss 0.355530\n",
      "average loss 0.376010\n",
      "test loss 0.453587\n",
      "Total run time was 129.272820\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 41\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.378655\n",
      "running iteration 25 with loss 0.373784\n",
      "running iteration 50 with loss 0.361933\n",
      "running iteration 75 with loss 0.392670\n",
      "running iteration 100 with loss 0.368496\n",
      "running iteration 125 with loss 0.372161\n",
      "running iteration 150 with loss 0.354608\n",
      "average loss 0.373943\n",
      "test loss 0.454313\n",
      "Total run time was 132.992426\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 42\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.379020\n",
      "running iteration 25 with loss 0.372512\n",
      "running iteration 50 with loss 0.360447\n",
      "running iteration 75 with loss 0.389613\n",
      "running iteration 100 with loss 0.366294\n",
      "running iteration 125 with loss 0.371010\n",
      "running iteration 150 with loss 0.354188\n",
      "average loss 0.372698\n",
      "test loss 0.453802\n",
      "Total run time was 130.472980\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 43\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.375782\n",
      "running iteration 25 with loss 0.371539\n",
      "running iteration 50 with loss 0.360256\n",
      "running iteration 75 with loss 0.388529\n",
      "running iteration 100 with loss 0.367545\n",
      "running iteration 125 with loss 0.370047\n",
      "running iteration 150 with loss 0.353308\n",
      "average loss 0.371671\n",
      "test loss 0.454864\n",
      "Total run time was 128.941914\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 44\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.375038\n",
      "running iteration 25 with loss 0.372436\n",
      "running iteration 50 with loss 0.367333\n",
      "running iteration 75 with loss 0.385466\n",
      "running iteration 100 with loss 0.364107\n",
      "running iteration 125 with loss 0.368542\n",
      "running iteration 150 with loss 0.352172\n",
      "average loss 0.371365\n",
      "test loss 0.455996\n",
      "Total run time was 130.958782\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 45\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.373231\n",
      "running iteration 25 with loss 0.369201\n",
      "running iteration 50 with loss 0.358090\n",
      "running iteration 75 with loss 0.383661\n",
      "running iteration 100 with loss 0.362603\n",
      "running iteration 125 with loss 0.367885\n",
      "running iteration 150 with loss 0.352963\n",
      "average loss 0.370095\n",
      "test loss 0.458381\n",
      "Total run time was 130.402273\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 46\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.372011\n",
      "running iteration 25 with loss 0.371193\n",
      "running iteration 50 with loss 0.360406\n",
      "running iteration 75 with loss 0.382984\n",
      "running iteration 100 with loss 0.360799\n",
      "running iteration 125 with loss 0.366257\n",
      "running iteration 150 with loss 0.349515\n",
      "average loss 0.368262\n",
      "test loss 0.460087\n",
      "Total run time was 129.637716\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 47\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.370839\n",
      "running iteration 25 with loss 0.366013\n",
      "running iteration 50 with loss 0.353752\n",
      "running iteration 75 with loss 0.384256\n",
      "running iteration 100 with loss 0.361347\n",
      "running iteration 125 with loss 0.364856\n",
      "running iteration 150 with loss 0.349475\n",
      "average loss 0.367320\n",
      "test loss 0.461848\n",
      "Total run time was 130.293729\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 48\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.372036\n",
      "running iteration 25 with loss 0.367531\n",
      "running iteration 50 with loss 0.353746\n",
      "running iteration 75 with loss 0.380777\n",
      "running iteration 100 with loss 0.359029\n",
      "running iteration 125 with loss 0.363448\n",
      "running iteration 150 with loss 0.347897\n",
      "average loss 0.365448\n",
      "test loss 0.462622\n",
      "Total run time was 130.332787\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 49\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.368893\n",
      "running iteration 25 with loss 0.365405\n",
      "running iteration 50 with loss 0.355197\n",
      "running iteration 75 with loss 0.381862\n",
      "running iteration 100 with loss 0.357374\n",
      "running iteration 125 with loss 0.373646\n",
      "running iteration 150 with loss 0.359579\n",
      "average loss 0.368279\n",
      "test loss 0.464485\n",
      "Total run time was 129.792459\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 50\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.372831\n",
      "running iteration 25 with loss 0.369273\n",
      "running iteration 50 with loss 0.356606\n",
      "running iteration 75 with loss 0.382639\n",
      "running iteration 100 with loss 0.357421\n",
      "running iteration 125 with loss 0.366580\n",
      "running iteration 150 with loss 0.349787\n",
      "average loss 0.367136\n",
      "test loss 0.465074\n",
      "Total run time was 130.444700\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 51\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.367076\n",
      "running iteration 25 with loss 0.365595\n",
      "running iteration 50 with loss 0.354444\n",
      "running iteration 75 with loss 0.378369\n",
      "running iteration 100 with loss 0.357477\n",
      "running iteration 125 with loss 0.363753\n",
      "running iteration 150 with loss 0.346867\n",
      "average loss 0.363484\n",
      "test loss 0.464841\n",
      "Total run time was 129.782005\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 52\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.364892\n",
      "running iteration 25 with loss 0.361351\n",
      "running iteration 50 with loss 0.348512\n",
      "running iteration 75 with loss 0.381669\n",
      "running iteration 100 with loss 0.356240\n",
      "running iteration 125 with loss 0.361622\n",
      "running iteration 150 with loss 0.344054\n",
      "average loss 0.361737\n",
      "test loss 0.466336\n",
      "Total run time was 130.659605\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 53\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.363646\n",
      "running iteration 25 with loss 0.359329\n",
      "running iteration 50 with loss 0.348775\n",
      "running iteration 75 with loss 0.375562\n",
      "running iteration 100 with loss 0.353385\n",
      "running iteration 125 with loss 0.360229\n",
      "running iteration 150 with loss 0.344260\n",
      "average loss 0.360577\n",
      "test loss 0.468245\n",
      "Total run time was 130.633679\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 54\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.362592\n",
      "running iteration 25 with loss 0.358138\n",
      "running iteration 50 with loss 0.348959\n",
      "running iteration 75 with loss 0.373564\n",
      "running iteration 100 with loss 0.352322\n",
      "running iteration 125 with loss 0.359249\n",
      "running iteration 150 with loss 0.341921\n",
      "average loss 0.358964\n",
      "test loss 0.471269\n",
      "Total run time was 130.150690\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 55\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.362311\n",
      "running iteration 25 with loss 0.357484\n",
      "running iteration 50 with loss 0.345694\n",
      "running iteration 75 with loss 0.372914\n",
      "running iteration 100 with loss 0.351495\n",
      "running iteration 125 with loss 0.358669\n",
      "running iteration 150 with loss 0.342298\n",
      "average loss 0.358057\n",
      "test loss 0.472399\n",
      "Total run time was 130.454005\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 56\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.360342\n",
      "running iteration 25 with loss 0.356884\n",
      "running iteration 50 with loss 0.344567\n",
      "running iteration 75 with loss 0.374590\n",
      "running iteration 100 with loss 0.350762\n",
      "running iteration 125 with loss 0.357891\n",
      "running iteration 150 with loss 0.342522\n",
      "average loss 0.356943\n",
      "test loss 0.473921\n",
      "Total run time was 129.173327\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 57\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.360292\n",
      "running iteration 25 with loss 0.354337\n",
      "running iteration 50 with loss 0.344970\n",
      "running iteration 75 with loss 0.375647\n",
      "running iteration 100 with loss 0.352239\n",
      "running iteration 125 with loss 0.356932\n",
      "running iteration 150 with loss 0.351620\n",
      "average loss 0.357289\n",
      "test loss 0.472774\n",
      "Total run time was 129.878163\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 58\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.362694\n",
      "running iteration 25 with loss 0.360140\n",
      "running iteration 50 with loss 0.361217\n",
      "running iteration 75 with loss 0.386333\n",
      "running iteration 100 with loss 0.360398\n",
      "running iteration 125 with loss 0.358012\n",
      "running iteration 150 with loss 0.343037\n",
      "average loss 0.363867\n",
      "test loss 0.475289\n",
      "Total run time was 130.544246\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 59\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.360408\n",
      "running iteration 25 with loss 0.352775\n",
      "running iteration 50 with loss 0.342183\n",
      "running iteration 75 with loss 0.378243\n",
      "running iteration 100 with loss 0.350109\n",
      "running iteration 125 with loss 0.354063\n",
      "running iteration 150 with loss 0.340370\n",
      "average loss 0.353744\n",
      "test loss 0.477595\n",
      "Total run time was 130.141921\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 60\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.356042\n",
      "running iteration 25 with loss 0.350186\n",
      "running iteration 50 with loss 0.340323\n",
      "running iteration 75 with loss 0.373096\n",
      "running iteration 100 with loss 0.348055\n",
      "running iteration 125 with loss 0.356845\n",
      "running iteration 150 with loss 0.339961\n",
      "average loss 0.352999\n",
      "test loss 0.480856\n",
      "Total run time was 130.282450\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 61\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.358235\n",
      "running iteration 25 with loss 0.367183\n",
      "running iteration 50 with loss 0.345197\n",
      "running iteration 75 with loss 0.379953\n",
      "running iteration 100 with loss 0.350390\n",
      "running iteration 125 with loss 0.354042\n",
      "running iteration 150 with loss 0.341506\n",
      "average loss 0.355734\n",
      "test loss 0.478500\n",
      "Total run time was 130.266039\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 62\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.358627\n",
      "running iteration 25 with loss 0.352274\n",
      "running iteration 50 with loss 0.336559\n",
      "running iteration 75 with loss 0.372966\n",
      "running iteration 100 with loss 0.348242\n",
      "running iteration 125 with loss 0.352697\n",
      "running iteration 150 with loss 0.340522\n",
      "average loss 0.351915\n",
      "test loss 0.478655\n",
      "Total run time was 128.943631\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 63\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.355455\n",
      "running iteration 25 with loss 0.351626\n",
      "running iteration 50 with loss 0.335176\n",
      "running iteration 75 with loss 0.368841\n",
      "running iteration 100 with loss 0.346063\n",
      "running iteration 125 with loss 0.351964\n",
      "running iteration 150 with loss 0.341535\n",
      "average loss 0.350415\n",
      "test loss 0.477870\n",
      "Total run time was 129.011094\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 64\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.357328\n",
      "running iteration 25 with loss 0.353860\n",
      "running iteration 50 with loss 0.339642\n",
      "running iteration 75 with loss 0.361784\n",
      "running iteration 100 with loss 0.347890\n",
      "running iteration 125 with loss 0.351057\n",
      "running iteration 150 with loss 0.338522\n",
      "average loss 0.350888\n",
      "test loss 0.476706\n",
      "Total run time was 129.497658\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 65\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.359743\n",
      "running iteration 25 with loss 0.350567\n",
      "running iteration 50 with loss 0.334145\n",
      "running iteration 75 with loss 0.363232\n",
      "running iteration 100 with loss 0.344935\n",
      "running iteration 125 with loss 0.352042\n",
      "running iteration 150 with loss 0.341068\n",
      "average loss 0.349835\n",
      "test loss 0.479158\n",
      "Total run time was 130.221762\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 66\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.354544\n",
      "running iteration 25 with loss 0.348916\n",
      "running iteration 50 with loss 0.334363\n",
      "running iteration 75 with loss 0.362356\n",
      "running iteration 100 with loss 0.344853\n",
      "running iteration 125 with loss 0.349267\n",
      "running iteration 150 with loss 0.342613\n",
      "average loss 0.348902\n",
      "test loss 0.481763\n",
      "Total run time was 128.363318\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 67\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.353370\n",
      "running iteration 25 with loss 0.348937\n",
      "running iteration 50 with loss 0.333350\n",
      "running iteration 75 with loss 0.365949\n",
      "running iteration 100 with loss 0.342052\n",
      "running iteration 125 with loss 0.346575\n",
      "running iteration 150 with loss 0.338155\n",
      "average loss 0.347561\n",
      "test loss 0.487010\n",
      "Total run time was 129.607871\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 68\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.354124\n",
      "running iteration 25 with loss 0.348925\n",
      "running iteration 50 with loss 0.331255\n",
      "running iteration 75 with loss 0.360982\n",
      "running iteration 100 with loss 0.342317\n",
      "running iteration 125 with loss 0.345367\n",
      "running iteration 150 with loss 0.334241\n",
      "average loss 0.346349\n",
      "test loss 0.489340\n",
      "Total run time was 130.503674\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 69\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.350594\n",
      "running iteration 25 with loss 0.351586\n",
      "running iteration 50 with loss 0.331488\n",
      "running iteration 75 with loss 0.359143\n",
      "running iteration 100 with loss 0.342263\n",
      "running iteration 125 with loss 0.344909\n",
      "running iteration 150 with loss 0.333617\n",
      "average loss 0.346325\n",
      "test loss 0.491216\n",
      "Total run time was 129.987322\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 70\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.348432\n",
      "running iteration 25 with loss 0.346913\n",
      "running iteration 50 with loss 0.330812\n",
      "running iteration 75 with loss 0.359609\n",
      "running iteration 100 with loss 0.348956\n",
      "running iteration 125 with loss 0.346760\n",
      "running iteration 150 with loss 0.335151\n",
      "average loss 0.346293\n",
      "test loss 0.491108\n",
      "Total run time was 128.319831\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 71\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.347747\n",
      "running iteration 25 with loss 0.351484\n",
      "running iteration 50 with loss 0.343207\n",
      "running iteration 75 with loss 0.440238\n",
      "running iteration 100 with loss 0.426390\n",
      "running iteration 125 with loss 0.407301\n",
      "running iteration 150 with loss 0.397111\n",
      "average loss 0.394601\n",
      "test loss 0.496483\n",
      "Total run time was 129.648876\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 72\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.416807\n",
      "running iteration 25 with loss 0.396578\n",
      "running iteration 50 with loss 0.382400\n",
      "running iteration 75 with loss 0.401944\n",
      "running iteration 100 with loss 0.384119\n",
      "running iteration 125 with loss 0.379273\n",
      "running iteration 150 with loss 0.371689\n",
      "average loss 0.392280\n",
      "test loss 0.485677\n",
      "Total run time was 129.686270\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 73\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.388050\n",
      "running iteration 25 with loss 0.375568\n",
      "running iteration 50 with loss 0.364685\n",
      "running iteration 75 with loss 0.381074\n",
      "running iteration 100 with loss 0.368507\n",
      "running iteration 125 with loss 0.362599\n",
      "running iteration 150 with loss 0.361692\n",
      "average loss 0.373988\n",
      "test loss 0.484482\n",
      "Total run time was 129.726105\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 74\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.372887\n",
      "running iteration 25 with loss 0.365628\n",
      "running iteration 50 with loss 0.355672\n",
      "running iteration 75 with loss 0.372461\n",
      "running iteration 100 with loss 0.362260\n",
      "running iteration 125 with loss 0.356775\n",
      "running iteration 150 with loss 0.355933\n",
      "average loss 0.365590\n",
      "test loss 0.484484\n",
      "Total run time was 130.218899\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 75\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.367446\n",
      "running iteration 25 with loss 0.359126\n",
      "running iteration 50 with loss 0.349228\n",
      "running iteration 75 with loss 0.367221\n",
      "running iteration 100 with loss 0.358274\n",
      "running iteration 125 with loss 0.354730\n",
      "running iteration 150 with loss 0.352668\n",
      "average loss 0.360518\n",
      "test loss 0.486909\n",
      "Total run time was 130.082170\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 76\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.364749\n",
      "running iteration 25 with loss 0.356552\n",
      "running iteration 50 with loss 0.346864\n",
      "running iteration 75 with loss 0.362566\n",
      "running iteration 100 with loss 0.354829\n",
      "running iteration 125 with loss 0.352942\n",
      "running iteration 150 with loss 0.350238\n",
      "average loss 0.358226\n",
      "test loss 0.486093\n",
      "Total run time was 131.475747\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 77\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.361463\n",
      "running iteration 25 with loss 0.353740\n",
      "running iteration 50 with loss 0.350088\n",
      "running iteration 75 with loss 0.364135\n",
      "running iteration 100 with loss 0.353810\n",
      "running iteration 125 with loss 0.351234\n",
      "running iteration 150 with loss 0.347796\n",
      "average loss 0.356418\n",
      "test loss 0.488295\n",
      "Total run time was 129.459182\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 78\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.357861\n",
      "running iteration 25 with loss 0.350212\n",
      "running iteration 50 with loss 0.340802\n",
      "running iteration 75 with loss 0.359042\n",
      "running iteration 100 with loss 0.351335\n",
      "running iteration 125 with loss 0.349285\n",
      "running iteration 150 with loss 0.345149\n",
      "average loss 0.353251\n",
      "test loss 0.490272\n",
      "Total run time was 130.653500\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 79\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.355765\n",
      "running iteration 25 with loss 0.347444\n",
      "running iteration 50 with loss 0.339842\n",
      "running iteration 75 with loss 0.358890\n",
      "running iteration 100 with loss 0.350950\n",
      "running iteration 125 with loss 0.349198\n",
      "running iteration 150 with loss 0.344466\n",
      "average loss 0.351649\n",
      "test loss 0.491281\n",
      "Total run time was 129.311933\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 80\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.354380\n",
      "running iteration 25 with loss 0.345142\n",
      "running iteration 50 with loss 0.349896\n",
      "running iteration 75 with loss 0.364413\n",
      "running iteration 100 with loss 0.351435\n",
      "running iteration 125 with loss 0.352510\n",
      "running iteration 150 with loss 0.349022\n",
      "average loss 0.354824\n",
      "test loss 0.492188\n",
      "Total run time was 129.567729\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 81\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.357358\n",
      "running iteration 25 with loss 0.348522\n",
      "running iteration 50 with loss 0.339941\n",
      "running iteration 75 with loss 0.357434\n",
      "running iteration 100 with loss 0.347617\n",
      "running iteration 125 with loss 0.347930\n",
      "running iteration 150 with loss 0.343691\n",
      "average loss 0.351698\n",
      "test loss 0.492312\n",
      "Total run time was 131.241951\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 82\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.353147\n",
      "running iteration 25 with loss 0.343846\n",
      "running iteration 50 with loss 0.337262\n",
      "running iteration 75 with loss 0.356503\n",
      "running iteration 100 with loss 0.347259\n",
      "running iteration 125 with loss 0.346394\n",
      "running iteration 150 with loss 0.340943\n",
      "average loss 0.349017\n",
      "test loss 0.493769\n",
      "Total run time was 130.143722\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 83\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.352177\n",
      "running iteration 25 with loss 0.343185\n",
      "running iteration 50 with loss 0.334992\n",
      "running iteration 75 with loss 0.354713\n",
      "running iteration 100 with loss 0.347133\n",
      "running iteration 125 with loss 0.345441\n",
      "running iteration 150 with loss 0.339605\n",
      "average loss 0.347443\n",
      "test loss 0.495477\n",
      "Total run time was 128.835880\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 84\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.350076\n",
      "running iteration 25 with loss 0.342375\n",
      "running iteration 50 with loss 0.333389\n",
      "running iteration 75 with loss 0.353612\n",
      "running iteration 100 with loss 0.346470\n",
      "running iteration 125 with loss 0.345275\n",
      "running iteration 150 with loss 0.338560\n",
      "average loss 0.346139\n",
      "test loss 0.496950\n",
      "Total run time was 128.596623\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 85\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.350254\n",
      "running iteration 25 with loss 0.340948\n",
      "running iteration 50 with loss 0.332535\n",
      "running iteration 75 with loss 0.352400\n",
      "running iteration 100 with loss 0.345975\n",
      "running iteration 125 with loss 0.343024\n",
      "running iteration 150 with loss 0.337064\n",
      "average loss 0.344918\n",
      "test loss 0.497033\n",
      "Total run time was 128.523736\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 86\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.349625\n",
      "running iteration 25 with loss 0.340747\n",
      "running iteration 50 with loss 0.331789\n",
      "running iteration 75 with loss 0.352297\n",
      "running iteration 100 with loss 0.344567\n",
      "running iteration 125 with loss 0.343631\n",
      "running iteration 150 with loss 0.336084\n",
      "average loss 0.344266\n",
      "test loss 0.499994\n",
      "Total run time was 129.788748\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 87\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.348763\n",
      "running iteration 25 with loss 0.339450\n",
      "running iteration 50 with loss 0.331848\n",
      "running iteration 75 with loss 0.351026\n",
      "running iteration 100 with loss 0.343310\n",
      "running iteration 125 with loss 0.341933\n",
      "running iteration 150 with loss 0.335505\n",
      "average loss 0.343390\n",
      "test loss 0.500497\n",
      "Total run time was 128.112474\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 88\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.348174\n",
      "running iteration 25 with loss 0.339196\n",
      "running iteration 50 with loss 0.330663\n",
      "running iteration 75 with loss 0.349911\n",
      "running iteration 100 with loss 0.345336\n",
      "running iteration 125 with loss 0.341885\n",
      "running iteration 150 with loss 0.335171\n",
      "average loss 0.342719\n",
      "test loss 0.502857\n",
      "Total run time was 128.923543\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 89\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.346473\n",
      "running iteration 25 with loss 0.337860\n",
      "running iteration 50 with loss 0.328689\n",
      "running iteration 75 with loss 0.348811\n",
      "running iteration 100 with loss 0.341320\n",
      "running iteration 125 with loss 0.341689\n",
      "running iteration 150 with loss 0.333333\n",
      "average loss 0.341207\n",
      "test loss 0.504563\n",
      "Total run time was 129.413070\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 90\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.345725\n",
      "running iteration 25 with loss 0.337139\n",
      "running iteration 50 with loss 0.327752\n",
      "running iteration 75 with loss 0.348297\n",
      "running iteration 100 with loss 0.340006\n",
      "running iteration 125 with loss 0.342198\n",
      "running iteration 150 with loss 0.335438\n",
      "average loss 0.341221\n",
      "test loss 0.505301\n",
      "Total run time was 128.351038\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 91\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.347947\n",
      "running iteration 25 with loss 0.337986\n",
      "running iteration 50 with loss 0.328562\n",
      "running iteration 75 with loss 0.348885\n",
      "running iteration 100 with loss 0.339132\n",
      "running iteration 125 with loss 0.339592\n",
      "running iteration 150 with loss 0.331742\n",
      "average loss 0.340702\n",
      "test loss 0.506164\n",
      "Total run time was 128.621065\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 92\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.343500\n",
      "running iteration 25 with loss 0.335844\n",
      "running iteration 50 with loss 0.326031\n",
      "running iteration 75 with loss 0.347095\n",
      "running iteration 100 with loss 0.338909\n",
      "running iteration 125 with loss 0.338377\n",
      "running iteration 150 with loss 0.330805\n",
      "average loss 0.339027\n",
      "test loss 0.508677\n",
      "Total run time was 128.682706\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 93\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.343685\n",
      "running iteration 25 with loss 0.335686\n",
      "running iteration 50 with loss 0.325199\n",
      "running iteration 75 with loss 0.345745\n",
      "running iteration 100 with loss 0.338837\n",
      "running iteration 125 with loss 0.337472\n",
      "running iteration 150 with loss 0.330216\n",
      "average loss 0.338201\n",
      "test loss 0.509588\n",
      "Total run time was 130.161178\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 94\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.342285\n",
      "running iteration 25 with loss 0.333773\n",
      "running iteration 50 with loss 0.323723\n",
      "running iteration 75 with loss 0.344715\n",
      "running iteration 100 with loss 0.337794\n",
      "running iteration 125 with loss 0.337214\n",
      "running iteration 150 with loss 0.333337\n",
      "average loss 0.337654\n",
      "test loss 0.508714\n",
      "Total run time was 130.076315\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 95\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.343985\n",
      "running iteration 25 with loss 0.333484\n",
      "running iteration 50 with loss 0.332117\n",
      "running iteration 75 with loss 0.348249\n",
      "running iteration 100 with loss 0.338411\n",
      "running iteration 125 with loss 0.339360\n",
      "running iteration 150 with loss 0.331976\n",
      "average loss 0.339506\n",
      "test loss 0.511181\n",
      "Total run time was 129.819370\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 96\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.345126\n",
      "running iteration 25 with loss 0.332356\n",
      "running iteration 50 with loss 0.323683\n",
      "running iteration 75 with loss 0.349293\n",
      "running iteration 100 with loss 0.336553\n",
      "running iteration 125 with loss 0.343513\n",
      "running iteration 150 with loss 0.334650\n",
      "average loss 0.339829\n",
      "test loss 0.509497\n",
      "Total run time was 129.051131\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 97\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.344182\n",
      "running iteration 25 with loss 0.335497\n",
      "running iteration 50 with loss 0.324175\n",
      "running iteration 75 with loss 0.345904\n",
      "running iteration 100 with loss 0.336001\n",
      "running iteration 125 with loss 0.335327\n",
      "running iteration 150 with loss 0.328860\n",
      "average loss 0.337797\n",
      "test loss 0.513317\n",
      "Total run time was 129.832315\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 98\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.340413\n",
      "running iteration 25 with loss 0.332359\n",
      "running iteration 50 with loss 0.322914\n",
      "running iteration 75 with loss 0.343185\n",
      "running iteration 100 with loss 0.334692\n",
      "running iteration 125 with loss 0.337261\n",
      "running iteration 150 with loss 0.328036\n",
      "average loss 0.335952\n",
      "test loss 0.513806\n",
      "Total run time was 128.668619\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 99\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.342116\n",
      "running iteration 25 with loss 0.330899\n",
      "running iteration 50 with loss 0.321267\n",
      "running iteration 75 with loss 0.341440\n",
      "running iteration 100 with loss 0.333378\n",
      "running iteration 125 with loss 0.334568\n",
      "running iteration 150 with loss 0.326561\n",
      "average loss 0.334574\n",
      "test loss 0.515658\n",
      "Total run time was 129.528887\n"
     ]
    }
   ],
   "source": [
    "with open('runOutput.txt', 'w') as f:\n",
    "    with tf.Session() as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for epoch in range(training_epochs):\n",
    "            totalError = 0.0\n",
    "            f.write(\"\"\"***************************\n",
    "***************************\n",
    "Running on epoch %d\n",
    "***************************\n",
    "***************************\n",
    "***************************\\n\"\"\" %(epoch))\n",
    "            print('***************************')\n",
    "            print('***************************')\n",
    "            print('Running on epoch %d'% (epoch))\n",
    "            print('***************************')\n",
    "            print('***************************')\n",
    "            start = time.time()\n",
    "            for b in range(total_batches):\n",
    "                offset = (b * batch_size) % (yTrain.shape[0] - batch_size)\n",
    "                batch_x = xTrain[offset:(offset + batch_size), :]\n",
    "                batch_y = yTrain[offset:(offset + batch_size), :]\n",
    "                _, c = session.run([train_op, loss_function],feed_dict={x: batch_x, yTruth : batch_y})\n",
    "                if(b%25 == 0):\n",
    "                    f.write('running iteration %d with loss %3f \\n'% (b, c))\n",
    "                    print('running iteration %d with loss %3f'% (b, c))\n",
    "                totalError = totalError + c\n",
    "            pred_y = session.run(y_last,feed_dict={x:xDev})\n",
    "            testLoss = tf.nn.sigmoid_cross_entropy_with_logits(logits = pred_y, \n",
    "                                                 labels = tf.cast(yDev, tf.float32))\n",
    "            # print('yolo2')\n",
    "            testLoss = tf.reduce_mean(testLoss)\n",
    "            testLoss = testLoss.eval()\n",
    "            epochPredictions[epoch,:,:] = pred_y\n",
    "            epochAvgLossValid[epoch] = testLoss\n",
    "            epochAvgLoss[epoch] = totalError/total_batches\n",
    "            print('average loss %f'% (totalError/total_batches))\n",
    "            print('test loss %f'%(testLoss))\n",
    "            print('Total run time was %3f'% (time.time() - start))\n",
    "            f.write('average loss %f \\n'%(totalError/total_batches)) \n",
    "            f.write('test loss %f \\n'%(testLoss))\n",
    "            f.write('Total run time was %3f \\n'% (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('epochPreds.npy', epochPredictions)\n",
    "np.save('epochAvgLoss.npy', epochAvgLoss)\n",
    "np.save('epochAvgLossValid.npy', epochAvgLossValid)\n",
    "# epochPredictions = np.load('epochPreds.npy')\n",
    "# epochAvgLoss = np.load('epochAvgLoss.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51452707,  0.45995344,  0.43462992,  0.41936219,  0.41235238,\n",
       "        0.41834732,  0.41078419,  0.40498442,  0.40353198,  0.40694118,\n",
       "        0.40437556,  0.40128296,  0.39994949,  0.39938753,  0.3983025 ,\n",
       "        0.40124542,  0.39742203,  0.39585325,  0.39460578,  0.39332082,\n",
       "        0.39194583,  0.3904777 ,  0.38875285,  0.38719968,  0.38609889,\n",
       "        0.38310986,  0.38016142,  0.37700441,  0.37408573,  0.37147727,\n",
       "        0.36928105,  0.36720278,  0.36547994,  0.36404498,  0.36169525,\n",
       "        0.35975248,  0.35806898,  0.35645668,  0.35473295,  0.35283949,\n",
       "        0.35178718,  0.34996518,  0.34802889,  0.34634936,  0.34720347,\n",
       "        0.34615051,  0.34215241,  0.34029411,  0.33853405,  0.33689153,\n",
       "        0.33550819,  0.33429784,  0.33327068,  0.33284229,  0.33115371,\n",
       "        0.33016771,  0.33065978,  0.32717054,  0.32479699,  0.32302532,\n",
       "        0.32135627,  0.32106279,  0.31867822,  0.31709279,  0.32231339,\n",
       "        0.31568401,  0.31362784,  0.31238926,  0.31162357,  0.31088293,\n",
       "        0.30999991,  0.30925826,  0.30789272,  0.30603077,  0.30453609,\n",
       "        0.3032737 ,  0.30291547,  0.30049385,  0.29951389,  0.29940536,\n",
       "        0.29755079,  0.29748144,  0.29770777,  0.29627038,  0.29461982,\n",
       "        0.2929474 ,  0.2937646 ,  0.29211997,  0.29663871,  0.29787166,\n",
       "        0.29214845,  0.28990988,  0.28818156,  0.28711496,  0.28642101,\n",
       "        0.28560856,  0.28541276,  0.28350213,  0.28088716,  0.27950343])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochAvgLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.75370455,  1.67933273, -2.69358039, ..., -2.01426339,\n",
       "        -0.86917311,  0.79890823],\n",
       "       [-4.36674786, -0.06165611, -2.74911141, ..., -2.62465668,\n",
       "        -2.43731642, -0.69009614],\n",
       "       [-4.46219921,  1.56112897, -2.70046782, ..., -1.89996243,\n",
       "        -0.88268757,  0.85096014],\n",
       "       ..., \n",
       "       [-4.7687335 ,  1.6234144 , -2.67308807, ..., -2.1105957 ,\n",
       "        -0.94674951,  0.7927385 ],\n",
       "       [-4.89458561,  1.26964736, -2.47386932, ..., -2.6117847 ,\n",
       "        -1.38338339,  0.81521231],\n",
       "       [-4.93843937,  1.41408908, -2.61022067, ..., -2.27724767,\n",
       "        -1.18468642,  0.76667136]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochPredictions[1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7fa8bdfdfb70>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22618506132782279"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalError/154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13182.0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6591000/(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '624': 1,\n",
       " 'V552': 2,\n",
       " 'V1062': 6,\n",
       " '323': 7,\n",
       " '962': 8,\n",
       " '437': 9,\n",
       " '288': 10,\n",
       " 'E8193': 11,\n",
       " 'V2501': 12,\n",
       " '471': 13,\n",
       " '333': 14,\n",
       " 'V1741': 15,\n",
       " 'E8543': 16,\n",
       " '176': 17,\n",
       " '651': 18,\n",
       " 'V0991': 19,\n",
       " 'E8405': 20,\n",
       " '273': 21,\n",
       " '226': 22,\n",
       " 'E9504': 1552,\n",
       " '183': 24,\n",
       " '823': 937,\n",
       " '611': 26,\n",
       " 'V4976': 624,\n",
       " 'E8210': 28,\n",
       " 'E9220': 29,\n",
       " '718': 30,\n",
       " 'V449': 31,\n",
       " 'V561': 1616,\n",
       " '299': 32,\n",
       " 'E9888': 33,\n",
       " 'E8702': 34,\n",
       " '343': 627,\n",
       " 'V0950': 939,\n",
       " '133': 37,\n",
       " 'V145': 38,\n",
       " 'V180': 39,\n",
       " 'E8840': 1811,\n",
       " 'V023': 40,\n",
       " '449': 41,\n",
       " 'V5481': 42,\n",
       " '218': 43,\n",
       " 'E8853': 267,\n",
       " '97': 45,\n",
       " '707': 46,\n",
       " '345': 47,\n",
       " '879': 48,\n",
       " 'V4281': 49,\n",
       " 'E8314': 50,\n",
       " '756': 51,\n",
       " 'E8609': 52,\n",
       " 'E9293': 53,\n",
       " 'V671': 54,\n",
       " 'E8584': 55,\n",
       " '161': 56,\n",
       " '999': 57,\n",
       " '180': 58,\n",
       " '972': 1384,\n",
       " 'V643': 59,\n",
       " 'E9294': 60,\n",
       " '7': 943,\n",
       " 'V4986': 62,\n",
       " '698': 63,\n",
       " 'E8497': 64,\n",
       " '875': 1764,\n",
       " 'E0039': 65,\n",
       " 'E9346': 66,\n",
       " 'V1261': 67,\n",
       " 'E9325': 68,\n",
       " 'V440': 69,\n",
       " '438': 70,\n",
       " 'E8624': 71,\n",
       " '377': 72,\n",
       " 'V1505': 73,\n",
       " 'E9331': 74,\n",
       " '659': 75,\n",
       " '738': 76,\n",
       " '354': 78,\n",
       " 'E9455': 79,\n",
       " '478': 81,\n",
       " 'E8162': 82,\n",
       " 'E9671': 83,\n",
       " '540': 84,\n",
       " 'V1085': 85,\n",
       " '436': 86,\n",
       " 'E9063': 87,\n",
       " '421': 88,\n",
       " '225': 946,\n",
       " 'E0026': 90,\n",
       " '919': 92,\n",
       " 'E9412': 93,\n",
       " 'E8769': 94,\n",
       " 'V0389': 95,\n",
       " '175': 96,\n",
       " 'E8353': 547,\n",
       " 'V1659': 98,\n",
       " 'E9452': 100,\n",
       " 'V174': 101,\n",
       " 'V4282': 102,\n",
       " 'V1083': 103,\n",
       " '822': 104,\n",
       " 'E9433': 105,\n",
       " 'V1381': 107,\n",
       " 'V1029': 108,\n",
       " '734': 109,\n",
       " 'V812': 110,\n",
       " '204': 111,\n",
       " 'V4589': 112,\n",
       " 'V017': 114,\n",
       " 'E9192': 115,\n",
       " 'E8002': 116,\n",
       " 'E9299': 117,\n",
       " 'V8741': 118,\n",
       " '111': 119,\n",
       " 'V8524': 120,\n",
       " 'V1859': 121,\n",
       " '317': 122,\n",
       " 'V4989': 123,\n",
       " 'E8800': 125,\n",
       " '326': 126,\n",
       " 'V1209': 127,\n",
       " 'V580': 128,\n",
       " '912': 130,\n",
       " 'E9288': 131,\n",
       " '492': 132,\n",
       " 'E8780': 133,\n",
       " 'V5881': 134,\n",
       " '173': 135,\n",
       " '414': 136,\n",
       " '953': 137,\n",
       " 'E0161': 138,\n",
       " 'E0089': 139,\n",
       " '321': 140,\n",
       " '866': 141,\n",
       " '351': 142,\n",
       " 'E8502': 143,\n",
       " '144': 144,\n",
       " '558': 146,\n",
       " 'V5416': 148,\n",
       " 'E9478': 336,\n",
       " 'V1006': 150,\n",
       " 'V291': 151,\n",
       " 'V4574': 152,\n",
       " '814': 153,\n",
       " '217': 154,\n",
       " 'E8187': 155,\n",
       " '824': 156,\n",
       " '432': 157,\n",
       " '402': 158,\n",
       " 'E8552': 159,\n",
       " '258': 160,\n",
       " 'E8503': 161,\n",
       " '876': 162,\n",
       " 'V1060': 1690,\n",
       " '208': 1578,\n",
       " 'E9242': 164,\n",
       " '385': 165,\n",
       " '405': 962,\n",
       " '454': 167,\n",
       " 'V1504': 168,\n",
       " 'E9301': 169,\n",
       " '682': 170,\n",
       " 'V138': 171,\n",
       " 'V6103': 172,\n",
       " '202': 173,\n",
       " '282': 174,\n",
       " 'E8138': 175,\n",
       " '629': 339,\n",
       " 'V560': 177,\n",
       " '694': 178,\n",
       " 'V272': 1268,\n",
       " '53': 180,\n",
       " 'E8842': 181,\n",
       " 'V167': 182,\n",
       " '342': 183,\n",
       " '610': 1052,\n",
       " 'E8216': 185,\n",
       " 'E9300': 186,\n",
       " 'E9572': 187,\n",
       " 'V111': 188,\n",
       " '428': 189,\n",
       " 'V6107': 190,\n",
       " 'V7651': 191,\n",
       " 'V0253': 192,\n",
       " '555': 193,\n",
       " '120': 194,\n",
       " 'E9506': 195,\n",
       " '433': 196,\n",
       " '205': 197,\n",
       " '341': 1118,\n",
       " 'V1641': 199,\n",
       " 'V444': 200,\n",
       " 'E9674': 201,\n",
       " 'V301': 202,\n",
       " 'E8384': 203,\n",
       " 'V4973': 1413,\n",
       " '623': 204,\n",
       " 'V4571': 205,\n",
       " '834': 206,\n",
       " 'V6141': 965,\n",
       " 'V113': 208,\n",
       " '729': 209,\n",
       " '496': 210,\n",
       " '132': 211,\n",
       " 'V163': 212,\n",
       " 'V8801': 213,\n",
       " '372': 214,\n",
       " 'V5417': 1470,\n",
       " '276': 216,\n",
       " 'V4511': 217,\n",
       " '339': 218,\n",
       " '685': 219,\n",
       " '139': 1700,\n",
       " '514': 220,\n",
       " '627': 288,\n",
       " 'V8389': 221,\n",
       " 'V4459': 222,\n",
       " 'V5843': 223,\n",
       " '255': 224,\n",
       " '943': 768,\n",
       " '188': 226,\n",
       " 'V5301': 1292,\n",
       " '881': 228,\n",
       " 'E9330': 229,\n",
       " 'V4578': 230,\n",
       " '712': 231,\n",
       " '298': 232,\n",
       " 'V016': 233,\n",
       " 'E8052': 1786,\n",
       " 'V1001': 813,\n",
       " '238': 234,\n",
       " 'E8792': 235,\n",
       " '122': 1429,\n",
       " 'E856': 509,\n",
       " '830': 237,\n",
       " 'V1309': 238,\n",
       " '770': 239,\n",
       " '38': 240,\n",
       " '595': 241,\n",
       " '847': 242,\n",
       " 'V5410': 243,\n",
       " '522': 1727,\n",
       " 'V4363': 244,\n",
       " 'V1004': 245,\n",
       " 'E8703': 246,\n",
       " '49': 247,\n",
       " 'E848': 248,\n",
       " '868': 667,\n",
       " 'V601': 250,\n",
       " '705': 1798,\n",
       " 'V052': 251,\n",
       " 'E8240': 252,\n",
       " 'V537': 253,\n",
       " '365': 254,\n",
       " 'E9238': 255,\n",
       " 'V292': 256,\n",
       " '260': 257,\n",
       " '494': 258,\n",
       " '989': 259,\n",
       " 'V0179': 353,\n",
       " '356': 262,\n",
       " 'V290': 263,\n",
       " '696': 264,\n",
       " '582': 265,\n",
       " 'V4614': 266,\n",
       " 'E9356': 44,\n",
       " 'V4364': 268,\n",
       " '731': 269,\n",
       " '980': 270,\n",
       " 'E8881': 271,\n",
       " 'V625': 977,\n",
       " 'V708': 274,\n",
       " '925': 275,\n",
       " 'V608': 276,\n",
       " 'cat:14': 277,\n",
       " '33': 278,\n",
       " '553': 356,\n",
       " 'E8415': 280,\n",
       " '440': 281,\n",
       " 'V3401': 282,\n",
       " '742': 980,\n",
       " 'V1043': 284,\n",
       " '313': 285,\n",
       " 'E9398': 286,\n",
       " '422': 287,\n",
       " 'E9687': 676,\n",
       " '794': 289,\n",
       " 'E9310': 290,\n",
       " '304': 291,\n",
       " 'E8150': 292,\n",
       " 'E9530': 293,\n",
       " 'V1819': 294,\n",
       " 'E8735': 474,\n",
       " '571': 296,\n",
       " '708': 297,\n",
       " 'E8191': 298,\n",
       " 'V5411': 299,\n",
       " '541': 300,\n",
       " 'V1242': 301,\n",
       " '792': 302,\n",
       " 'E8551': 1475,\n",
       " 'V5863': 678,\n",
       " 'V596': 304,\n",
       " 'E8343': 305,\n",
       " '588': 591,\n",
       " '145': 1598,\n",
       " '958': 308,\n",
       " '905': 309,\n",
       " '578': 310,\n",
       " '23': 311,\n",
       " 'V6406': 312,\n",
       " 'V1652': 1406,\n",
       " 'V8543': 313,\n",
       " '928': 314,\n",
       " 'E9386': 315,\n",
       " 'V1506': 316,\n",
       " 'V5841': 317,\n",
       " 'V1059': 318,\n",
       " '404': 319,\n",
       " 'E9250': 320,\n",
       " 'E8192': 1601,\n",
       " 'V252': 322,\n",
       " '869': 323,\n",
       " '591': 324,\n",
       " '802': 326,\n",
       " 'E8613': 327,\n",
       " 'E8846': 328,\n",
       " 'E9358': 329,\n",
       " '604': 330,\n",
       " 'V703': 331,\n",
       " 'V1586': 1420,\n",
       " '991': 332,\n",
       " '812': 333,\n",
       " 'E9421': 334,\n",
       " '908': 335,\n",
       " 'E9334': 149,\n",
       " '358': 337,\n",
       " 'E9209': 1703,\n",
       " '435': 338,\n",
       " 'E8130': 176,\n",
       " 'V602': 340,\n",
       " 'E9308': 342,\n",
       " 'E9315': 343,\n",
       " 'E8508': 344,\n",
       " 'E9344': 345,\n",
       " 'E8161': 346,\n",
       " '825': 1067,\n",
       " '921': 348,\n",
       " 'V4361': 349,\n",
       " 'E8783': 350,\n",
       " 'V5401': 351,\n",
       " 'E8830': 352,\n",
       " 'V1254': 261,\n",
       " 'E8587': 354,\n",
       " 'V1811': 355,\n",
       " 'E8554': 279,\n",
       " '507': 357,\n",
       " 'V5844': 1584,\n",
       " 'E9240': 358,\n",
       " '185': 359,\n",
       " 'V331': 360,\n",
       " '872': 361,\n",
       " '781': 362,\n",
       " 'E8548': 1608,\n",
       " '594': 364,\n",
       " 'E9689': 365,\n",
       " '733': 366,\n",
       " '466': 367,\n",
       " '525': 368,\n",
       " '884': 1250,\n",
       " '93': 830,\n",
       " '880': 369,\n",
       " '804': 370,\n",
       " '348': 371,\n",
       " 'E9317': 372,\n",
       " 'V672': 373,\n",
       " '954': 374,\n",
       " '639': 1724,\n",
       " '841': 375,\n",
       " 'V9010': 376,\n",
       " 'V08': 377,\n",
       " 'V140': 379,\n",
       " '431': 380,\n",
       " 'E9451': 381,\n",
       " 'V8530': 382,\n",
       " 'E915': 1615,\n",
       " 'E8490': 384,\n",
       " '885': 385,\n",
       " '665': 386,\n",
       " '195': 388,\n",
       " 'E8230': 389,\n",
       " '584': 390,\n",
       " 'V433': 391,\n",
       " '158': 392,\n",
       " 'V4577': 393,\n",
       " '842': 532,\n",
       " 'E8789': 1304,\n",
       " 'V640': 396,\n",
       " '586': 397,\n",
       " '134': 398,\n",
       " '622': 399,\n",
       " '461': 400,\n",
       " 'E9309': 570,\n",
       " 'E8710': 404,\n",
       " '955': 582,\n",
       " 'V1585': 406,\n",
       " 'V624': 407,\n",
       " 'E9208': 408,\n",
       " 'V171': 697,\n",
       " '331': 411,\n",
       " '206': 412,\n",
       " 'E8132': 413,\n",
       " 'E9800': 1307,\n",
       " 'V462': 416,\n",
       " 'V461': 417,\n",
       " '910': 418,\n",
       " 'V3001': 419,\n",
       " 'E8140': 420,\n",
       " 'E0080': 421,\n",
       " '30': 422,\n",
       " 'V298': 423,\n",
       " '254': 425,\n",
       " 'E9651': 1756,\n",
       " 'E8298': 426,\n",
       " '961': 427,\n",
       " '536': 428,\n",
       " 'V270': 429,\n",
       " 'V8812': 430,\n",
       " 'E9447': 431,\n",
       " '846': 432,\n",
       " '587': 433,\n",
       " 'V053': 434,\n",
       " '765': 435,\n",
       " 'V5422': 436,\n",
       " '752': 437,\n",
       " 'V1061': 438,\n",
       " 'V6111': 439,\n",
       " '34': 440,\n",
       " '40': 441,\n",
       " 'E976': 442,\n",
       " '607': 1004,\n",
       " '398': 445,\n",
       " '520': 446,\n",
       " '992': 447,\n",
       " 'V452': 448,\n",
       " '934': 449,\n",
       " '337': 450,\n",
       " 'E9109': 451,\n",
       " '542': 452,\n",
       " 'V5842': 453,\n",
       " '566': 454,\n",
       " 'V151': 455,\n",
       " '632': 456,\n",
       " 'E8248': 457,\n",
       " 'E8706': 458,\n",
       " '284': 1312,\n",
       " 'E9570': 460,\n",
       " '914': 461,\n",
       " '891': 106,\n",
       " '275': 463,\n",
       " 'V4611': 464,\n",
       " 'E9379': 1627,\n",
       " 'V1071': 466,\n",
       " '863': 467,\n",
       " 'V1241': 468,\n",
       " 'V8521': 469,\n",
       " '355': 470,\n",
       " 'V721': 471,\n",
       " 'V4972': 472,\n",
       " 'V5412': 473,\n",
       " '213': 1526,\n",
       " '790': 475,\n",
       " '773': 476,\n",
       " 'V4588': 477,\n",
       " '798': 478,\n",
       " 'V5811': 479,\n",
       " '537': 480,\n",
       " 'V510': 481,\n",
       " '371': 482,\n",
       " 'E8261': 483,\n",
       " 'V6104': 225,\n",
       " '164': 1318,\n",
       " '228': 1046,\n",
       " '590': 487,\n",
       " '539': 1240,\n",
       " 'E9019': 489,\n",
       " 'E9393': 490,\n",
       " 'E8189': 1573,\n",
       " '821': 492,\n",
       " '278': 1632,\n",
       " 'E9579': 495,\n",
       " '761': 496,\n",
       " 'E9351': 1108,\n",
       " 'E8582': 498,\n",
       " '227': 499,\n",
       " 'V1251': 500,\n",
       " '916': 501,\n",
       " '483': 502,\n",
       " '820': 503,\n",
       " '870': 504,\n",
       " 'E899': 1160,\n",
       " '453': 507,\n",
       " 'E8200': 508,\n",
       " 'cat:16': 510,\n",
       " 'E9340': 511,\n",
       " '815': 512,\n",
       " '660': 1220,\n",
       " 'V1541': 514,\n",
       " '8': 515,\n",
       " 'cat:10': 516,\n",
       " '446': 517,\n",
       " 'V1079': 518,\n",
       " 'V1502': 520,\n",
       " 'V040': 522,\n",
       " 'E9453': 523,\n",
       " 'V4963': 524,\n",
       " 'V029': 525,\n",
       " '723': 526,\n",
       " '136': 528,\n",
       " 'E8212': 529,\n",
       " 'V1584': 1019,\n",
       " '976': 531,\n",
       " '839': 394,\n",
       " '12': 533,\n",
       " '79': 534,\n",
       " 'E9320': 535,\n",
       " 'E8012': 536,\n",
       " 'V5302': 537,\n",
       " '265': 538,\n",
       " 'V5339': 539,\n",
       " '616': 540,\n",
       " 'V0261': 541,\n",
       " '229': 542,\n",
       " 'E0010': 944,\n",
       " 'V850': 544,\n",
       " 'V5861': 545,\n",
       " 'E9270': 546,\n",
       " '376': 97,\n",
       " 'E8801': 548,\n",
       " 'E8318': 1646,\n",
       " 'E8257': 551,\n",
       " 'E9248': 1332,\n",
       " 'E0139': 553,\n",
       " '806': 554,\n",
       " 'V6285': 555,\n",
       " 'E0138': 556,\n",
       " 'E9673': 558,\n",
       " '36': 559,\n",
       " 'V641': 560,\n",
       " 'E9385': 561,\n",
       " '923': 562,\n",
       " 'V4983': 563,\n",
       " 'E9470': 1024,\n",
       " '831': 565,\n",
       " 'E9198': 566,\n",
       " '380': 567,\n",
       " '957': 568,\n",
       " '873': 569,\n",
       " '429': 727,\n",
       " 'E9292': 571,\n",
       " '922': 572,\n",
       " '411': 573,\n",
       " 'E8902': 1640,\n",
       " 'E9821': 574,\n",
       " 'E9211': 575,\n",
       " '918': 576,\n",
       " 'V6129': 577,\n",
       " 'V403': 578,\n",
       " 'V554': 580,\n",
       " 'V536': 1013,\n",
       " 'V8489': 405,\n",
       " '572': 583,\n",
       " '801': 585,\n",
       " 'E8841': 586,\n",
       " 'E9060': 587,\n",
       " 'V8401': 588,\n",
       " '362': 589,\n",
       " 'E8233': 590,\n",
       " 'E9201': 1728,\n",
       " 'E8555': 1357,\n",
       " '840': 592,\n",
       " 'V453': 594,\n",
       " 'V289': 751,\n",
       " '279': 595,\n",
       " 'E9502': 596,\n",
       " 'V168': 597,\n",
       " '671': 1654,\n",
       " '860': 598,\n",
       " '187': 599,\n",
       " '340': 600,\n",
       " 'E9382': 601,\n",
       " '833': 602,\n",
       " 'V1649': 603,\n",
       " 'E8228': 604,\n",
       " '592': 666,\n",
       " 'E9600': 606,\n",
       " 'V741': 607,\n",
       " 'E8740': 608,\n",
       " 'V425': 609,\n",
       " '458': 610,\n",
       " '788': 611,\n",
       " 'V0971': 612,\n",
       " 'E9507': 613,\n",
       " '170': 614,\n",
       " 'V4582': 615,\n",
       " '215': 1657,\n",
       " '155': 617,\n",
       " 'V51': 1343,\n",
       " 'V8533': 619,\n",
       " 'V071': 620,\n",
       " '533': 621,\n",
       " '666': 622,\n",
       " '35': 623,\n",
       " 'V1047': 27,\n",
       " '602': 626,\n",
       " '988': 35,\n",
       " 'V110': 628,\n",
       " 'cat:4': 629,\n",
       " 'E8768': 630,\n",
       " 'E9390': 1283,\n",
       " '137': 631,\n",
       " '803': 632,\n",
       " '306': 634,\n",
       " '861': 635,\n",
       " '94': 1035,\n",
       " 'E8260': 637,\n",
       " 'E8133': 638,\n",
       " '778': 1363,\n",
       " '159': 639,\n",
       " '3': 145,\n",
       " 'V1302': 641,\n",
       " '970': 642,\n",
       " '190': 643,\n",
       " 'E9395': 645,\n",
       " '945': 646,\n",
       " 'E9380': 647,\n",
       " 'E8241': 648,\n",
       " '783': 649,\n",
       " 'V1052': 650,\n",
       " 'V202': 651,\n",
       " 'E9571': 652,\n",
       " '297': 653,\n",
       " 'V1255': 654,\n",
       " '116': 655,\n",
       " '308': 198,\n",
       " 'V5489': 414,\n",
       " 'V020': 658,\n",
       " 'E8180': 659,\n",
       " '325': 660,\n",
       " 'E8500': 661,\n",
       " '216': 662,\n",
       " 'V6289': 663,\n",
       " 'V1364': 664,\n",
       " 'V1072': 665,\n",
       " 'cat:1': 249,\n",
       " '777': 1191,\n",
       " 'V583': 669,\n",
       " 'cat:2': 670,\n",
       " 'E9322': 671,\n",
       " '335': 672,\n",
       " 'V1581': 673,\n",
       " '664': 674,\n",
       " 'E8251': 675,\n",
       " 'cat:11': 579,\n",
       " 'E8171': 677,\n",
       " '799': 303,\n",
       " 'V5399': 679,\n",
       " 'V1007': 680,\n",
       " '171': 681,\n",
       " 'E9479': 682,\n",
       " '182': 683,\n",
       " '686': 684,\n",
       " 'E9589': 685,\n",
       " '77': 686,\n",
       " 'cat:6': 687,\n",
       " '386': 688,\n",
       " 'E8908': 689,\n",
       " '154': 690,\n",
       " 'E8583': 691,\n",
       " '150': 692,\n",
       " '456': 1329,\n",
       " 'V667': 693,\n",
       " 'E8793': 694,\n",
       " '633': 696,\n",
       " '388': 410,\n",
       " '902': 698,\n",
       " '484': 699,\n",
       " 'E9360': 700,\n",
       " 'E8121': 701,\n",
       " '465': 702,\n",
       " '142': 703,\n",
       " '268': 704,\n",
       " 'E8797': 705,\n",
       " 'E9463': 706,\n",
       " 'V160': 707,\n",
       " 'E8668': 708,\n",
       " 'V556': 709,\n",
       " 'E8589': 710,\n",
       " '352': 711,\n",
       " 'E8541': 712,\n",
       " 'E8845': 713,\n",
       " 'V4573': 714,\n",
       " 'V431': 715,\n",
       " 'E0032': 716,\n",
       " '52': 1670,\n",
       " 'E8217': 718,\n",
       " 'E989': 719,\n",
       " '877': 721,\n",
       " 'E8550': 722,\n",
       " '357': 723,\n",
       " '412': 724,\n",
       " '262': 1311,\n",
       " 'E8556': 726,\n",
       " '397': 1243,\n",
       " 'E9204': 1358,\n",
       " '816': 729,\n",
       " '511': 730,\n",
       " '426': 731,\n",
       " '315': 732,\n",
       " '617': 733,\n",
       " '149': 734,\n",
       " '538': 1049,\n",
       " '579': 736,\n",
       " '500': 737,\n",
       " '743': 738,\n",
       " '663': 1673,\n",
       " '130': 955,\n",
       " 'E9804': 739,\n",
       " 'E9173': 740,\n",
       " '5': 741,\n",
       " '367': 742,\n",
       " '235': 743,\n",
       " 'E8242': 744,\n",
       " 'E9001': 745,\n",
       " 'E8809': 1050,\n",
       " 'E9850': 747,\n",
       " '597': 748,\n",
       " 'V6284': 749,\n",
       " '237': 750,\n",
       " '746': 754,\n",
       " 'E8637': 752,\n",
       " 'V4975': 753,\n",
       " 'E8641': 804,\n",
       " 'V469': 755,\n",
       " 'V061': 756,\n",
       " '791': 757,\n",
       " 'V626': 758,\n",
       " '387': 759,\n",
       " '13': 760,\n",
       " '947': 762,\n",
       " 'V1044': 763,\n",
       " '18': 817,\n",
       " 'E8197': 764,\n",
       " '753': 765,\n",
       " 'E977': 766,\n",
       " 'E9290': 767,\n",
       " '599': 867,\n",
       " '249': 770,\n",
       " 'V660': 771,\n",
       " '232': 772,\n",
       " '420': 773,\n",
       " '66': 774,\n",
       " '808': 775,\n",
       " '375': 776,\n",
       " '309': 912,\n",
       " 'E9100': 778,\n",
       " 'V420': 779,\n",
       " '779': 780,\n",
       " 'E8588': 782,\n",
       " 'E9241': 783,\n",
       " 'E8532': 784,\n",
       " '430': 785,\n",
       " 'E0190': 786,\n",
       " '464': 787,\n",
       " 'E8163': 788,\n",
       " '534': 985,\n",
       " 'V4985': 790,\n",
       " 'V0382': 791,\n",
       " 'E9222': 792,\n",
       " '459': 793,\n",
       " 'V789': 794,\n",
       " '994': 795,\n",
       " 'E8580': 796,\n",
       " 'V172': 797,\n",
       " '620': 1056,\n",
       " 'E0076': 800,\n",
       " 'V6149': 1683,\n",
       " 'V1087': 803,\n",
       " 'E8748': 1069,\n",
       " 'E9370': 805,\n",
       " 'V4971': 806,\n",
       " '172': 807,\n",
       " '647': 808,\n",
       " 'V1009': 809,\n",
       " '382': 810,\n",
       " 'E9419': 811,\n",
       " 'E986': 812,\n",
       " '724': 1115,\n",
       " 'cat:5': 1684,\n",
       " 'V5423': 814,\n",
       " 'V610': 815,\n",
       " 'V4961': 816,\n",
       " '441': 1152,\n",
       " 'E9426': 818,\n",
       " '848': 819,\n",
       " 'E8348': 820,\n",
       " 'V5831': 821,\n",
       " '674': 822,\n",
       " '295': 888,\n",
       " '853': 823,\n",
       " 'E8619': 1197,\n",
       " '148': 825,\n",
       " '413': 826,\n",
       " '642': 827,\n",
       " '574': 1804,\n",
       " 'E8495': 828,\n",
       " '110': 829,\n",
       " '495': 1225,\n",
       " '628': 1686,\n",
       " '670': 832,\n",
       " 'V6549': 1594,\n",
       " 'E9410': 1252,\n",
       " 'E8761': 836,\n",
       " '27': 837,\n",
       " 'V618': 838,\n",
       " 'V434': 839,\n",
       " 'E9420': 840,\n",
       " 'E9225': 841,\n",
       " 'E8142': 842,\n",
       " '714': 843,\n",
       " 'E8889': 844,\n",
       " '301': 845,\n",
       " 'V9039': 846,\n",
       " '305': 847,\n",
       " 'E8795': 848,\n",
       " 'V3201': 1784,\n",
       " '942': 849,\n",
       " 'E9314': 850,\n",
       " '21': 851,\n",
       " 'V1507': 852,\n",
       " '370': 853,\n",
       " '618': 1356,\n",
       " '219': 855,\n",
       " 'V4512': 856,\n",
       " '987': 857,\n",
       " '557': 1362,\n",
       " 'V1542': 859,\n",
       " '15': 1593,\n",
       " 'E9068': 860,\n",
       " '383': 861,\n",
       " '906': 862,\n",
       " 'V155': 484,\n",
       " 'E9190': 864,\n",
       " 'E9499': 927,\n",
       " '730': 1758,\n",
       " 'V6282': 866,\n",
       " 'E8041': 868,\n",
       " 'E912': 869,\n",
       " 'V8542': 870,\n",
       " '423': 871,\n",
       " 'V065': 872,\n",
       " '728': 873,\n",
       " '909': 874,\n",
       " 'E9394': 875,\n",
       " 'E0060': 876,\n",
       " 'V707': 877,\n",
       " 'V0981': 1450,\n",
       " '759': 1071,\n",
       " '289': 835,\n",
       " '125': 880,\n",
       " 'E9304': 882,\n",
       " 'V146': 883,\n",
       " '291': 959,\n",
       " 'E8839': 885,\n",
       " 'E9352': 1376,\n",
       " 'E9295': 896,\n",
       " '272': 889,\n",
       " '521': 890,\n",
       " '556': 891,\n",
       " 'V1022': 892,\n",
       " 'V1084': 893,\n",
       " '381': 894,\n",
       " '239': 895,\n",
       " 'E970': 897,\n",
       " 'V2652': 898,\n",
       " '903': 1012,\n",
       " '127': 900,\n",
       " 'V8538': 901,\n",
       " '964': 1586,\n",
       " '451': 902,\n",
       " 'E0299': 903,\n",
       " 'E8585': 904,\n",
       " '287': 1380,\n",
       " '394': 906,\n",
       " 'E9354': 907,\n",
       " '259': 908,\n",
       " '596': 909,\n",
       " '184': 910,\n",
       " '477': 911,\n",
       " 'cat:8': 777,\n",
       " '744': 913,\n",
       " '852': 914,\n",
       " 'E8654': 915,\n",
       " '997': 1077,\n",
       " '174': 1385,\n",
       " 'V1559': 918,\n",
       " '774': 919,\n",
       " 'E8705': 920,\n",
       " 'E8718': 921,\n",
       " '151': 922,\n",
       " 'V181': 923,\n",
       " '874': 924,\n",
       " 'E9193': 925,\n",
       " 'V4579': 926,\n",
       " 'V192': 928,\n",
       " '681': 929,\n",
       " '598': 930,\n",
       " '615': 147,\n",
       " 'E9809': 932,\n",
       " '684': 933,\n",
       " 'V4501': 1782,\n",
       " 'E8844': 934,\n",
       " '789': 935,\n",
       " '661': 936,\n",
       " 'V1000': 25,\n",
       " '319': 938,\n",
       " '701': 36,\n",
       " 'E9363': 940,\n",
       " 'E0011': 941,\n",
       " '960': 942,\n",
       " '209': 61,\n",
       " 'E9670': 761,\n",
       " 'cat:18': 657,\n",
       " 'E888': 945,\n",
       " 'V4962': 89,\n",
       " '882': 947,\n",
       " 'V5867': 948,\n",
       " 'V655': 949,\n",
       " '410': 950,\n",
       " '45': 951,\n",
       " 'V1051': 952,\n",
       " 'E8062': 953,\n",
       " 'V5413': 129,\n",
       " 'V1082': 834,\n",
       " '648': 956,\n",
       " '890': 957,\n",
       " 'V1389': 958,\n",
       " '867': 960,\n",
       " 'V011': 961,\n",
       " '691': 1754,\n",
       " '296': 166,\n",
       " '762': 963,\n",
       " 'E9303': 964,\n",
       " '389': 207,\n",
       " '141': 966,\n",
       " 'V188': 967,\n",
       " '569': 968,\n",
       " '516': 969,\n",
       " '749': 970,\n",
       " '220': 971,\n",
       " 'E0071': 972,\n",
       " 'V5849': 973,\n",
       " '85': 974,\n",
       " 'V443': 975,\n",
       " 'E8709': 976,\n",
       " '726': 272,\n",
       " 'E8227': 978,\n",
       " 'cat:17': 283,\n",
       " 'E8655': 981,\n",
       " '211': 983,\n",
       " '290': 789,\n",
       " 'E9397': 987,\n",
       " 'V9089': 988,\n",
       " 'E9174': 989,\n",
       " 'V0482': 990,\n",
       " '751': 991,\n",
       " 'V8523': 1463,\n",
       " '193': 992,\n",
       " 'V143': 994,\n",
       " 'E9205': 995,\n",
       " 'E8494': 996,\n",
       " 'E918': 997,\n",
       " 'E8190': 1602,\n",
       " 'E9438': 999,\n",
       " '763': 1000,\n",
       " '490': 1001,\n",
       " 'E8219': 1002,\n",
       " '32': 1003,\n",
       " 'V468': 444,\n",
       " 'E0061': 1005,\n",
       " 'V4966': 1006,\n",
       " 'V1069': 1007,\n",
       " 'E8600': 1741,\n",
       " '703': 1008,\n",
       " 'E963': 1009,\n",
       " '143': 1010,\n",
       " 'V632': 1011,\n",
       " '292': 1827,\n",
       " '415': 695,\n",
       " ...}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.icdDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
