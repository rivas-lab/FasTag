{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the LSTM on your Data\n",
    "\n",
    "This notebook will take you through the steps necessary to train an LSTM to recognize ICD-9 codes, or items from similar dictionaries, from free text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Make sure that the below packages are installed on the server on which this program will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src/taggerSystem/')\n",
    "from data_util import load_and_preprocess_data, load_embeddings, ModelHelper, lastTrueWordIdxs\n",
    "import tensorflow as tf\n",
    "from simpleLSTMWithNNetModel import Model, reloadModel\n",
    "from trainModel import trainModel\n",
    "import os\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pickle\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories\n",
    "\n",
    "Executing the following cell will prompt the user to type in the directories corresponding to the training and validation sets, the vocabulary, and the word vector mappings. Defaults are given in the comments below.\n",
    "\n",
    "Note that the training and test data needs to have one column dedicated to free text (`noteIdx`) and another dedicated to top-level ICD-9 codes (`codeIdx`) associated with each patient. Preferably, the latter should be strung together using '-' as the delimiter (e.g. for patient 1, 1-2-6-4).\n",
    "\n",
    "Please make sure that the parameters such as the embed size, maximum note length, learning rate, number of maximum training epochs, batch size, hidden layer size, number of neural net layers, and probabilities are to your specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put sample file with require file headers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjust training data headers to match small icd9 training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the path to the training data? data/0815/mimic+csu_mm_reps_0122_train.csv\n",
      "What is the path to the validation data? data/0815/mimic+csu_mm_reps_0122_valid.csv\n",
      "What is the path to the vocabulary? data/icd9Vocab.txt\n",
      "What is the path to the vocabulary? data/newgloveicd9.txt\n",
      "Which column contains top-level ICD-9 codes (outputs) in the training and test data? Default is 9. 9\n",
      "Which column contains notes/text (inputs) in the training and test data? Default is 6. 6\n"
     ]
    }
   ],
   "source": [
    "data_train = raw_input('What is the path to the training data? ') #default: data/icd9NotesDataTable_train.csv\n",
    "data_valid = raw_input('What is the path to the validation data? ') #default: data/icd9NotesDataTable_valid.csv\n",
    "vocab = raw_input('What is the path to the vocabulary? ') #default: data/icd9Vocab.txt\n",
    "wordVecs = raw_input('What is the path to the vocabulary? ') #data/newgloveicd9.txt. These are length 300 word vectors from GloVE\n",
    "\n",
    "NUM = \"NNNUMMM\"\n",
    "UNK = \"UUUNKKK\"\n",
    "EMBED_SIZE = 300 # this should correspond to the length of the word vectors\n",
    "maxAllowedNoteLength = 1000\n",
    "max_grad_norm = 5\n",
    "codeIdx = raw_input('Which column contains top-level ICD-9 codes (outputs) in the training and test data? Default is 9. ')\n",
    "textIdx = raw_input('Which column contains notes/text (inputs) in the training and test data? Default is 6. ')\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 256\n",
    "n_hidden = 200\n",
    "output_keep_prob = 0.5\n",
    "input_keep_prob = 1\n",
    "numLayers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# Fixing some issue ashley had\n",
    "\n",
    "textIdx = int(textIdx)\n",
    "codeIdx = int(codeIdx)# I'm not sure how models were trinaed before if this part was broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, make sure that the output path is specified as you would like. By default, the program saves the output in a folder with the name of your choice within the folder `results`.\n",
    "\n",
    "If there exists a folder with results that you would like to load again, use that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where are models and performances (to be) saved? 0122_mimic+csu_mm_reps\n"
     ]
    }
   ],
   "source": [
    "output_path = raw_input('Where are models and performances (to be) saved? ')\n",
    "output_path = os.path.join('results', output_path)\n",
    "if output_path == 'results/':\n",
    "    output_path = 'results/temp'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Executing the following cell will ask whether or not there is a previously saved model; if not, the model will train features from scratch, and if so, the features will be loaded.\n",
    "\n",
    "Note that AZ added \"int() to the codeIdx and textIdx to resolve some errors that were preventing it from initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a previously trained model? [Y/n] n\n",
      "Total number of batches per epoch: 399\n",
      "Maximum note length: 1000\n",
      "Number of ICD-9 codes: 19\n",
      "There are a total of: 19 ICD-9 codes\n",
      "{   'cat:1': 8,\n",
      "    'cat:10': 16,\n",
      "    'cat:11': 15,\n",
      "    'cat:12': 14,\n",
      "    'cat:13': 13,\n",
      "    'cat:14': 12,\n",
      "    'cat:15': 11,\n",
      "    'cat:16': 10,\n",
      "    'cat:17': 9,\n",
      "    'cat:18': 18,\n",
      "    'cat:19': 17,\n",
      "    'cat:2': 7,\n",
      "    'cat:3': 6,\n",
      "    'cat:4': 5,\n",
      "    'cat:5': 4,\n",
      "    'cat:6': 3,\n",
      "    'cat:7': 2,\n",
      "    'cat:8': 1,\n",
      "    'cat:9': 0}\n",
      "xDev shape: nObs = 39914, nWords = 1000\n",
      "yDev shape: nObs = 39914, nClasses = 19\n",
      "xTrain shape: nObs = 102399, nWords = 1000\n",
      "yTrain shape: nObs = 102399, nClasses = 19\n",
      "Embeddings shape: nWords = 10008, wordVec length = 300\n"
     ]
    }
   ],
   "source": [
    "sizeList = [n_hidden, 150, 75] # these are the weights we will be using\n",
    "\n",
    "def query_yes_no(question, default=\"yes\"):\n",
    "    \"\"\"Ask a yes/no question via raw_input() and return their answer.\n",
    "\n",
    "    \"question\" is a string that is presented to the user.\n",
    "    \"default\" is the presumed answer if the user just hits <Enter>.\n",
    "        It must be \"yes\" (the default), \"no\" or None (meaning\n",
    "        an answer is required of the user).\n",
    "\n",
    "    The \"answer\" return value is True for \"yes\" or False for \"no\".\n",
    "    \"\"\"\n",
    "    valid = {\"yes\": True, \"y\": True, \"ye\": True,\n",
    "             \"no\": False, \"n\": False}\n",
    "    if default is None:\n",
    "        prompt = \" [y/n] \"\n",
    "    elif default == \"yes\":\n",
    "        prompt = \" [Y/n] \"\n",
    "    elif default == \"no\":\n",
    "        prompt = \" [y/N] \"\n",
    "    else:\n",
    "        raise ValueError(\"invalid default answer: '%s'\" % default)\n",
    "\n",
    "    while True:\n",
    "        sys.stdout.write(question + prompt)\n",
    "        choice = raw_input().lower()\n",
    "        if default is not None and choice == '':\n",
    "            return valid[default]\n",
    "        elif choice in valid:\n",
    "            return valid[choice]\n",
    "        else:\n",
    "            sys.stdout.write(\"Please respond with 'yes' or 'no' \"\n",
    "                             \"(or 'y' or 'n').\\n\")\n",
    "            \n",
    "prev_model = query_yes_no(\"Is there a previously trained model?\")\n",
    "\n",
    "if prev_model:\n",
    "    helper, train, dev, train_raw, dev_raw, xTrain, yTrain, xDev, yDev = load_and_preprocess_data(\n",
    "    data_train = data_train, data_valid = data_valid, \n",
    "    maxAllowedNoteLength = maxAllowedNoteLength, \n",
    "    codeIdx = int(codeIdx), textIdx = int(textIdx),\n",
    "    helperLoadPath = output_path)\n",
    "else:\n",
    "    #print codeIdx\n",
    "    #print textIdx\n",
    "    helper, train, dev, train_raw, dev_raw, xTrain, yTrain, xDev, yDev = load_and_preprocess_data(\n",
    "    data_train = data_train, data_valid = data_valid, \n",
    "    maxAllowedNoteLength = maxAllowedNoteLength, \n",
    "    codeIdx = int(codeIdx), textIdx = int(textIdx))\n",
    "    \n",
    "embeddings = load_embeddings(vocab, wordVecs, helper, embeddingSize = EMBED_SIZE)\n",
    "lastTrueWordIdx_train = lastTrueWordIdxs(train)\n",
    "lastTrueWordIdx_dev = lastTrueWordIdxs(dev)\n",
    "helper.save(output_path) # token2id and max length saved to output_path\n",
    "sizeList.append(helper.n_labels)\n",
    "\n",
    "total_batches = (xTrain.shape[0]//batch_size)\n",
    "print('Total number of batches per epoch: %d'%(total_batches))\n",
    "print('Maximum note length: %d'%(helper.max_length))\n",
    "print('Number of ICD-9 codes: %d'%(helper.n_labels))\n",
    "print('There are a total of: {} ICD-9 codes'.format(len(helper.icdDict.keys())))\n",
    "pp.pprint(helper.icdDict)\n",
    "print('xDev shape: nObs = %d, nWords = %d'%(xDev.shape))\n",
    "print('yDev shape: nObs = %d, nClasses = %d'%(yDev.shape))\n",
    "print('xTrain shape: nObs = %d, nWords = %d'%(xTrain.shape))\n",
    "print('yTrain shape: nObs = %d, nClasses = %d'%(yTrain.shape))\n",
    "print('Embeddings shape: nWords = %d, wordVec length = %d'%(embeddings.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell initializes the dictionary of hyperparameters for the model that fully describe the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'EMBED_SIZE': 300,\n",
      "    'batchSize': 256,\n",
      "    'inputKeepProb': 1,\n",
      "    'learningRate': 0.001,\n",
      "    'maxGradNorm': 5,\n",
      "    'maxNoteLength': 1000,\n",
      "    'n_hidden': 200,\n",
      "    'numLayers': 1,\n",
      "    'outputKeepProb': 0.5,\n",
      "    'sizeList': [200, 150, 75, 19],\n",
      "    'trainingEpochsMax': 100}\n"
     ]
    }
   ],
   "source": [
    "hyperParamDict = {'EMBED_SIZE': EMBED_SIZE,\n",
    "                  'maxNoteLength': maxAllowedNoteLength,\n",
    "                  'maxGradNorm': max_grad_norm,\n",
    "                  'outputKeepProb': output_keep_prob,\n",
    "                  'inputKeepProb': input_keep_prob,\n",
    "                  'learningRate': learning_rate,\n",
    "                  'trainingEpochsMax': training_epochs,\n",
    "                  'batchSize': batch_size,\n",
    "                  'n_hidden': n_hidden,\n",
    "                 'numLayers': numLayers,\n",
    "                 'sizeList':sizeList}\n",
    "pp.pprint(hyperParamDict)\n",
    "with open(os.path.join(output_path, 'hyperParamDict.pickle'), 'wb') as handle:\n",
    "    pickle.dump(hyperParamDict, handle, protocol = 2)\n",
    "    #dumping with 2 because ALTUD uses python 2.7 right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Finally, the model is trained (be wary - it will take some time; on an Amazon Deep Learning AMI, it took around an hour to train)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of embeddings\n",
      "(?, 1000, 300)\n",
      "<class 'tensorflow.python.ops.rnn_cell_impl.MultiRNNCell'>\n",
      "<tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fcd37d4ee10>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 1000, 300)\n",
      "cell output size\n",
      "200\n",
      "cell state size\n",
      "(LSTMStateTuple(c=200, h=200),)\n",
      "output shape\n",
      "(?, 1000, 200)\n",
      "offset shape\n",
      "(?, 1)\n",
      "output shape new shape\n",
      "(?, 200)\n",
      "flattened indices shape\n",
      "(?, 1)\n",
      "output flattened shape\n",
      "(?, 200)\n",
      "(200, 150)\n",
      "W_1 shape\n",
      "(150,)\n",
      "b_1 shape\n",
      "(150, 75)\n",
      "W_2 shape\n",
      "(75,)\n",
      "bias shape\n",
      "(19,)\n",
      "U shape\n",
      "(75, 19)\n",
      "bias shape\n",
      "(19,)\n",
      "output wx + b\n",
      "(?, 19)\n",
      "(?, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "***************************\n",
      "Running on epoch 0\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.693269 at time 1.581384\n",
      "running iteration 25 with loss 0.487189 at time 33.215275\n",
      "running iteration 50 with loss 0.478750 at time 64.887364\n",
      "running iteration 75 with loss 0.453166 at time 96.595995\n",
      "running iteration 100 with loss 0.452149 at time 128.301554\n",
      "running iteration 125 with loss 0.448263 at time 160.001611\n",
      "running iteration 150 with loss 0.690074 at time 191.706280\n",
      "running iteration 175 with loss 0.325784 at time 223.510821\n",
      "running iteration 200 with loss 0.284836 at time 255.311713\n",
      "running iteration 225 with loss 0.291725 at time 287.118439\n",
      "running iteration 250 with loss 0.295361 at time 318.870485\n",
      "running iteration 275 with loss 0.286907 at time 350.595414\n",
      "running iteration 300 with loss 0.301422 at time 382.293051\n",
      "running iteration 325 with loss 0.285223 at time 413.996011\n",
      "running iteration 350 with loss 0.314568 at time 445.699129\n",
      "running iteration 375 with loss 0.323178 at time 477.511213\n",
      "average training loss 0.375688\n",
      "test loss 0.546199\n",
      "Total run time was 555.044951\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 1\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 1.023871 at time 1.274551\n",
      "running iteration 25 with loss 0.491657 at time 33.009629\n",
      "running iteration 50 with loss 0.464164 at time 64.724163\n",
      "running iteration 75 with loss 0.442816 at time 96.640126\n",
      "running iteration 100 with loss 0.446713 at time 128.548640\n",
      "running iteration 125 with loss 0.432543 at time 160.380082\n",
      "running iteration 150 with loss 0.437658 at time 192.120326\n",
      "running iteration 175 with loss 0.314191 at time 223.934155\n",
      "running iteration 200 with loss 0.273818 at time 255.798956\n",
      "running iteration 225 with loss 0.269309 at time 287.592050\n",
      "running iteration 250 with loss 0.271143 at time 319.502429\n",
      "running iteration 275 with loss 0.259769 at time 351.272000\n",
      "running iteration 300 with loss 0.279943 at time 383.172502\n",
      "running iteration 325 with loss 0.266761 at time 415.084993\n",
      "running iteration 350 with loss 0.283613 at time 446.990980\n",
      "running iteration 375 with loss 0.301442 at time 478.908135\n",
      "average training loss 0.357137\n",
      "test loss 0.473895\n",
      "Total run time was 557.062031\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 2\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.866775 at time 1.288415\n",
      "running iteration 25 with loss 0.464475 at time 33.261350\n",
      "running iteration 50 with loss 0.445089 at time 65.217271\n",
      "running iteration 75 with loss 0.435828 at time 96.989955\n",
      "running iteration 100 with loss 0.440842 at time 128.765693\n",
      "running iteration 125 with loss 0.427389 at time 160.514422\n",
      "running iteration 150 with loss 0.434677 at time 192.241918\n",
      "running iteration 175 with loss 0.290515 at time 223.954610\n",
      "running iteration 200 with loss 0.238991 at time 255.697030\n",
      "running iteration 225 with loss 0.241574 at time 287.382687\n",
      "running iteration 250 with loss 0.246760 at time 319.078502\n",
      "running iteration 275 with loss 0.230013 at time 350.750071\n",
      "running iteration 300 with loss 0.255757 at time 382.437806\n",
      "running iteration 325 with loss 0.238888 at time 414.103822\n",
      "running iteration 350 with loss 0.255874 at time 445.775830\n",
      "running iteration 375 with loss 0.273564 at time 477.449190\n",
      "average training loss 0.335095\n",
      "test loss 0.441957\n",
      "Total run time was 554.153882\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 3\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.827461 at time 1.275996\n",
      "running iteration 25 with loss 0.445218 at time 33.057527\n",
      "running iteration 50 with loss 0.440074 at time 64.850114\n",
      "running iteration 75 with loss 0.427118 at time 96.585782\n",
      "running iteration 100 with loss 0.435607 at time 128.422704\n",
      "running iteration 125 with loss 0.423972 at time 160.128381\n",
      "running iteration 150 with loss 0.444933 at time 191.851705\n",
      "running iteration 175 with loss 0.258800 at time 223.678778\n",
      "running iteration 200 with loss 0.211453 at time 255.550493\n",
      "running iteration 225 with loss 0.220816 at time 287.314651\n",
      "running iteration 250 with loss 0.211603 at time 319.200674\n",
      "running iteration 275 with loss 0.203693 at time 351.013893\n",
      "running iteration 300 with loss 0.232119 at time 382.830540\n",
      "running iteration 325 with loss 0.215180 at time 414.636623\n",
      "running iteration 350 with loss 0.235339 at time 446.386890\n",
      "running iteration 375 with loss 0.248312 at time 478.179520\n",
      "average training loss 0.317075\n",
      "test loss 0.395642\n",
      "Total run time was 556.094212\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 4\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.743445 at time 1.283768\n",
      "running iteration 25 with loss 0.439933 at time 33.302261\n",
      "running iteration 50 with loss 0.430074 at time 65.167073\n",
      "running iteration 75 with loss 0.422346 at time 96.930443\n",
      "running iteration 100 with loss 0.425403 at time 128.801958\n",
      "running iteration 125 with loss 0.414899 at time 160.738146\n",
      "running iteration 150 with loss 0.419472 at time 192.688998\n",
      "running iteration 175 with loss 0.227050 at time 224.615178\n",
      "running iteration 200 with loss 0.186109 at time 256.542504\n",
      "running iteration 225 with loss 0.195479 at time 288.460909\n",
      "running iteration 250 with loss 0.197993 at time 320.409925\n",
      "running iteration 275 with loss 0.185231 at time 352.360139\n",
      "running iteration 300 with loss 0.217446 at time 384.284955\n",
      "running iteration 325 with loss 0.198244 at time 416.010840\n",
      "running iteration 350 with loss 0.216962 at time 447.728956\n",
      "running iteration 375 with loss 0.234660 at time 479.498638\n",
      "average training loss 0.297839\n",
      "test loss 0.346293\n",
      "Total run time was 556.623229\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 5\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.572548 at time 1.288633\n",
      "running iteration 25 with loss 0.427175 at time 33.050675\n",
      "running iteration 50 with loss 0.419706 at time 64.951807\n",
      "running iteration 75 with loss 0.418339 at time 96.882037\n",
      "running iteration 100 with loss 0.417619 at time 128.812778\n",
      "running iteration 125 with loss 0.397303 at time 160.748816\n",
      "running iteration 150 with loss 0.403501 at time 192.696318\n",
      "running iteration 175 with loss 0.210322 at time 224.621090\n",
      "running iteration 200 with loss 0.170282 at time 256.542645\n",
      "running iteration 225 with loss 0.174117 at time 288.486643\n",
      "running iteration 250 with loss 0.180859 at time 320.425685\n",
      "running iteration 275 with loss 0.174396 at time 352.150479\n",
      "running iteration 300 with loss 0.198396 at time 383.869132\n",
      "running iteration 325 with loss 0.181239 at time 415.573496\n",
      "running iteration 350 with loss 0.202962 at time 447.263547\n",
      "running iteration 375 with loss 0.220784 at time 479.032250\n",
      "average training loss 0.279885\n",
      "test loss 0.325196\n",
      "Total run time was 556.678018\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 6\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.536272 at time 1.284276\n",
      "running iteration 25 with loss 0.410755 at time 33.221959\n",
      "running iteration 50 with loss 0.403459 at time 65.158425\n",
      "running iteration 75 with loss 0.398657 at time 97.106769\n",
      "running iteration 100 with loss 0.401466 at time 129.068059\n",
      "running iteration 125 with loss 0.383320 at time 161.025075\n",
      "running iteration 150 with loss 0.390977 at time 193.004376\n",
      "running iteration 175 with loss 0.186280 at time 224.949005\n",
      "running iteration 200 with loss 0.150376 at time 256.898832\n",
      "running iteration 225 with loss 0.163406 at time 288.834695\n",
      "running iteration 250 with loss 0.169909 at time 320.791041\n",
      "running iteration 275 with loss 0.160766 at time 352.731820\n",
      "running iteration 300 with loss 0.184158 at time 384.674642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running iteration 325 with loss 0.169790 at time 416.603540\n",
      "running iteration 350 with loss 0.194469 at time 448.539220\n",
      "running iteration 375 with loss 0.207639 at time 480.490455\n",
      "average training loss 0.263960\n",
      "test loss 0.299760\n",
      "Total run time was 558.712527\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 7\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.477814 at time 1.291435\n",
      "running iteration 25 with loss 0.399503 at time 33.273653\n",
      "running iteration 50 with loss 0.390067 at time 65.257490\n",
      "running iteration 75 with loss 0.387884 at time 97.257123\n",
      "running iteration 100 with loss 0.386945 at time 129.222821\n",
      "running iteration 125 with loss 0.368562 at time 161.182592\n",
      "running iteration 150 with loss 0.380099 at time 193.171394\n",
      "running iteration 175 with loss 0.171399 at time 225.123951\n",
      "running iteration 200 with loss 0.142117 at time 257.100943\n",
      "running iteration 225 with loss 0.151998 at time 289.040633\n",
      "running iteration 250 with loss 0.157380 at time 321.021681\n",
      "running iteration 275 with loss 0.148287 at time 352.971554\n",
      "running iteration 300 with loss 0.168206 at time 384.906223\n",
      "running iteration 325 with loss 0.155143 at time 416.851862\n",
      "running iteration 350 with loss 0.182910 at time 448.781415\n",
      "running iteration 375 with loss 0.194701 at time 480.722404\n",
      "average training loss 0.250707\n",
      "test loss 0.281472\n",
      "Total run time was 558.135199\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 8\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.438081 at time 1.283156\n",
      "running iteration 25 with loss 0.382582 at time 33.042851\n",
      "running iteration 50 with loss 0.375516 at time 64.783229\n",
      "running iteration 75 with loss 0.371643 at time 96.504122\n",
      "running iteration 100 with loss 0.373713 at time 128.218657\n",
      "running iteration 125 with loss 0.355564 at time 159.909395\n",
      "running iteration 150 with loss 0.359617 at time 191.597673\n",
      "running iteration 175 with loss 0.161679 at time 223.270956\n",
      "running iteration 200 with loss 0.134333 at time 254.946513\n",
      "running iteration 225 with loss 0.144775 at time 286.621784\n",
      "running iteration 250 with loss 0.147246 at time 318.293204\n",
      "running iteration 275 with loss 0.140312 at time 349.955266\n",
      "running iteration 300 with loss 0.159192 at time 381.638510\n",
      "running iteration 325 with loss 0.150167 at time 413.308161\n",
      "running iteration 350 with loss 0.169759 at time 444.968131\n",
      "running iteration 375 with loss 0.187897 at time 476.629869\n",
      "average training loss 0.238029\n",
      "test loss 0.278466\n",
      "Total run time was 553.348574\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 9\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.449505 at time 1.277088\n",
      "running iteration 25 with loss 0.370893 at time 32.969487\n",
      "running iteration 50 with loss 0.364341 at time 64.668080\n",
      "running iteration 75 with loss 0.355835 at time 96.359759\n",
      "running iteration 100 with loss 0.358144 at time 128.067931\n",
      "running iteration 125 with loss 0.342523 at time 159.767040\n",
      "running iteration 150 with loss 0.346247 at time 191.455709\n",
      "running iteration 175 with loss 0.153597 at time 223.129770\n",
      "running iteration 200 with loss 0.122262 at time 254.790791\n",
      "running iteration 225 with loss 0.132403 at time 286.453092\n",
      "running iteration 250 with loss 0.136826 at time 318.104307\n",
      "running iteration 275 with loss 0.129599 at time 349.758373\n",
      "running iteration 300 with loss 0.147830 at time 381.435003\n",
      "running iteration 325 with loss 0.144323 at time 413.095693\n",
      "running iteration 350 with loss 0.156320 at time 444.755227\n",
      "running iteration 375 with loss 0.173943 at time 476.441606\n",
      "average training loss 0.227172\n",
      "test loss 0.267894\n",
      "Total run time was 553.156057\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 10\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.417610 at time 1.273892\n",
      "running iteration 25 with loss 0.354342 at time 32.969972\n",
      "running iteration 50 with loss 0.350783 at time 64.654336\n",
      "running iteration 75 with loss 0.345799 at time 96.478768\n",
      "running iteration 100 with loss 0.338077 at time 128.373701\n",
      "running iteration 125 with loss 0.329985 at time 160.290972\n",
      "running iteration 150 with loss 0.335219 at time 192.206010\n",
      "running iteration 175 with loss 0.141129 at time 224.118793\n",
      "running iteration 200 with loss 0.113868 at time 256.027138\n",
      "running iteration 225 with loss 0.118724 at time 287.966598\n",
      "running iteration 250 with loss 0.134435 at time 319.907313\n",
      "running iteration 275 with loss 0.127421 at time 351.835477\n",
      "running iteration 300 with loss 0.136528 at time 383.772306\n",
      "running iteration 325 with loss 0.142066 at time 415.712155\n",
      "running iteration 350 with loss 0.149208 at time 447.563847\n",
      "running iteration 375 with loss 0.164658 at time 479.315335\n",
      "average training loss 0.217194\n",
      "test loss 0.263293\n",
      "Total run time was 557.079889\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 11\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.399961 at time 1.286723\n",
      "running iteration 25 with loss 0.344532 at time 33.241221\n",
      "running iteration 50 with loss 0.344435 at time 65.201071\n",
      "running iteration 75 with loss 0.336007 at time 97.176864\n",
      "running iteration 100 with loss 0.329551 at time 129.146974\n",
      "running iteration 125 with loss 0.313374 at time 161.139765\n",
      "running iteration 150 with loss 0.323527 at time 192.999722\n",
      "running iteration 175 with loss 0.132530 at time 224.752879\n",
      "running iteration 200 with loss 0.110890 at time 256.464159\n",
      "running iteration 225 with loss 0.121100 at time 288.146806\n",
      "running iteration 250 with loss 0.126314 at time 319.831773\n",
      "running iteration 275 with loss 0.118796 at time 351.596362\n",
      "running iteration 300 with loss 0.130608 at time 383.456542\n",
      "running iteration 325 with loss 0.134872 at time 415.341929\n",
      "running iteration 350 with loss 0.141122 at time 447.241301\n",
      "running iteration 375 with loss 0.157931 at time 479.154794\n",
      "average training loss 0.208975\n",
      "test loss 0.255172\n",
      "Total run time was 556.458858\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 12\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.366992 at time 1.279617\n",
      "running iteration 25 with loss 0.336914 at time 33.053104\n",
      "running iteration 50 with loss 0.333253 at time 64.923066\n",
      "running iteration 75 with loss 0.325065 at time 96.874246\n",
      "running iteration 100 with loss 0.317643 at time 128.839161\n",
      "running iteration 125 with loss 0.312984 at time 160.829293\n",
      "running iteration 150 with loss 0.320435 at time 192.840316\n",
      "running iteration 175 with loss 0.129556 at time 224.802044\n",
      "running iteration 200 with loss 0.102780 at time 256.755436\n",
      "running iteration 225 with loss 0.109741 at time 288.689363\n",
      "running iteration 250 with loss 0.121140 at time 320.636120\n",
      "running iteration 275 with loss 0.114256 at time 352.584269\n",
      "running iteration 300 with loss 0.124815 at time 384.496212\n",
      "running iteration 325 with loss 0.132163 at time 416.289384\n",
      "running iteration 350 with loss 0.129194 at time 448.205332\n",
      "running iteration 375 with loss 0.155118 at time 480.043524\n",
      "average training loss 0.200979\n",
      "test loss 0.253653\n",
      "Total run time was 558.124511\n",
      "New best model found. Saving\n",
      "results/0122_mimic+csu_mm_reps\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 13\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.349788 at time 1.285800\n",
      "running iteration 25 with loss 0.326406 at time 33.243710\n",
      "running iteration 50 with loss 0.330242 at time 65.213595\n",
      "running iteration 75 with loss 0.320814 at time 97.200213\n",
      "running iteration 100 with loss 0.313490 at time 129.181765\n",
      "running iteration 125 with loss 0.300054 at time 161.160770\n",
      "running iteration 150 with loss 0.307183 at time 193.162025\n",
      "running iteration 175 with loss 0.116797 at time 225.148308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running iteration 200 with loss 0.098957 at time 257.128644\n",
      "running iteration 225 with loss 0.101180 at time 289.068367\n",
      "running iteration 250 with loss 0.113588 at time 321.027264\n",
      "running iteration 275 with loss 0.105978 at time 352.978230\n",
      "running iteration 300 with loss 0.120091 at time 384.941393\n",
      "running iteration 325 with loss 0.120769 at time 416.903864\n",
      "running iteration 350 with loss 0.125648 at time 448.850491\n",
      "running iteration 375 with loss 0.148471 at time 480.599989\n",
      "average training loss 0.193668\n",
      "test loss 0.254510\n",
      "Total run time was 558.668744\n",
      "validation Loss Increase\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 14\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.336565 at time 1.279463\n",
      "running iteration 25 with loss 0.323892 at time 33.265999\n",
      "running iteration 50 with loss 0.318146 at time 65.246777\n",
      "running iteration 75 with loss 0.310510 at time 97.217541\n",
      "running iteration 100 with loss 0.302324 at time 129.206197\n",
      "running iteration 125 with loss 0.291829 at time 161.212947\n",
      "running iteration 150 with loss 0.302716 at time 193.227675\n",
      "running iteration 175 with loss 0.111948 at time 225.235567\n",
      "running iteration 200 with loss 0.094850 at time 257.232823\n",
      "running iteration 225 with loss 0.098409 at time 289.210761\n",
      "running iteration 250 with loss 0.111462 at time 321.194828\n",
      "running iteration 275 with loss 0.101617 at time 353.160238\n",
      "running iteration 300 with loss 0.111816 at time 385.159676\n",
      "running iteration 325 with loss 0.118411 at time 417.180016\n",
      "running iteration 350 with loss 0.116697 at time 449.176898\n",
      "running iteration 375 with loss 0.134504 at time 481.146803\n",
      "average training loss 0.186928\n",
      "test loss 0.259758\n",
      "Total run time was 559.408671\n",
      "validation Loss Increase\n",
      "***************************\n",
      "***************************\n",
      "Running on epoch 15\n",
      "***************************\n",
      "***************************\n",
      "running iteration 0 with loss 0.331472 at time 1.283495\n",
      "running iteration 25 with loss 0.313855 at time 33.284486\n",
      "running iteration 50 with loss 0.315560 at time 65.254420\n",
      "running iteration 75 with loss 0.300772 at time 97.254966\n",
      "running iteration 100 with loss 0.295172 at time 129.243356\n",
      "running iteration 125 with loss 0.285041 at time 161.220739\n",
      "running iteration 150 with loss 0.291566 at time 193.039937\n",
      "running iteration 175 with loss 0.102128 at time 224.807346\n",
      "running iteration 200 with loss 0.090807 at time 256.668271\n",
      "running iteration 225 with loss 0.087995 at time 288.639590\n",
      "running iteration 250 with loss 0.102464 at time 320.607598\n",
      "running iteration 275 with loss 0.098922 at time 352.602699\n",
      "running iteration 300 with loss 0.105849 at time 384.582925\n",
      "running iteration 325 with loss 0.113283 at time 416.566122\n",
      "running iteration 350 with loss 0.114856 at time 448.557508\n",
      "running iteration 375 with loss 0.133959 at time 480.501349\n",
      "average training loss 0.180601\n",
      "test loss 0.262138\n",
      "Total run time was 558.744942\n",
      "validation Loss Increase\n",
      "Stopping early because of increasing validation loss\n"
     ]
    }
   ],
   "source": [
    "from trainModel import trainModel\n",
    "xDev[xDev == -1] = 0\n",
    "xTrain[xTrain == -1] = 0\n",
    "trainModel(helperObj = helper, embeddings = embeddings, hyperParamDict = hyperParamDict, \n",
    "          xDev = xDev, xTrain = xTrain, yDev = yDev, yTrain = yTrain, \n",
    "           lastTrueWordIdx_dev = lastTrueWordIdx_dev, \n",
    "           lastTrueWordIdx_train = lastTrueWordIdx_train,\n",
    "           training_epochs = training_epochs, \n",
    "           output_path = output_path, batchSizeTrain = batch_size,\n",
    "           sizeList = sizeList,\n",
    "           maxIncreasingLossCount = 100, batchSizeDev = 1500, chatty = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the session closed. You should be able to see your results in the `output_path` directory you specified earlier.\n",
    "\n",
    "To evaluate the results and generate plots and such, please check out `predictionEvaluation.ipynb` in the same repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xDev[xDev == -1] = 0\n",
    "# xTrain[xTrain == -1] = 0\n",
    "# trueWordIdxs = tf.placeholder(tf.int32, shape = (None,1))\n",
    "# with tf.Session() as session:\n",
    "#     tf.global_variables_initializer().run()\n",
    "#     modelDict = reloadModel(session = session,\n",
    "#                             saverCheckPointPath = output_path,\n",
    "#                             saverMetaPath = output_path + '/bestModel.meta')\n",
    "#     print('here we go')\n",
    "#     for i in range(3):\n",
    "#         pred_y = session.run(modelDict['y_last'],feed_dict={modelDict['xPlaceHolder']: xDev,\n",
    "#                                       modelDict['trueWordIdxs']:lastTrueWordIdx_dev,\n",
    "#                                       modelDict['outputKeepProb']: 1.0,\n",
    "#                                       modelDict['inputKeepProb']: 1.0}, ) \n",
    "#         validLoss = tf.nn.sigmoid_cross_entropy_with_logits(logits = pred_y, \n",
    "#                                              labels = tf.cast(yDev, tf.float32))\n",
    "#         validLoss = tf.reduce_mean(validLoss)\n",
    "#         validLoss = validLoss.eval()\n",
    "#         print('test loss %f'%(validLoss))\n",
    "#         print('***********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
